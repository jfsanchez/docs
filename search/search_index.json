{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Presentaci\u00f3ns","text":"<ul> <li> <p>\ud83d\udda5\ufe0f Conceptos de inform\u00e1tica b\u00e1sica</p> </li> <li> <p>\ud83d\udd78\ufe0f Modos de Rede no VirtualBox</p> </li> <li> <p>\ud83d\udc31 Uso b\u00e1sico de git</p> </li> <li> <p>\ud83d\udc0d Conda e pip</p> </li> <li> <p>\u274e XPATH para uso con Selenium</p> </li> <li> <p>\ud83e\udeb6 MongoDB</p> </li> <li> <p>\ud83d\udc33 Docker / Contedores</p> </li> <li> <p>\ud83d\udcd5 FP en Galicia. Desactualizado!</p> </li> </ul> <p>Presentaci\u00f3ns feitas con revealjs.</p> <p>Os materiais publicanse con copyright. Perm\u00edtese o seu uso en docencia, pero non para formaci\u00f3n de formadores. Non se permite a s\u00faa inclusi\u00f3n en materiales elaborados, oficiais ou non por parte de empresas que elaboren/vendan materiais, bootcamps, editoriais e similares ou a instituci\u00f3ns p\u00fablicas ou privadas de calquer tipo, posto que non forman parte dos seus materiais. O \u00fanico uso permitido \u00e9 a docentes para as s\u00faas clases.</p> <p>Se atopas erros, por favor, ponte en contacto conmigo (preme nunha das presentaci\u00f3ns e mira o correo na \u00faltima diapositiva).</p>"},{"location":"amazon-corretto-java-0-instalacion/","title":"Java / Amazon Corretto / OpenJDK","text":""},{"location":"amazon-corretto-java-0-instalacion/#orixe","title":"Orixe","text":"<p>A primeira versi\u00f3n de Java (Oak) foi desenvolvida por Sun Microsystems, empresa comprada por Oracle en 2009/2010. Trala compra, houbo denuncias a grandes empresas que empregaban a API de Java como Google no seu Android. Tam\u00e9n houbo cambios no sistema de licenciamento. En 2017 houbo cambios importantes no modelo de actualizaci\u00f3ns e outros problemas.</p> <p>Entre tanto, no 2007 cre\u00e1rase unha m\u00e1quina virtual de Java libre chamada OpenJDK, o seu uso aumentou nos \u00faltimos anos. Fai uns anos, Amazon creou unha distribuci\u00f3n gratuita baseada en OpenJDK optimizada para nube e con soporte a longo prazo tanto en melloras de rendemento como correcci\u00f3n de erros de seguridade. A historia \u00e9 moito m\u00e1is complexa e pode lerse na p\u00e1xina da Wikipedia adicada ao OpenJDK.</p>"},{"location":"amazon-corretto-java-0-instalacion/#instalacion-de-amazon-corretto","title":"Instalaci\u00f3n de Amazon Corretto","text":"DebianRocky/FedoraGNU/Linux xen\u00e9rico <pre><code>sudo apt update\nsudo apt -y dist-upgrade\nsudo apt install java-common\nwget https://corretto.aws/downloads/latest/amazon-corretto-21-x64-linux-jdk.deb\nsudo dpkg -i amazon-corretto-21-x64-linux-jdk.deb\nrm amazon-corretto-21-x64-linux-jdk.deb\n</code></pre> <pre><code>sudo dnf update -y\nsudo curl -L -o /etc/yum.repos.d/corretto.repo https://yum.corretto.aws/corretto.repo\nsudo dnf install -y java-21-amazon-corretto-devel\n</code></pre> <pre><code>mkdir -p $HOME/bin\ncd\nwget https://corretto.aws/downloads/latest/amazon-corretto-11-x64-linux-jdk.tar.gz\ntar -xzf amazon-corretto-11-x64-linux-jdk.tar.gz\nmv amazon-corretto-11*-linux-x64/ bin/amazon-corretto-latest\nrm amazon-corretto-11-x64-linux-jdk.tar.gz\n# Configuro o PATH\necho \"export PATH=$HOME/bin:$HOME/bin/amazon-corretto-latest/bin:$PATH\" &gt;&gt; $HOME/.profile\n. ~/.profile\n</code></pre> <p>O paquete mete o binario dentro dun directorio que xa est\u00e1 no PATH e a instalaci\u00f3n xen\u00e9rica configura o PATH a man, polo que poderemos executar:</p> <pre><code>java --version\n</code></pre>"},{"location":"amazon-corretto-java-0-instalacion/#configuracion-do-java_home","title":"Configuraci\u00f3n do JAVA_HOME","text":"<p>Atopar o <code>JAVA_HOME</code> \u00e9 tarefa sinxela. Se executamos o comando <code>type java</code> para saber onde reside o binario de java e imos averiguando a onde est\u00e1 apuntado o enlace simb\u00f3lico con <code>ls -l RUTA</code>, sacaremos esta conclusi\u00f3n:</p> <p><code>/usr/bin/java</code> \u2192 <code>/etc/alternatives/java</code> \u2192 <code>/usr/lib/jvm/java-21-amazon-corretto/bin/java</code>.</p> <p>Engadimos o JAVA_HOME. \u00c9 moi conveniente para que os programas atopen o contorno de OpenJDK.</p> Debian/Rocky/FedoraGNU/Linux xen\u00e9rico <pre><code>echo \"export JAVA_HOME='/usr/lib/jvm/java-21-amazon-corretto/'\" &gt;&gt; $HOME/.profile\nsource ~/.profile\n</code></pre> <pre><code>echo \"export JAVA_HOME=$HOME/bin/amazon-corretto-latest\" &gt;&gt; $HOME/.profile\n. ~/.profile\n</code></pre>"},{"location":"amazon-corretto-java-0-instalacion/#comandos-utiles","title":"Comandos \u00fatiles","text":"<ul> <li><code>jps</code>: Ver os procesos en Java.</li> <li><code>keytool</code>: Administrar os certificados empregados por Java nun almac\u00e9n.</li> </ul>"},{"location":"amazon-corretto-java-0-instalacion/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>Implementaci\u00f3n libre de Java: https://openjdk.org/</li> <li>Amazon Corretto (baseada no OpenJDK): https://aws.amazon.com/es/corretto/</li> <li>Java de Oracle: https://www.oracle.com/java/technologies/downloads/</li> </ul>"},{"location":"apache-airflow-0-instalacion/","title":"\ud83c\udf40 Apache Airflow \u2014 \ud83e\uddfe Instalaci\u00f3n","text":"<p>Programa e monitoriza fluxos de datos. Unha especie de cron con esteroides ou un orquestador de datos.</p>"},{"location":"apache-airflow-0-instalacion/#mais-informacion","title":"M\u00e1is informaci\u00f3n:","text":"<ul> <li>https://airflow.apache.org/</li> <li>https://github.com/javicacheiro/pyspark_course/tree/master/supplementary/airflow</li> <li>https://aitor-medrano.github.io/iabd/dataflow/airflow.html</li> </ul>"},{"location":"apache-hadoop-0-instalacion/","title":"\ud83d\udc18 Apache Hadoop \u2014 \ud83e\uddfe Instalaci\u00f3n","text":"<p>Instalaci\u00f3n de Apache Hadoop empregando ClusterShell</p>"},{"location":"apache-hadoop-0-instalacion/#requisitos-previos","title":"Requisitos previos","text":"<p>Estas probas foron feitas nunha contorna baixo Rocky Linux 8.5 v2 no CESGA, no seu OpenStack.</p>"},{"location":"apache-hadoop-0-instalacion/#grupo-de-seguridade","title":"Grupo de seguridade","text":"<p>Teremos que abrir os seguintes portos (ollo, deber\u00edamolos abrir s\u00f3 entre eles e para nos, posto que deixar abertos os portos \u00e9 un importante risco de seguridade):</p> <p>Xerais:</p> <ul> <li>SSH: 22 (TCP).</li> </ul> <p>Apache Hadoop:</p> <ul> <li>HADOOP_HDFS: 9000 (TCP)</li> <li>HADDOP_MASTER_WEB: 9870 (TCP)</li> <li>HADOOP_SECONDARY_NAMENODE_WEB 9864 (TCP) (admin)</li> <li>HADOOP_SECONDARY_NAMENODE_WEB 9868 (TCP)</li> </ul> <p>Apache Spark:</p> <ul> <li>SPARK_MAIN: 9001 (TCP)</li> <li>INFO_MASTER_SPARK: 8080 (TCP)</li> <li>INFO_WORKERS_SPARK: 8081 (TCP)</li> <li>INFO_WORKERS_SPARK_WEB: 4040 (TCP)</li> <li>OUTROS: 7707 (TCP)</li> </ul>"},{"location":"apache-hadoop-0-instalacion/#instalacion-de-clustershell","title":"Instalaci\u00f3n de ClusterShell","text":"<p>Debemos instalar ClusterShell no nodo master ou no equipo onde fagamos a instalaci\u00f3n. ClusterShell \u00e9 un programa que permite enviar \u00e1 vez comandos a varias m\u00e1quinas.</p> <p>Executemos os comandos dende o noso equipo local ou dende o nodo master, podemos incluir o nodo master para conectarnos contra el mesmo e executar tam\u00e9n nel os comandos.</p>"},{"location":"apache-hadoop-0-instalacion/#instalacion-dende-rocky-linux-ou-distro-baseada-en-redhat","title":"Instalaci\u00f3n dende Rocky Linux ou distro baseada en Redhat","text":"<pre><code>sudo yum --enablerepo=extras -y install epel-release\n</code></pre> <pre><code>sudo yum install -y clustershell\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#instalacion-dende-linux-mint-ou-distro-baseada-en-ubuntudebian","title":"Instalaci\u00f3n dende Linux Mint ou distro baseada en Ubuntu/Debian","text":"<pre><code>sudo apt-get install clustershell\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#conexion-aos-servidores-por-nome","title":"Conexi\u00f3n aos servidores por nome","text":"<p>Deberemos configurar o arquivo <code>/etc/hosts</code> cos nomes dos servidores:</p> /etc/hosts<pre><code>X.Y.Z.T1 hadoop1 hadoop1.local\nX.Y.Z.T2 hadoop2 hadoop2.local\nX.Y.Z.T3 hadoop3 hadoop3.local\n...\n[X.Y.Z.Tn hadoopN hadoopN.local]\n</code></pre> <p>Cada un destes servidores debe ter como m\u00ednimo 4 GB de RAM (8 \u00e9 o m\u00ednimo recomendable m\u00e1is imos aplicar restricci\u00f3ns na configuraci\u00f3n).</p> <p>Debemos ter creado un usuario chamado <code>cesgaxuser</code>, co que executaremos t\u00f3dolos comandos. Este usuario existe por defecto nas m\u00e1quinas virtuais novas creadas no OpenStack do CESGA.</p> <p>Dende o nodo master (hadoop1) debemos poder conectar por SSH ao resto de nodos: hadoop2, hadoop3 ... hadoopN (ter copiada a parte p\u00fablica da chave SSH no <code>.ssh/authorized_keys</code>). Podemos xerar e meter unha chave nova no master (empregando <code>ssh-keygen</code>) ou ben copiar a chave que nos xenere o OpenStack (arquivo .pem coa chave RSA).</p> <p>Se copiamos a chave RSA xerada polo OpenStack durante a creaci\u00f3n da m\u00e1quina, podemos copiala mediante scp:</p> <p>Neste exemplo imaxinamos que este arquivo, gardado no directorio onde nos atopemos, ch\u00e1mase: <code>ficheiro-chave-ssh.pem</code></p> <ul> <li> <p>Copiamos o arquivo (ollo, hai que repetir o arquivo, unha vez para pasalo como chave a empregar e outra para copialo):</p> <pre><code>scp -i ficheiro-chave-ssh.pem \\\n  ficheiro-chave-ssh.pem cesgaxuser@hadoop1:/home/cesgaxuser/\n</code></pre> </li> </ul> <p>Se nos devolve un erro coma este:</p> <pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nPermissions 0755 for 'ficheiro-chave-ssh.pem' are too open.\nIt is required that your private key files are NOT accessible by others.\nThis private key will be ignored.\nLoad key \"ficheiro-chave-ssh.pem\": bad permissions\n</code></pre> <p>Deberemos dar permisos adecuados (s\u00f3 podemos ler a chave nos):</p> <pre><code>chmod 0600 ficheiro-chave-ssh.pem\n</code></pre> <ul> <li> <p>Conectamos co master:</p> <pre><code>ssh -i ficheiro-chave-ssh.pem cesgaxuser@hadoop1\n</code></pre> </li> <li> <p>Dentro do master, forzaremos a creaci\u00f3n da estrutura <code>.ssh</code> no directorio <code>$HOME</code>:</p> <pre><code>ssh localhost\n</code></pre> </li> </ul> <p>Preguntaranos se queremos conectar co servidor, xa que \u00e9 a primeira vez e non co\u00f1ece a chave:</p> <pre><code>[cesgaxuser@hadoop1 ~]$ ssh localhost\nThe authenticity of host 'localhost (::1)' can't be established.\nECDSA key fingerprint is SHA256:5aeqrZspd4Wev7IrUFH/KS8OXORpa614OEWXRHUG+yE.\nAre you sure you want to continue connecting (yes/no/[fingerprint])? \n</code></pre> <p>Contestamos <code>yes</code> e damos a enter para que se cree a estrutura <code>.ssh</code>.</p> <p>Agora toca mover a chave privada ao directorio por defecto:</p> <pre><code>mv ficheiro-chave-ssh.pem .ssh/id_rsa\n</code></pre> <p>E dar os permisos adecuados:</p> <pre><code>chmod 0600 .ssh/id_rsa\n</code></pre> <p>Finalmente, xeraremos a parte p\u00fablica da nosa chave privada:</p> <pre><code>ssh-keygen -y -f .ssh/id_rsa &gt; .ssh/id_rsa.pub\n</code></pre> <p>Copiaremos as chaves do nodo master ao resto de nodos por comodidade, de xeito que poderemos enviar un comando a t\u00f3dolos nodos dende calquera. Esto pode supor un risco de seguridade, mais poderemos borrar se queremos a chave privada do resto de nodos. De t\u00f3dolos xeitos, tendo en conta que a configuraci\u00f3n \u00e9 a mesma en t\u00f3dolos nodos e que est\u00e1n conectados, que logre acceder a un, moi probablemente poida acceder a todos.</p> <p>No <code>.ssh/known_hosts</code> de hadoop1, hadoop2 ... hadoopN precisamos os fingerprints de todos os servidores. Para facelo:</p> <ul> <li> <p>Descargamos os fingerprints dos servidores (con t\u00f3dalas IPs e nomes):</p> <pre><code>for servidor in $(cat /etc/hosts|grep hadoop); do \\\n  ssh-keyscan -H $servidor; done &gt;&gt; /home/cesgaxuser/.ssh/known_hosts\n</code></pre> </li> </ul> <p>Se mud\u00e1semos a li\u00f1a que lista os hosts por esta: <code>$(cat /etc/hosts|grep hadoop|awk '{print $1}'</code>, poder\u00edamos asociar as chaves s\u00f3 os enderezos IP.</p> <ul> <li> <p>Copiamos a configuraci\u00f3n a t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy /home/cesgaxuser/.ssh \\\n  --dest /home/cesgaxuser/\n</code></pre> </li> </ul>"},{"location":"apache-hadoop-0-instalacion/#actualizacion-de-paquetes","title":"Actualizaci\u00f3n de paquetes","text":"<p>Antes de seguir, \u00e9 moi conveniente actualizar o sistema para evitar erros de seguridade. Deste xeito probamos que podemos conectar con t\u00f3dolos nodos.</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] sudo dnf update -y\n</code></pre> <p>(opcional, m\u00e1is recomendable) E por comodidade, instalamos <code>nano</code> un editor moi simple e m\u00e1is amigable que <code>vi</code> e tam\u00e9n <code>net-tools</code> por se precisamos ver certas configuraci\u00f3ns de rede para diagnosticar erros.</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] sudo dnf install -y nano net-tools\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#instalacion-de-java-openjdk-correto-de-amazon","title":"Instalaci\u00f3n de Java OpenJDK Correto de Amazon","text":"<p>En t\u00f3dolos equipos debemos ter instalada a m\u00e1quina virtual de Java OpenJDK versi\u00f3n Corrreto de Amazon a trav\u00e9s de repositorio. </p> <p>Engadimos o respositorio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo curl -L -o /etc/yum.repos.d/corretto.repo \\\n  https://yum.corretto.aws/corretto.repo\n</code></pre> <p>Instalamos o paquete:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo dnf install -y java-11-amazon-corretto-devel`\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#configuracion-do-nodo-master","title":"Configuraci\u00f3n do nodo master","text":"<p>Debemos conectarnos por SSH ao nodo master:</p> <pre><code>ssh cesgaxuser@hadoop1\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#configuracion-de-java_home-en-todolos-servidores","title":"Configuraci\u00f3n de JAVA_HOME en t\u00f3dolos servidores","text":"<p>Editaremos o arquivo <code>/home/cesgaxuser/.bashrc</code> para configurar as variables de contorna necesarias.</p> <pre><code>nano .bashrc\n</code></pre> <p>Metemos esta li\u00f1a ao final:</p> .bashrc<pre><code>export JAVA_HOME='/usr/lib/jvm/java-11-amazon-corretto/'\n</code></pre> <p>Esto configura a variable de contorna <code>JAVA_HOME</code>. Non deber\u00eda ser necesario ao estar instalada a m\u00e1quina dende un repositorio automatizado, pero \u00e9 unha boa pr\u00e1ctica para que o resto de scripts non dean fallos ou avisos.</p> <p>Pechamos a sesi\u00f3n (Ctrl+D) e volvemos entrar (ou executamos <code>. ./bashrc</code> ou <code>source .bashrc</code> para recargar as variables de entorno).</p> <p>Copiamos este arquivo ao resto de nodos, empregaremos clustershell para simplificar o proceso:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] --copy .bashrc --dest /home/cesgaxuser/\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#descargando-e-instalando-apache-hadoop-en-todolos-nodos","title":"Descargando e instalando Apache Hadoop en t\u00f3dolos nodos","text":"<p>No nodo master, descargamos Apache Hadoop da web oficial:</p> <pre><code>curl https://dlcdn.apache.org/hadoop/common/hadoop-3.2.4/hadoop-3.2.4.tar.gz \\\n  --output hadoop-3.2.4.tar.gz\n</code></pre> <p>E copi\u00e1molo ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy hadoop-3.2.4.tar.gz --dest /home/cesgaxuser/\n</code></pre> <p>Descomprimimos en t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \n  tar -xzf hadoop-3.2.4.tar.gz\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#configurando-as-variables-de-contorna-especificas-de-apache-hadoop","title":"Configurando as variables de contorna espec\u00edficas de Apache Hadoop","text":"<p>Metemos no <code>.bashrc</code> ao final as seguintes novas variables da contorna:</p> .bashrc<pre><code>export HADOOP_HOME='/home/cesgaxuser/hadoop-3.2.4'\nexport PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin\n</code></pre> <p>E copiamos o arquivo ao resto de nodos para aplicar a mesma configuraci\u00f3n:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy .bashrc --dest /home/cesgaxuser/\n</code></pre> <p>Pechamos a sesi\u00f3n (Ctrl+D) e volvemos entrar (ou executamos <code>. ./bashrc</code> ou <code>source .bashrc</code> para recargar as variables de entorno).</p> <p>Para comprobar se funciona a instalaci\u00f3n b\u00e1sica e as variables de contorna, podemos escribir o comando:</p> <pre><code>hdfs\n</code></pre> <p>E deber\u00eda devolvernos a axuda do comando.</p>"},{"location":"apache-hadoop-0-instalacion/#configurando-apache-hadoop","title":"Configurando Apache Hadoop","text":"<p>Editamos os arquivos de configuraci\u00f3n seguintes e os deixamos as\u00ed:</p> hadoop-3.2.4/etc/hadoop/core-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;fs.default.name&lt;/name&gt;\n            &lt;value&gt;hdfs://hadoop1:9000&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre> hadoop-3.2.4/etc/hadoop/hdfs-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n            &lt;value&gt;/home/cesgaxuser/data/nameNode&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n            &lt;value&gt;/home/cesgaxuser/data/dataNode&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;dfs.replication&lt;/name&gt;\n            &lt;value&gt;1&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre> hadoop-3.2.4/etc/hadoop/mapred-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n            &lt;value&gt;yarn&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n            &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;\n            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n            &lt;name&gt;mapreduce.map.env&lt;/name&gt;\n            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n            &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;\n            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n        &lt;/property&gt;\n\n    &lt;!-- L\u00edmite de uso de RAM (non po\u00f1er se temos alomenos 8GB por servidor --&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.app.mapreduce.am.resource.mb&lt;/name&gt;\n        &lt;value&gt;512&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;\n        &lt;value&gt;256&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;\n        &lt;value&gt;256&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;/configuration&gt;\n</code></pre> <p>No seguinte arquivo lembra substituir XXX.XXX.XXX.XXX pola IP do nodo master ou mellor polo host: hadoop1:</p> hadoop-3.2.4/etc/hadoop/yarn-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;yarn.acl.enable&lt;/name&gt;\n            &lt;value&gt;0&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n            &lt;value&gt;XXX.XXX.XXX.XXX&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- L\u00edmite de uso de RAM (non po\u00f1er se temos +8GB por servidor --&gt;\n        &lt;property&gt;\n            &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;\n            &lt;value&gt;1536&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;\n            &lt;value&gt;1536&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;\n            &lt;value&gt;128&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;\n            &lt;value&gt;false&lt;/value&gt;\n        &lt;/property&gt;\n\n    &lt;/configuration&gt;\n</code></pre> <p>E tam\u00e9n metemos os nodos que queiramos que fagan de workers no arquivo:</p> hadoop-3.2.4/etc/hadoop/workers<pre><code>hadoop1\nhadoop2\nhadoop3\nhadoop4\n</code></pre> <p>Agora precisamos crear os directorios que almacenar\u00e1n os datos:</p> <pre><code>mkdir -p /home/cesgaxuser/data/nameNode\nmkdir -p /home/cesgaxuser/data/dataNode\n</code></pre> <p>Con esto ter\u00edamos configurado yarn en hadoop1 (master).</p>"},{"location":"apache-hadoop-0-instalacion/#configuracion-do-resto-de-nodos","title":"Configuraci\u00f3n do resto de nodos","text":"<p>Podemos copiar simplemente a configuraci\u00f3n ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy hadoop-3.2.4/etc/hadoop/workers \\\n  hadoop-3.2.4/etc/hadoop/yarn-site.xml \\\n  hadoop-3.2.4/etc/hadoop/mapred-site.xml \\\n  hadoop-3.2.4/etc/hadoop/hdfs-site.xml \\\n  hadoop-3.2.4/etc/hadoop/core-site.xml \\\n  --dest /home/cesgaxuser/hadoop-3.2.4/etc/hadoop\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#formatear-o-hdfs","title":"Formatear o HDFS:","text":"<p>Dende hadoop1 (o nodo master) executamos:</p> <pre><code>hdfs namenode -format\n</code></pre> <p>E finalmente dende o master iniciamos todo o sistema (esto conecta por SSH aos nodos e executa os comandos necesarios para que se po\u00f1an a traballar):</p> <pre><code>start-dfs.sh\nstart-yarn.sh\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#arrancando-apache-hadoop-ao-inicio-con-cron","title":"Arrancando Apache Hadoop ao inicio con cron","text":"<p>Se queremos lanzar o proceso de Apache Hadoop dende cron (por exemplo para facer uso da opci\u00f3n <code>@reboot</code>) deberemos cambiar por si acaso o arquivo: <code>hadoop-3.2.4/etc/hadoop/hadoop-env.sh</code> e mudar as seguintes variables, para non depender do .bashrc do usuario:</p> hadoop-3.2.4/etc/hadoop/hadoop-env.sh<pre><code>    export JAVA_HOME='/usr/lib/jvm/java-11-amazon-corretto/'\n    export HADOOP_HOME='/home/cesgaxuser/hadoop-3.2.4'\n    export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\n    #HADOOP_OPTS=\n</code></pre> <p>Unha vez cambiemos o arquivo, copiar\u00e9molo ao resto de nodos, por coherencia e por manter igual a configuraci\u00f3n en t\u00f3dolos sitios.</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy hadoop-3.2.4/etc/hadoop/hadoop-env.sh \\\n  --dest /home/cesgaxuser/hadoop-3.2.4/etc/hadoop\n</code></pre> <p>Finalmente editaremos o cron do nodo master para indicarlle que arranque Hadoop cando iniciemos a m\u00e1quina:</p> <p>(importante: Se non queres empregar vi, establece a variable <code>EDITOR=nano</code> se o tes instalado)</p> <pre><code>crontab -e\n</code></pre> <p>E metemos no arquivo o seguinte contido:</p> <pre><code>@reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-dfs.sh\n@reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-yarn.sh\n</code></pre> <p>Por \u00faltimo reiniciamos t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] sudo reboot\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#comprobando-que-funciona","title":"Comprobando que funciona","text":"<p>Para obter informaci\u00f3n do HDFS, podemos empregar o comando:</p> <pre><code>hdfs dfsadmin -report\n</code></pre> <p>Queda iniciar yarn.</p>"},{"location":"apache-hadoop-0-instalacion/#bibliografia","title":"Bibliograf\u00eda","text":"<p>Podes atopar m\u00e1is informaci\u00f3n:</p> <ul> <li>https://www.linode.com/docs/guides/how-to-install-and-set-up-hadoop-cluster/</li> <li>https://sparkbyexamples.com/spark/spark-setup-on-hadoop-yarn/</li> <li>https://www.linode.com/docs/guides/install-configure-run-spark-on-top-of-hadoop-yarn-cluster/</li> <li>https://www.tutorialspoint.com/es/hadoop/hadoop_multi_node_cluster.htm</li> <li>https://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</li> </ul>"},{"location":"apache-hadoop-0-instalacion/#copyright","title":"Copyright","text":"<p>\u00a9 2023 - Jose S\u00e1nchez</p> <p>Se atopas erros, agradecerei que me env\u00edes un email/mensaxe co aviso ou as correcci\u00f3ns.</p>"},{"location":"apache-hadoop-1-comandos/","title":"\ud83d\udc18 Apache Hadoop \u2014 \ud83d\udd32 Comandos","text":"<p>Apache Hadoop, \u00e9 un framework que permite o procesamento distribuido de grande volume de datos sobre cl\u00fasteres de computadoras empregando modelos sinxelos de programaci\u00f3n.</p> <p>O HDFS ou Hadoop Distributed File System \u00e9 un sistema de arquivos distribu\u00eddo empregado por Apache Hadoop que espalla os datos polos distintos discos dos servidores que forman o cl\u00faster de Hadoop.</p> <ul> <li> <p>Os arquivos grandes div\u00eddense en bloques (blocks) por defecto de 128 MiB.</p> </li> <li> <p>De cada bloque hai varias copias, o n\u00famero exacto establ\u00e9ceo o factor de replicaci\u00f3n (replication factor) por defecto 3.</p> </li> </ul>"},{"location":"apache-hadoop-1-comandos/#onde-estan-os-meus-datos","title":"Onde est\u00e1n os meus datos?","text":"<p>A primeira pregunta que debemos facernos \u00e9: Onde est\u00e1n os meus datos?</p> <ul> <li>No $HOME do teu usuario -&gt; /home/subdirs-opcionais/usuario.</li> <li>No HOME do servidor de HADOOP -&gt; /user/usuario.</li> </ul> <p>A variable $HOME normalmente fai referencia ao teu cartafol persoal. Este adoita estar en /home/usuario ou en /home/algo/mais/usuario. Estes son os arquivos aos que accedes normalmente.</p> <p>O HOME de Hadoop normalmente estar\u00e1 en: /user/usuario e para acceder a \u00e9l debes empregar o comando hdfs ou ben API ou programas que se relacionen con Hadoop. A URL de acceso ao arquivo ten o formato: hdfs://nameservice1/user/usuario/arquivo.</p>"},{"location":"apache-hadoop-1-comandos/#interactuando-co-sistema-de-arquivos","title":"Interactuando co sistema de arquivos","text":"<p>O programa hdfs danos unha interfaz e operaci\u00f3ns \u00fatiles para acceder ao HDFS de Hadoop. Os comandos seguen unha sintaxe de tipo:</p> <pre><code>hdfs dfs -COMANDO # (1)!\n</code></pre> <ol> <li>dfs: Indica que a operaci\u00f3n \u00e9 de arquivos sobre o sistema de arquivos.</li> </ol> <p>Os comandos habituais son:</p>"},{"location":"apache-hadoop-1-comandos/#ver-arquivos-e-directorios","title":"Ver arquivos e directorios","text":"<p>Ver arquivos no noso HOME de HDFS. Imos ver adem\u00e1is as distintas rutas: relativas, absolutas e completas.</p> <pre><code>hdfs dfs -ls\n</code></pre> <p>Ver arquivos que hai en \"directorio\" que \u00e9 un directorio que est\u00e1 no noso HOME de HDFS:</p> <pre><code>hdfs dfs -ls directorio\n</code></pre> <p>O mesmo que o anterior pero empregando unha ruta absoluta:</p> <pre><code>hdfs dfs -ls /user/usuario/directorio\n</code></pre> <p>O mesmo que o anterior pero empregando a ruta absoluta e completa do HDFS:</p> <pre><code>hdfs dfs -ls hdfs://nameservice1/user/usuario/directorio\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#transferindo-datos-entre-o-hdfs-e-o-almacenamento-local","title":"Transferindo datos entre o HDFS e o almacenamento local","text":"<p>\ud83d\udd3c Subir/Enviar o ARQUIVO_LOCAL que est\u00e1 no noso $HOME (\"o noso disco duro\") a un directorio de HDFS chamado \"DIRECTORIO_HDFS\":</p> <pre><code>hdfs dfs -put ARQUIVO_LOCAL DIRECTORIO_HDFS\n</code></pre> <p>\ud83d\udd3d Baixar/Descargar/Recibir do HDFS (\"cl\u00faster de Hadoop\") o arquivo ao noso almacenamento local (\"disco duro\"):</p> <pre><code>hdfs dfs -get arquivo-do-hdfs.txt\n</code></pre> <p>Amosar un arquivo do HDFS por consola en modo texto. Adem\u00e1is admite o formato ZIP e TextRecordInputStream:</p> <pre><code>hdfs dfs -text arquivo.zip\nhdfs dfs -text arquivo.txt\n</code></pre> <p>Amosar un arquivo do HDFS por consola, danos igual o formato no que estea:</p> <pre><code>hdfs dfs -cat arquivo-calquera.xyz\n</code></pre> <p>Ver o inicio do arquivo (cabeceira) empregando pipes:</p> <pre><code>hdfs dfs -cat arquivo-moi-grande.csv|head\n</code></pre> <p>Amosar a cola (o final) do arquivo. \u00datil para comprobar se est\u00e1 ben recibido e o formato.</p> <pre><code>hdfs dfs -tail arquivo-longo.csv\n</code></pre> <p>Copiar un arquivo dentro do HDFS (de HDFS a HDFS)</p> <pre><code>hdfs dfs -cp ARQUIVO_ORIXE ARQUIVO_DESTINO\n</code></pre> <p>Mover un arquivo dentro do HDFS (de HDFS a HDFS)</p> <p><pre><code>hdfs dfs -mv ARQUIVO_ORIXE ARQUIVO_DESTINO\n</code></pre> Borrar un arquivo do HDFS</p> <pre><code>hdfs dfs -rm arquivo.txt\n</code></pre> <p>Resultado:</p> <pre><code>25/02/08 16:39:19 INFO fs.TrashPolicyDefault: Moved: 'hdfs://nameservice1/user/usuario/arquivo.txt' to trash at: hdfs://nameservice1/user/usuario/.Trash/Current/user/usuario/arquivo.txt\n</code></pre> <p>Borrar un arquivo do HDFS evitando a papeleira (skipTrash):</p> <pre><code>hdfs dfs -rm -skipTrash arquivo.txt\n</code></pre> <p>Resultado: <pre><code>Deleted arquivo.txt\n</code></pre></p>"},{"location":"apache-hadoop-1-comandos/#mudando-de-usuario-grupo-e-permisos","title":"Mudando de usuario, grupo e permisos","text":"<p>Seguindo a m\u00e1scara de permisos UGO podemos mudar os permisos dun arquivo ou dun directorio de forma recursiva (-R):</p> <pre><code>hdfs dfs -chmod 765 ficheiro\n</code></pre> <pre><code>hdfs dfs -chmod -R 755 meudir\n</code></pre> <p>Tam\u00e9n podemos mudar o propietario e o grupo do ficheiro (tam\u00e9n admite -R para directorios):</p> <pre><code>hdfs dfs -chown hadoop:hadoop ficheiro123.txt\n</code></pre> <p>Ou mudar solo o grupo:</p> <pre><code>hdfs dfs -chgrp hadoop ficheiro321.txt\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#e-cuestion-de-espazo","title":"\u00c9 cuesti\u00f3n de espazo","text":"<p>Medir o espazo consumido non sempre \u00e9 directo. Se preguntamos canto oucpa un arquivo:</p> <pre><code>dfs dfs -du -h -s 100MB.zip\n</code></pre> <p>Veremos dous tama\u00f1os: Tama\u00f1o do arquivo e o espazo en disco consumido.</p> <pre><code>100 M  300 M  100MB.zip\n</code></pre> <p>O tama\u00f1o en disco consumido p\u00f3dese calcular como o resultado de multiplicar o tama\u00f1o do arquivo polo factor de replicaci\u00f3n. Pode haber diferencias debidas ao tama\u00f1o de bloque, sobre todo con tama\u00f1os de bloque grandes.</p> <p>Consultar o espazo libre dispo\u00f1ible:</p> <pre><code>hdfs dfs -df -h\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#outros-comandos-utiles-probar","title":"Outros comandos \u00fatiles (probar):","text":"<p>Engadir (concatenar) o contido de <code>ventas-diarias-hoxe-LOCAL.txt</code> que est\u00e1 no almacenamento local (disco duro local ou $HOME) ao arquivo do HDFS <code>ventas-HDFS.txt</code></p> <pre><code>hdfs dfs -appendToFile ventas-diarias-hoxe-LOCAL.txt ventas-HDFS.txt\n</code></pre> <p>Descargar a local ao arquivo <code>ventas-local.txt</code> o resultado da concatenaci\u00f3n dos arquivos do HDFS: <code>ventas-HDFS-part1.txt</code> e <code>ventas-HDFS-part2.txt</code>.</p> <pre><code>hdfs dfs -getmerge -nl ventas-HDFS-part1.txt ventas-HDFS-part2.txt ventas-local.txt\n</code></pre> <p>Xerar un checksum dos datos para comprobar se est\u00e1n ben (empr\u00e9gase MD5, non est\u00e1 pensado para modificaci\u00f3ns maliciosas dos datos, sen\u00f3n para cambios accidentais)</p> <pre><code>hdfs dfs -checksum ventas-HDFS.txt\n</code></pre> <p>Mudar o factor de replicaci\u00f3n dun arquivo ou dun directorio:</p> <pre><code>hadoop fs -setrep -w 3 100MB.zip\nhadoop fs -setrep -w 3 -R /user/usuario/directorio\n</code></pre> <p>C\u00f3mo se comproba que mudou. D\u00faas maneiras:</p> <p>Con ls, o n\u00famero antes de usuario \u00e9 o factor de replicaci\u00f3n:</p> <pre><code>-rw-r--r--   **4** usuario grupo  104857600 2025-01-29 22:00 100MB.zip\n</code></pre> <p>Con du mirando que sube o espacio ocupado en disco:</p> <pre><code>hdfs dfs -du -h -s 100MB.zip\n</code></pre> <p>Vemos que:</p> <pre><code>100 M  400 M  100MB.zip\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#arquivos-de-configuracion","title":"Arquivos de configuraci\u00f3n","text":""},{"location":"apache-hadoop-1-comandos/#hdfs-sitexml-tamano-de-bloque","title":"hdfs-site.xml. Tama\u00f1o de bloque","text":"<p>Cada arquivo div\u00eddese en bloques (m\u00ednimo 1 bloque por arquivo) de por defecto 128 MiB.</p> <pre><code>&lt;property&gt;\n&lt;name&gt;dfs.block.size&lt;/name&gt;\n&lt;value&gt;134217728&lt;/value&gt;\n&lt;property&gt;\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#hdfs-sitexml-factor-de-replicacion","title":"hdfs-site.xml. Factor de replicaci\u00f3n","text":"<p>O n\u00famero de copias de cada bloque, por defecto 3.</p> <pre><code>&lt;property&gt;\n&lt;name&gt;dfs.replication&lt;/name&gt;\n&lt;value&gt;3&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://bigdata.cesga.es/tutorials/hdfs.html</li> </ul> <p>Se empregas os recursos do CESGA, lembra que dende a casa debes conectarte \u00e1 VPN antes de conectarte por SSH ao servidor hadoop.cesga.es.</p>"},{"location":"apache-hadoop-2-cuentapalabras/","title":"\ud83d\udc18 Apache Hadoop \u2014 \ud83e\uddee Exemplo contapalabras","text":"<p>Imos empregar o .jar de exemplo para demostrar a operaci\u00f3n de mapreduce contando palabras sobre un arquivo presente no HDFS.</p> <p>Este arquivo .jar de exemplo pod\u00e9molo executar directamente en Apache Hadoop:</p> <ul> <li><code>/opt/cloudera/parcels/CDH-6.1.1-1.cdh6.1.1.p0.875250/jars/hadoop-mapreduce-examples-3.0.0-cdh6.1.1.jar</code></li> </ul> <p>Preparando o contorno</p> <ol> <li> <p>Creamos un arquivo coa lista da compra:</p> $HOME/lista_compra.txt<pre><code>echo \"Ovos, leite, pan, pan, ovos, aceite, sal, ovos, leite, carne, peixe, fari\u00f1a, pan raiao, ovos, leite fari\u00f1a.\" &gt; lista_compra.txt\n</code></pre> </li> <li> <p>Creamos o directorio <code>compras</code> no HDFS e subimos o arquivo ese directorio:     <pre><code>hdfs dfs -mkdir compras\nhdfs dfs -put lista_compra.txt compras/\n</code></pre></p> </li> <li> <p>Comprobamos que temos subido correctamente o arquivo:     <pre><code>hdfs dfs -ls compras\n</code></pre></p> </li> <li> <p>Executamos o comando <code>yarn jar</code> con estes par\u00e1metros:     <pre><code>yarn jar \\\n    /opt/cloudera/parcels/CDH-6.1.1-1.cdh6.1.1.p0.875250/jars/hadoop-mapreduce-examples-3.0.0-cdh6.1.1.jar \\\n    wordcount compras resumo_compras\n</code></pre></p> </li> </ol> <p>Deber\u00eda terse creado en <code>resumo_contas</code> o conteo de palabras dos arquivos que estivesen dentro do directorio <code>compras</code>.</p>"},{"location":"apache-kafka-0-instalacion-docker/","title":"\u27bf Apache Kafka \u2014 \ud83d\udc33 Instalaci\u00f3n","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/r/apache/kafka</li> </ul>"},{"location":"apache-kafka-0-instalacion-docker/#crear-o-contedor","title":"Crear o contedor","text":"<p>Lanzamos un novo contedor brokerkafkiano que escoita no porto 9092.</p> <pre><code>docker run -d  \\\n  --name brokerkafkiano \\\n  --hostname brokerkafkiano.local \\\n  -p 9092:9092 -p 9093:9093 \\\n  -e KAFKA_NODE_ID=1 \\\n  -e KAFKA_PROCESS_ROLES=broker,controller \\\n  -e KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \\\n  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://brokerkafkiano.local:9092 \\\n  -e KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER \\\n  -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \\\n  -e KAFKA_CONTROLLER_QUORUM_VOTERS=1@brokerkafkiano.local:9093 \\\n  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \\\n  -e KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 \\\n  -e KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 \\\n  -e KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0 \\\n  -e KAFKA_NUM_PARTITIONS=3 \\\n  --restart unless-stopped \\\n  apache/kafka:latest\n</code></pre> <p>\u26a0\ufe0f O nome brokerkafkiano.local deber\u00eda ser cambiado por un nome DNS ou nome presente no <code>etc/hosts</code> que se resolvese ben dende t\u00f3dolos sitios que conecten con Kafka.</p>"},{"location":"apache-kafka-0-instalacion-docker/#crear-un-topic","title":"Crear un topic","text":"<p>Empregando o script <code>kafka-topics.sh</code> crearemos o topic (tema) metamorfosis.</p> <pre><code>docker exec -it brokerkafkiano \\\n  /opt/kafka/bin/kafka-topics.sh \\\n  --bootstrap-server brokerkafkiano.local:9092 \\\n  --create --topic metamorfosis\n</code></pre>"},{"location":"apache-kafka-0-instalacion-docker/#escribir-mensaxes-ao-topic-produtor","title":"Escribir mensaxes ao topic (produtor)","text":"<p>Imos escribir unha serie de mensaxes no produtor, a\u00ednda que ningu\u00e9n estea suscrito ao topic consumindo estes datos. Para lanzar un produtor (enviar datos a Kafka) empregamos o producer de consola de dentro do contedor:</p> <p><pre><code>docker exec -it brokerkafkiano \\\n    /opt/kafka/bin/kafka-console-producer.sh \\\n    --bootstrap-server brokerkafkiano.local:9092 \\\n    --topic metamorfosis\n</code></pre> Agora poderemos escribir alg\u00fans textos, por exemplo:</p> <pre><code>Hola Mundo!\nClave=Valor\n1234567890\nabc\n</code></pre> <p>Se queremos sair da consola, premeremos Ctrl+C.</p>"},{"location":"apache-kafka-0-instalacion-docker/#recibir-mensaxes-do-topic-consumidor","title":"Recibir mensaxes do topic (consumidor)","text":"<p>Os datos anteriores seguen en Kafka e podemos ter acceso ao topic dende o inicio do mesmo:</p> <pre><code>docker exec --interactive -it brokerkafkiano \\\n    /opt/kafka/bin/kafka-console-consumer.sh \\\n    --bootstrap-server brokerkafkiano.local:9092 \\\n    --topic metamorfosis \\\n    --from-beginning\n</code></pre> <p>Se deixamos aberta esta consola e noutra lanzamos un produtor que env\u00ede datos ao metamorfosis, deber\u00edan reflectirse nesta primeira consola en pouco tempo.</p>"},{"location":"apache-kafka-0-instalacion-docker/#ligazons-a-mais-informacion","title":"Ligaz\u00f3ns a m\u00e1is informaci\u00f3n","text":""},{"location":"apache-kafka-0-instalacion-docker/#descargas-oficiais-do-software","title":"Descargas oficiais do software","text":"<ul> <li>http://kafka.apache.org</li> <li>https://hub.docker.com/r/apache/kafka</li> </ul>"},{"location":"apache-kafka-0-instalacion-docker/#configuracion-de-autenticacion-e-cifrado","title":"Configuraci\u00f3n de autenticaci\u00f3n e cifrado","text":"<ul> <li>https://kafka.apache.org/documentation/#security_authz</li> <li>Titorial (non probado): https://www.baeldung.com/ops/kafka-authentication-topics-sh</li> </ul>"},{"location":"apache-kafka-1-conceptos-basicos/","title":"\u27bf Apache Kafka \u2014 \ud83d\udc1c\ufe0f Conceptos b\u00e1sicos","text":"<p>Apacha Kafka \u00e9 unha plataforma distribuida en tempo real para streaming de datos. Foi desenvolvida por Linkedin e posteriormente donada \u00e1 Apache Software Foundation. Est\u00e1 escrito en Java e Scala.</p> <p>Imaxina un servidor de IRC ou de discord pero para aplicaci\u00f3ns. Hay temas (ou canles) dos que queres falar e cada aplicaci\u00f3n pode enviar ou ler mensaxes, sen que se perdan.</p> <p>Se ves do mundo dos microservicios, sonarache o protocolo MQTT: Message Queue Telemetry Transport. Este esquema segue un sistema de publicaci\u00f3n \u2194 suscripci\u00f3n moi parecido ao de Apache Kafka. MQTT \u00e9 un protocolo cunha especificaci\u00f3n para a capa de transporte m\u00e1is non o contido o u como funciona a aplicaci\u00f3n. Os programas con soporte MQTT deber\u00edan ser compatibles entre si, por exemplo:</p> <ul> <li>https://www.rabbitmq.com/</li> <li>https://mosquitto.org/</li> <li>https://joram.ow2.io/</li> </ul> <p>Nestes sistemas, a\u00ednda que se pode producir/consumir mensaxes a distintas velocidades, poder\u00eda chegarse a perder algunha. Est\u00e1 pensado m\u00e1is para a inxesta en tempo real.</p> <p>En Kafka non se perden mensaxes, xa que se persisten (gardan) por eso as veces, algunhas persoas consid\u00e9rano como unha base de datos por algunhas das s\u00faas caracter\u00edsticas de persistencia, recuperaci\u00f3n de datos, particionamento, etc.</p> <p>Por outra banda, Apache Kafka est\u00e1 dese\u00f1ado para ser depregado como un cluster de varios nodos, fortalecendo as\u00ed a s\u00faa estabilidade. Emprega o seu propio protocolo de rede, polo que non ten porqu\u00e9 ser compatible con MQTT de xeito directo (a\u00ednda que existen conectores e implementaci\u00f3ns para conseguir esta compatibilidade).</p> <p>A vantaxe de Apache Kafka radica na s\u00faa estabilidade xa que \u00e9 un sistema que pode estar distribuido e replicado.</p> <p></p> <p>Apache Kafka emprega un commit log distribuido</p>"},{"location":"apache-kafka-1-conceptos-basicos/#broker","title":"Broker","text":"<p>Un cluster est\u00e1 formado por varios brokers de Kafka que se comunican entre si empregando Zookeeper.</p> <p>Aos servidores de Kafka dun cluster se lles chama Brokers.</p> <p>Cada broker ten topics e recibe e garda as mensaxes dos produtores e tam\u00e9n permite aos consumidores recoller as mensaxes.</p> <p>Para o proceso de descubrimento, o cliente (produtor ou consumidor) debe poder resolver por DNS alomenos un broker de kafka (tam\u00e9n chamado bootstrap server). Unha vez se conecta a un servidor, recibir\u00e1 a informaci\u00f3n de como conectar ao cluster enteiro. Ollo, o resto de hosts dos bootstrap servers deben poder resolverse tam\u00e9n.</p>"},{"location":"apache-kafka-1-conceptos-basicos/#produtor","title":"Produtor","text":"<p>Os produtores mandan mensaxes aos topics, estes mensaxes escr\u00edbense nunha partici\u00f3n. As mensaxes poden ser enviadas as\u00edncronamente.</p> <p>Os productores deben recuperarse autom\u00e1ticamente en caso de fallos no broker e deben decidir a que broker escribir. Sempre hai un l\u00edder para un topic/partici\u00f3n dado e se falla, outro cunha r\u00e9plica toma o control.</p>"},{"location":"apache-kafka-1-conceptos-basicos/#consumidor","title":"Consumidor","text":"<p>Len as mensaxes dos topics/temas/canles. </p> <p>Deben manter un rexistro da partici\u00f3n e do offset porque os brokers de Kafka non te\u00f1en estado (stateless).</p> <p>Debido a esto poden rebobinar ou saltar a calquera punto nunha partici\u00f3n. Deben recuperarse autom\u00e1ticamente no caso de fallos no broker.</p> <p>Grupos de consumidores</p> <ul> <li>Un conxunto de varios consumidores coordinados para consumir os datos xuntos do mesmo topic.</li> </ul> <p>Que ocorre cando se presenta un fallo na recuperaci\u00f3n?</p> <ul> <li>Se un consumidor morre, ser\u00e1 capaz de ler hacia atr\u00e1s dende onde o deixou, empregando o offset e a partici\u00f3n que ter\u00e1 almacenados.</li> <li>O grupo de consumidores debe rebalancearse autom\u00e1ticamente no caso que un consumidor do grupo morra ou se son engadidos novos consumidores.</li> </ul>"},{"location":"apache-kafka-1-conceptos-basicos/#topictemas","title":"Topic/Temas","text":"<p>Un topic \u00e9 como unha canle de informaci\u00f3n \u00e1 que nos podemos unir para producir/consumir (enviar/recibir) mensaxes. Algo as\u00ed como unha sorte de canle dun IRC ou de discord.</p> <p>As mensaxes que chegan aos topics forman o \"data stream\" e g\u00e1rdanse como clave/valor. \u00c1s mensaxes tam\u00e9n se lles pode chamar rexistros (records).</p> <p>Datos que hai nunha mensaxe:</p> <ul> <li>Key: Chave (pode estar vac\u00eda).</li> <li>Value: Valor (pode estar vac\u00edo).</li> <li>Tipo de compresi\u00f3n: Ninguha, GZIP, snappy \u2192 Google, ideas de LZ77.</li> <li>Cabeceira (opcional).</li> <li>Partici\u00f3n e offset.</li> <li>Timestamp (marca de tempo).</li> </ul> <p>Kafka sabe en que estado est\u00e1 cada consumidor e lle vai enviando as mensaxes.</p> <p>As mensaxes son inmutables, unha vez se escriben a unha partici\u00f3n, non poden cambiar.</p> <p>Poden conter calquer tipo de datos (almac\u00e9nase en formato binario) polo que deberemos serializalos/deserializalos correctamente (codificalos/descodificalos).</p> <p>\u26a0\ufe0f Non reinventes a roda! Hai librar\u00edas que fan todo o traballo de serializaci\u00f3n/deserializaci\u00f3n por nos para os formatos que m\u00e1is se soen empregar con Kafka: JSON e Avro.</p> <p>Un consumidor pode unirse a un t\u00f3pico (canle) para recibir o seu \"data stream\".</p> <p>Debido a arquitectura de alta dispo\u00f1ibilidade de Kafka, cada topic ten un factor de replicaci\u00f3n ou Replication Factor (idealmente maior a 1). Cada r\u00e9plica \u00e9 id\u00e9ntica byte a byte. Se un broker cae, outro broker que ten a r\u00e9plica dos datos pode pasar a servila.</p> <p>O c\u00f3digo empregado nos produtores e consumidores deber\u00eda ter en conta a propiedade da idempotencia (se recibes a mesma mensaxe duplicada, detectala ou que non afecte).</p>"},{"location":"apache-kafka-1-conceptos-basicos/#particions","title":"Partici\u00f3ns","text":"<p>Os topics div\u00eddense en diferentes partici\u00f3ns, cada partici\u00f3n toma a forma dun commit log estruturado.</p> <p>Est\u00e1 ordeada, \u00e9 inmutable e as mensaxes eng\u00e1dense ao final. Unha partici\u00f3n non se pode dividir entre dous ou m\u00e1is brokers ou discos, crear\u00edase unha nova a continuaci\u00f3n.</p> <p>Offset</p> <p>As mensaxes de cada partici\u00f3n te\u00f1en un n\u00famero secuencial asignado chamado offset que indenficia de forma un\u00edvoca cada mensaxe dentro dunha partici\u00f3n (o n\u00famero \u00e9 \u00fanico dentro da partici\u00f3n).</p> <p>L\u00edder da partici\u00f3n</p> <p>Para cada partici\u00f3n so un broker pode actuar como l\u00edder nesa partici\u00f3n, o resto poden replicar os datos e son ISR (in-sync replicas).</p> <p>Os produtores so poden enviar os datos ao broker que sexa o l\u00edder desa partici\u00f3n, mentres que os consumidores por defecto ler\u00e1n o dato tam\u00e9n do l\u00edder (a\u00ednda que dende a versi\u00f3n 2.4 de Kafka, poden lelo de calquera r\u00e9plica sincronizada).</p> <p>Se cae un l\u00edder, unha das r\u00e9plicas que te\u00f1a unha copia sincronizada dos datos, toma o papel de l\u00edder.</p>"},{"location":"apache-kafka-1-conceptos-basicos/#zookeeper","title":"Zookeeper","text":"<p>\u00c9 un servidor de c\u00f3digo fonte aberto que permite a coordinaci\u00f3n distribuida. Baseado no algorimo de consenso Paxos.</p> <p>Manten datos de configuraci\u00f3n e segue a relaci\u00f3n de l\u00edder-seguidor (leader/follower) ao longo de t\u00f3dalas partici\u00f3ns.</p> <p>En canto \u00e1s versi\u00f3n de Kafka e Zookeeper:</p> <ul> <li>Versi\u00f3ns inferiores e iguais a 2.x precisan Zookeeper de xeito obrigatorio.</li> <li>Versi\u00f3ns 3.x e maiores poden funcionar sen Zookeeper (empregando Kafka Raft/KRaft).</li> <li>A partires da versi\u00f3n 3.3 KRaft consid\u00e9rase estable e v\u00e1lido para contornos de produci\u00f3n.</li> <li>A partires da versi\u00f3n 4.0 est\u00e1 planeado eliminar ZooKeeper.</li> </ul> <p>Mant\u00e9n a lista de brokers no cluster, axuda a elixir o l\u00edder de cada partici\u00f3n e env\u00eda as notificaci\u00f3ns a Kafka no caso de cambios (un broker morre, b\u00f3rrase un topic, cr\u00e9ase un topic, lev\u00e1ntase un broker...)</p> <p>Os offsets non se gardan en Zookeper dende a versi\u00f3n 0.10 de Kafka, agora son os consumidores os que gardan estes offsets en Kafka, nun topic chamado __consumer__offsets.</p> <p>Polo tanto, cando un consumidor morre, poder\u00e1 ler este topic e recuperarse xusto dende onde deixou a lectura.</p>"},{"location":"apache-kafka-1-conceptos-basicos/#cousas-da-entrega-e-outras-caracteristicas","title":"Cousas da entrega e outras caracter\u00edsticas","text":"<p>Acuses de recibo / Confirmaci\u00f3ns (ACK \u2014 Acknowledgement)</p> <p>Os produtores poden pedir recibir confirmaci\u00f3ns das escrituras.</p> <ul> <li>acks=0. O produtor non espera e poder\u00edan perderse datos</li> <li>acks=1. O produtor espera pola confirmaci\u00f3n do l\u00edder (p\u00e9rdida espor\u00e1dica de datos cando cae o l\u00edder e non hai copias confirmadas).</li> <li>acks=todas. O produtor espera pola confirmaci\u00f3n do l\u00edder e das r\u00e9plicas co que idealmente non haber\u00eda posbilidade de perda de datos.</li> </ul> <p>Un produtor pode mandar unha \"key\" coa mensaxe de xeito que mensaxes coa misma \"key\" vaia \u00e1 mesma partici\u00f3n. Se esta \"key\" \u00e9 null, ent\u00f3n os datos mandaranse cun algoritmo de Round Robin entre as partici\u00f3ns.</p> <p>As mensaxes da mesma partici\u00f3n mant\u00e9\u00f1ense en orde porque se le en orde de menor a maior offset.</p> <p>Esta orde non se mant\u00e9n entre partici\u00f3ns (offsets repetidos en diferentes partici\u00f3ns, non na mesma) polo que se queremos todas as mensaxes ordenadas, deberemos empregar un topic cunha soa partici\u00f3n.</p>"},{"location":"apache-kafka-1-conceptos-basicos/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://www.confluent.io/resources/kafka-the-definitive-guide/</li> <li>https://github.com/javicacheiro/pyspark_course/blob/master/supplementary/kafka/</li> </ul>"},{"location":"apache-kafka-2-python/","title":"\u27bf Apache Kafka \u2014 \ud83d\udc0d Python","text":""},{"location":"apache-kafka-2-python/#traballando-en-python-con-apache-kafka","title":"Traballando en Python con Apache Kafka","text":""},{"location":"apache-kafka-2-python/#instalacion-de-paquetes","title":"Instalaci\u00f3n de paquetes","text":"<ol> <li> <p>Instalamos os dous m\u00f3dulos, kafka-python \u00e9 un m\u00f3dulo m\u00e1is simple mentres que o de confluent ten </p> <pre><code>conda install -c conda-forge kafka-python python-confluent-kafka\n</code></pre> </li> <li> <p>Sigue o notebook do repositorio.</p> </li> </ol>"},{"location":"apache-kafka-2-python/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":""},{"location":"apache-kafka-2-python/#librarias-de-conexion-en-python","title":"Librar\u00edas de conexi\u00f3n en Python","text":"<ul> <li>https://github.com/dpkp/kafka-python</li> <li>https://github.com/confluentinc/confluent-kafka-python</li> </ul>"},{"location":"apache-kafka-2-python/#outros","title":"Outros","text":"<ul> <li>https://developer.confluent.io/get-started/python</li> <li>https://github.com/javicacheiro/pyspark_course/blob/master/supplementary/kafka/</li> <li>https://aitor-medrano.github.io/iabd/dataflow/kafka1.html</li> </ul>"},{"location":"apache-kafka-3-spark/","title":"\u27bf Apache Kafka \u2014 \u269d Spark","text":""},{"location":"apache-kafka-3-spark/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://github.com/javicacheiro/pyspark_course/blob/master/supplementary/kafka/unit_5_spark_integration.md</li> </ul>"},{"location":"apache-kafka-4-nifi/","title":"\u27bf Apache Kafka \u2014 \ud83d\udca7 Nifi","text":"<p>Existen dous procesadores:</p> <ul> <li> <p>ConsumerKafka. Permite recibir datos. Na lapela Properties:</p> <ul> <li>Crear un novo Kafka Connection Service (se non existe)</li> <li>Group ID: 1</li> <li>Topics: metamorfosis</li> </ul> </li> <li> <p>ProducerKafka: Permite enviar datos. Na lapela Properties:</p> <ul> <li>Crear un novo Kafka Connection Service (se non existe)</li> <li>Topic Name: metamorfosis</li> </ul> </li> </ul> <p>Ambos precisan dun:</p> <ul> <li>KafkaConnectionService. Na lapela Properties debemos mudar:<ul> <li>Bootstrap servers: O nome DNS/host do servidor de Kafka. \u26a0\ufe0f Ollo, se ese nome \u00e9 localhost e est\u00e1s noutro host, tratar\u00e1 de conectarse a onde est\u00e1s.</li> </ul> </li> </ul>"},{"location":"apache-nifi-0-instalacion-manual/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83e\uddfe Instalaci\u00f3n manual","text":"<p>Esta instalaci\u00f3n \u00e9 xen\u00e9rica para case calquera distribuci\u00f3n de GNU/Linux. Recom\u00e9ndase empregar o docker por ser m\u00e1is c\u00f3modo e r\u00e1pido.</p>"},{"location":"apache-nifi-0-instalacion-manual/#descarga-verificacion-e-outras-operacions","title":"Descarga, verificaci\u00f3n e outras operaci\u00f3ns","text":"<p>\u26a0\ufe0f AVISO: Dependendo da versi\u00f3n de Apache Nifi precisaremos como m\u00ednimo unha determinada versi\u00f3n de Java (OpenJDK/Amazon Corretto):</p> <ul> <li>Versi\u00f3n 11 para Apache Nifi v1.2.x.</li> <li>Versi\u00f3n 23 para Apache Nifi v2.4.x.</li> </ul> <p>A explicaci\u00f3n \u00e9 para instalar a versi\u00f3n de Apache Nifi 1.24.0, se queres baixar outra versi\u00f3n mira a p\u00e1xina de descargas: https://nifi.apache.org/download/.</p> <ol> <li> <p>Sigue as instrucci\u00f3ns para instalar Amazon Corretto.</p> </li> <li> <p>Descargamos Apache Nifi 1.24.0 e o seu arquivo de firma (asc):</p> <pre><code>wget https://dlcdn.apache.org/nifi/1.24.0/nifi-1.24.0-bin.zip --no-check-certificate\nwget https://dlcdn.apache.org/nifi/1.24.0/nifi-1.24.0-bin.zip.asc --no-check-certificate\n</code></pre> </li> <li> <p>Comprobar a firma (e por tanto a integridade do arquivo e que non foi alterado) \u00e9 unha boa pr\u00e1ctica, as\u00ed que primeiro baixamos a chave SSH coa que foi firmado o arquivo:</p> <pre><code>gpg --keyserver pgpkeys.mit.edu --recv-key 0C07C6D5\n</code></pre> </li> <li> <p>E verificamos que coincide:</p> <pre><code>gpg --verify nifi-1.24.0-bin.zip.asc nifi-1.24.0-bin.zip\n</code></pre> <p>Se todo coincide dir\u00e1 \"Good signature from ...\". En caso de non coincidir a sinatura, debemos comprobar de novo os arquivos, volvelos baixar, revisar o sitio oficial e buscar outra descarga, etc.</p> </li> <li> <p>Descomprimimos Apache Nifi e movemos Apache Nifi dentro do directorio bin que temos creado:</p> <pre><code>unzip nifi-1.24.0-bin.zip\nmv nifi-1.24.0 bin/\n</code></pre> </li> <li> <p>Finalmente facemos un pouco de limpieza:</p> <pre><code>rm nifi-1.24.0-bin.zip nifi-1.24.0-bin.zip.asc\n</code></pre> </li> </ol>"},{"location":"apache-nifi-0-instalacion-manual/#configuracion","title":"Configuraci\u00f3n","text":"<p>Debemos configurar Apache Nifi. Precisamos mudar dous arquivos:</p> <ul> <li><code>bin/nifi-env.sh</code></li> <li><code>conf/nifi.properties</code></li> </ul> <p>Editamos primeiro <code>nifi-env.sh</code>:</p> <pre><code>nano $HOME/bin/nifi-1.24.0/bin/nifi-env.sh\n</code></pre> <p>Teremos que indicarlle que m\u00e1quina de Java coller (descomentamos se fai falta o JAVA_HOME e po\u00f1\u00e9molo como segue):</p> $HOME/bin/nifi-1.24.0/bin/nifi-env.sh<pre><code>export JAVA_HOME=\"$HOME/bin/amazon-corretto-latest/\"\n</code></pre> <p>Agora debemos configurar no arquivo <code>nifi.properties</code> o porto https, a IP na que vai a escoitar e o interfaz por defecto. Por defecto Apache Nifi abre un porto de xesti\u00f3n aleatorio, m\u00e1is non abre o porto para a interfaz web.</p> <p>A instalaci\u00f3n \u00e9 dependente da IP do nodo de login, polo que debemos consultala. A que se pon aqu\u00ed dase como exemplo e debes mirar a t\u00faa.</p> <p>Miramos a ip co comando <code>ifconfig</code>, en concreto inter\u00e9sanos a IPv4 (tam\u00e9n podemos ver as IP con <code>hostname -I</code>):</p> <pre><code>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 9000\n        inet 10.10.10.101  netmask 255.0.0.0  broadcast 0.0.0.0\n        inet6 fe80::0001:0203:0405:0001  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 00:01:02:03:04:05  txqueuelen 1000  (Ethernet)\n        RX packets 324227052  bytes 234877693356 (218.7 GiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 242422788  bytes 830555348369 (773.5 GiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n</code></pre> <p>Debemos escoller un porto non ocupado por ningu\u00e9n. Recomendaci\u00f3n: Colle un porto algo, por exemplo 648XX e substit\u00fae XX polo teu n\u00famero de usuario.</p> <p>Anota nalg\u00fan sitio a IP do comando anterior o porto que acabas de escoller. Vou empregar de exemplo a IP: 10.10.10.101 e o porto 64801. Ollo! emprega os datos correctos ou non che funcionar\u00e1.</p> <p>Editamos o arquivo <code>nifi.properties</code>:</p> <pre><code>nano $HOME/bin/nifi-1.24.0/conf/nifi.properties\n</code></pre> <p>E cubrimos cos datos anteriores as seguintes variables no arquivo:</p> $HOME/bin/nifi-1.24.0/conf/nifi.properties<pre><code>nifi.web.https.host=10.10.10.101\nnifi.web.https.port=64801\n</code></pre>"},{"location":"apache-nifi-0-instalacion-manual/#inicio-de-nifi","title":"Inicio de Nifi","text":"<p>Dentro de nifi hai un directorio bin que cont\u00e9n os scripts de lanzamento. En concreto inter\u00e9sanos: <code>bin/nifi.sh</code></p> <p>Entramos dentro do directorio:</p> <pre><code>cd $HOME/bin/nifi-1.24.0/bin\n</code></pre> <p>E executamos:</p> <pre><code>./nifi.sh start\n</code></pre> <p>Agora debemos consultar o usuario e clave por defecto en: <code>logs/nifi-app.log</code>.</p> <p>Buscaremos o texto \"Generated\":</p> <pre><code>cat $HOME/bin/nifi-1.24.0/logs/nifi-app.log| grep Generated\n</code></pre> <p>Con eses datos xa podemos entrar nun navegador web na IP do nodo do paso anterior (no meu exemplo: https://10.10.10.101:64801). Por favor non esquezas o https.</p> <p>Para parar Apache Nifi executaremos:</p> <pre><code>./nifi.sh stop\n</code></pre>"},{"location":"apache-nifi-0-instalacion/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83d\udc33 Instalaci\u00f3n","text":""},{"location":"apache-nifi-0-instalacion/#instalacion-rapida-de-apache-nifi-empregando-docker","title":"Instalaci\u00f3n r\u00e1pida de Apache Nifi empregando Docker","text":"<p>\ud83d\udcdd Antes de seguir aseg\u00farate de ter instalado docker no equipo.</p> <p>Baseado no repositorio do proxecto Apache coa imaxe \"non\" oficial de Apache Nifi: https://hub.docker.com/r/apache/nifi/.</p> <p>Imos crear un contedor que ter\u00e1 acceso a un directorio compartido para meter os drivers JDBC e os datasets que precisemos.</p> <pre><code>mkdir -p $HOME/nifi-compartido/{jdbc,datasets}\n\ndocker run --name nifi \\\n  -p 8443:8443 \\\n  -e NIFI_WEB_HTTPS_PORT=8443 \\\n  -e SINGLE_USER_CREDENTIALS_USERNAME=admin \\\n  -e SINGLE_USER_CREDENTIALS_PASSWORD=EsteEunContrasinalMoiLongo1234567890 \\\n  -v $HOME/nifi-compartido:/opt/nifi/compartido \\\n  --restart unless-stopped -d apache/nifi:latest\n</code></pre> <p>Se o queremos expo\u00f1er \u00e1 rede local, debemos darlle un nome coa opci\u00f3n: <code>--hostname srvnifiniano</code> e que ese nome responda \u00e1 IP do servidor.</p> <p>\u26a0\ufe0f Advertencia: Para conectar emprega localhost como nome da m\u00e1quina (fai un t\u00fanel SSH cando sexa preciso). Do contrario vaiche dar un erro de SNI incorrecto. Se quixeras conectar cun DNS personalizado (por exemplo: nifi.jfsanchez.es) ter\u00edas que xerar un certificado SSL e mudar o arquivo de configuraci\u00f3n de nifi.</p> <p>Datos de conexi\u00f3n</p> <ul> <li>\ud83d\udc64 Usuario por defecto: admin</li> <li>\ud83d\udd11 Contrasinal de exemplo: EsteEunContrasinalMoiLongo1234567890</li> <li>\ud83d\udcdd Emprega https para conectar. Exemplo: https://localhost:8443. Lembra facer o tunel SSH.</li> </ul>"},{"location":"apache-nifi-0-instalacion/#descargando-e-configurando-o-driver-jdbc-para-mysql","title":"Descargando e configurando o driver JDBC para MySQL","text":"<ol> <li>Imos a https://www.mysql.com/products/connector/ e seleccionamos JDBC for MySQL (connector J) \u2192 Download.</li> <li>Select Operating system \u2192 Platform independent.</li> <li>Platform Independent (Architecture Independent) \u2192 Compressed TAR Archive \u2192 Click dereito no bot\u00f3n Download e copiar a URL da ligaz\u00f3n.</li> </ol> <p>Se quix\u00e9semos unha versi\u00f3n antiga (por exemplo a: 8.4.0), ter\u00edamos que ir a: https://downloads.mysql.com/archives/c-j/</p> <p>Podes empregar o seguinte script que baixa as versi\u00f3n anteriormente citadas, descompr\u00edmeas e garda o .jar no directorio <code>$HOME/nifi-compartido/jdbc/</code>.</p> <p>\u26a0\ufe0f Se deixa de funcionar podes corrixilo buscando a nova URL do driver.</p> <pre><code>wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-j-9.2.0.tar.gz\nwget https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-j-8.4.0.tar.gz\ntar -xzf mysql-connector-j-9.2.0.tar.gz -C $HOME/nifi-compartido/jdbc\ntar -xzf mysql-connector-j-8.4.0.tar.gz -C $HOME/nifi-compartido/jdbc\nmv $HOME/nifi-compartido/jdbc/mysql-connector-j-9.2.0/mysql-connector-j-9.2.0.jar $HOME/nifi-compartido/jdbc/\nmv $HOME/nifi-compartido/jdbc/mysql-connector-j-8.4.0/mysql-connector-j-8.4.0.jar $HOME/nifi-compartido/jdbc/\nrm -rf $HOME/nifi-compartido/jdbc/mysql-connector-j-9.2.0 $HOME/nifi-compartido/jdbc/mysql-connector-j-8.4.0\nrm mysql-connector-j-8.4.0.tar.gz mysql-connector-j-9.2.0.tar.gz\n</code></pre> <p>Podes empregar un par\u00e1metro dentro dun contexto coa ruta completa ao JDBC para engadila r\u00e1pidamente cando fose preciso. Mira a p\u00e1xina de par\u00e1metros para atopar como configuralo deste xeito.</p>"},{"location":"apache-nifi-1-conceptos-previos/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83d\udc1c\ufe0f Conceptos previos","text":"<p>(documentaci\u00f3n en elaboraci\u00f3n)</p> <p></p> <p>Apache Nifi \u00e9 un software adicado a automatizar o fluxo de datos entre sistemas. Tam\u00e9n pode ser considerado unha ferramenta ETL (Extract/Load/Transform). Web Oficial: https://nifi.apache.org/</p>"},{"location":"apache-nifi-1-conceptos-previos/#barra-de-ferramentas-de-apache-nifi","title":"Barra de ferramentas de Apache Nifi","text":"<p>A seguinte documentaci\u00f3n foi elaborada empregando a versi\u00f3n: 2.2.0.</p> <p></p>"},{"location":"apache-nifi-1-conceptos-previos/#procesadores","title":"Procesadores","text":""},{"location":"apache-nifi-1-conceptos-previos/#tipos-de-procesadores","title":"Tipos de procesadores","text":"<p>Poden clasificarse de moitas maneiras, sen embargo os m\u00e1is relevantes poder\u00edan resumirse en:</p> <ul> <li>Inxesta de datos: GetFile, GetFTP, GetKAFKA, GetHTTP, InvokeHTTP, PostHTTP, ListenHTTP...</li> <li>Enrutamento: RouteOnAttribute, RouteOnContent, ControlRate, RouteText...</li> <li>Base de datos: ExecuteSQL, PutSQL, PutDatabaseRecord, ListDatabaseTables...</li> <li>De interacci\u00f3n co sistema operativo: ExecuteScript, ExecuteProcess, ExecuteGroovyScript, ExecuteStreamCommand...</li> <li>Transformaci\u00f3n de datos: ReplaceText, JoltTransformJSON...</li> <li>Extracci\u00f3n de atributos: UpdateAttribute, EvaluateJSONPath, ExtractText, AttributesToJSON...</li> <li>Env\u00edo de datos: PutEmail, PutKafka, PutSFTP, PutFile, PutFTP...</li> <li>Divisi\u00f3n e agregaci\u00f3n: SplitText, SplitJson, SplitXml, MergeContent, SplitContent...</li> </ul>"},{"location":"apache-nifi-1-conceptos-previos/#estados-dun-procesador","title":"Estados dun procesador","text":"<ul> <li>Parado \u2192 Non se est\u00e1 a executar.</li> <li>En execuci\u00f3n \u2192 Activo, realizando unha tarefa.</li> <li>Deshabilitado \u2192 Non se pode iniciar a non ser que se active. \u00datil para modificar.</li> <li>Con erros/advertencias \u2192 Falta ou falla algo na configuraci\u00f3n.</li> </ul>"},{"location":"apache-nifi-1-conceptos-previos/#grupos-de-procesadoresprocesamento","title":"Grupos de procesadores/procesamento","text":"<p>Temos un canvas principal no que o orde \u00e9 importante. Dividir tarefas m\u00e1is simples, ter unha vista l\u00f3xica de todo. Meter as subtareas complexas nun grupo...</p> <p>Colecci\u00f3n de procesadores e conexi\u00f3ns.</p> <p>Conxunto m\u00ednimo que se garda no control de versi\u00f3ns (Nifi registry ou git).</p>"},{"location":"apache-nifi-1-conceptos-previos/#flowfile","title":"FlowFile","text":"<p>Un arquivo de fluxo, FlowFile ou FF \u00e9...</p> <p>Pasa os datos entre os diferentes procesadores. Definir streaming de datos.</p> <p>Como obxecto \u00e9 inmutable, a\u00ednda que o seu contido e atributos poden cambiar.</p> <ul> <li>Datos</li> <li>Atributos/Metadatos</li> </ul>"},{"location":"apache-nifi-1-conceptos-previos/#colas-e-conexions","title":"Colas e conexi\u00f3ns","text":"<p>Unha conexi\u00f3n p\u00f3dese asociar a varios tipos de resultados.</p> <p>Conexi\u00f3n cola que enruta os FlowFiles entre procesadores. P\u00f3dese enrutar en funci\u00f3n de diferentes condici\u00f3ns.</p> <p>As condici\u00f3ns dunha conexi\u00f3n son as relaci\u00f3ns entre procesadores e poden ser:</p> <ul> <li>Est\u00e1ticas: As t\u00edpicas: Success, Failure, Retry, Response, Request, Match, Unmatch...</li> <li>Din\u00e1micas: Baseadas en atributos dun FlowFile definidos por un usuario. RouteOnAtribute</li> </ul>"},{"location":"apache-nifi-1-conceptos-previos/#colas-limpeza-caducidade-de-datos","title":"Colas. Limpeza, caducidade de datos","text":"<p>Limpeza cando falla unha transformaci\u00f3n e quedan datos pendentes, tama\u00f1o m\u00e1ximo e caducidade por tempo (exemplo un procesador non \u00e9 capaz de procesar os datos \u00e1 mesma velocidade que outro)</p> <p>Click dereito nunha cola \u2192 Configure \u2192 Lapela Settings.</p> <ul> <li>Prioritizers.<ul> <li>FirstInFirstOutPrioritizer: FIFO...</li> <li>...</li> </ul> </li> <li>FlowFile Expiration.</li> <li>Back Pressure Object Threshold.</li> <li>Size Threshold.</li> <li>Load Balance Strategy (so se hai varios nodos).</li> </ul>"},{"location":"apache-nifi-1-conceptos-previos/#controller-services-e-o-seu-scope","title":"Controller Services e o seu Scope","text":"<p>Cada grupo de procesamento ten o seu \u00e1mbito.</p>"},{"location":"apache-nifi-1-conceptos-previos/#data-provenance","title":"Data Provenance","text":"<p>Para analizar os datos polos distintos pasos. Estados. Caducidade en tempo...</p>"},{"location":"apache-nifi-1-conceptos-previos/#portos","title":"Portos","text":"<p>Atributos: nome</p> <p>Utilidade entre grupos de procesamento.</p> <p>Cada grupo de procesamento pode ter varios portos de entrada e sa\u00edda.</p>"},{"location":"apache-nifi-1-conceptos-previos/#portos-de-entrada","title":"Portos de entrada","text":"<p>Entrada de datos de outro grupo...</p>"},{"location":"apache-nifi-1-conceptos-previos/#portos-de-saida","title":"Portos de sa\u00edda","text":"<p>Punto de sa\u00edda/env\u00edo de datos a...</p>"},{"location":"apache-nifi-1-conceptos-previos/#funnel-embudos","title":"Funnel (embudos)","text":"<p>Permiten combinar a sa\u00edda de datos de diferentes conexi\u00f3ns.</p> <p>(en elaboraci\u00f3n...)</p>"},{"location":"apache-nifi-1-primeiros-pasos/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83d\udc63 Primeiros pasos","text":""},{"location":"apache-nifi-1-primeiros-pasos/#requisitos-previos","title":"Requisitos previos","text":"<p>Lembra seguir a gu\u00eda de instalaci\u00f3n de Apache Nifi antes de continuar con este documento.</p> <p>Imos ver un par de exemplos simples para demostrar o funcionamento de Apache Nifi.</p>"},{"location":"apache-nifi-1-primeiros-pasos/#creando-contedores-coas-bases-de-datos","title":"Creando contedores coas bases de datos","text":"<p>Creamos un servidor de MySQL</p> <pre><code>docker volume create mysql4nifi_vol\n\ndocker run -p 9906:3306 --name mysql4nifi \\\n    -v mysql4nifi_vol:/var/lib/mysql \\\n    -e MYSQL_ROOT_PASSWORD=Nifi.My456 \\\n    -e MYSQL_DATABASE=nifi \\\n    -e MYSQL_USER=nifi \\\n    -e MYSQL_PASSWORD=Nifi.Abc123 \\\n    --restart unless-stopped -d mysql:8\n</code></pre> <p>Conectamos \u00e1 base de datos:</p> <pre><code>docker exec -it mysql4nifi mysql -hlocalhost -unifi -pNifi.Abc123 nifi\n</code></pre> <p>E pegamos o script:</p> <pre><code>CREATE TABLE tronoPers(\n    id INTEGER,\n    firstName VARCHAR(100),\n    lastName VARCHAR(100),\n    fullName VARCHAR(100),\n    title VARCHAR(100),\n    family VARCHAR(100),\n    image VARCHAR(255),\n    imageUrl VARCHAR(255)\n);\n\nCREATE TABLE tronoCont(\n    id INTEGER,\n    name VARCHAR(100)\n);\n\nCREATE TABLE estrenosNet(\n    videoID INTEGER,\n    country CHAR(2),\n    title1 VARCHAR(255),\n    title2 VARCHAR(255),\n    startTime TIMESTAMP,\n    collection INTEGER,\n    image TEXT,\n    genre INTEGER\n);\n</code></pre> <p>\u26a0\ufe0f Non copies e pegues os seguintes comandos sen ler.</p> <p>Tan so se tiveses que crear a BBDD e o usuario a man porque xa te\u00f1as o servidor MySQL creado, ser\u00eda as\u00ed:</p> <pre><code>CREATE DATABASE nifi;\nCREATE USER 'nifi'@'%' IDENTIFIED BY 'Nifi.Abc123';\nGRANT ALL PRIVILEGES ON nifi.* TO 'nifi'@'%';\nFLUSH PRIVILEGES;\nuse nifi;\n</code></pre>"},{"location":"apache-nifi-1-primeiros-pasos/#lendo-duas-apis-de-exemplo","title":"Lendo d\u00faas APIs de exemplo","text":"<p>Imos facer d\u00faas probas, unha cunha API chamada ThronesAPI e outra real, a de Netflix.</p>"},{"location":"apache-nifi-1-primeiros-pasos/#thronesapi","title":"ThronesAPI","text":"<p>A API de ThronesAPI perm\u00edtenos baixar directamente a informaci\u00f3n e ten documentaci\u00f3n de uso.</p> <p>Por exemplo, podemos arrastrar un novo procesador e seleccionar InvokeHTTP e nas propiedades empregar calquera das URL:</p> <ul> <li>https://thronesapi.com/api/v2/Characters</li> <li>https://thronesapi.com/api/v2/Continents</li> </ul> <p>Dende o canvas de Nifi arrastramos un grupo de procesamento e lle chamamos Trona2. Facemos doble click dentro del para meternos e dentro do seu canvas arrastramos un procesador. No cadro de b\u00fasqueda po\u00f1emos que sexa de tipo: InvokeHTTP.</p> <p>Facemos doble click no novo procesador InvokeHTTP e modificamos:</p> <ul> <li>Na lapela Settings cambiamos a s\u00faa propiedade name a ThronesAPI.</li> <li>Na lapela Scheduling deixamos o evento como Time driven, pero en Run Schedule mudamos os 0 segundos por 300 segundos.</li> <li>Na lapela Properties mudamos o campo HTTP URL por: https://thronesapi.com/api/v2/Characters.</li> <li>Na lapela Relationships marcamos terminate nos casos: Failure, No Retry, e Retry.</li> </ul> <p>Cando te\u00f1amos modificado todo, premeremos en Apply.</p> <p>Facemos click dereito no procesador e seleccionamos Change color e po\u00f1emos unha cor vermella.</p> <p>Volvemos a facer doble click no procesador e imos \u00e1 lapela Properties, na parte superior dereita veremos Verification e un check \u2714\ufe0f.</p> <p></p> <p>Prememos no check para ver se o procesador supera todas as verificaci\u00f3ns de deber\u00eda verse todo en verde. Se tes algo mal, corr\u00edxeo antes de continuar. En xeral para case todos os controis, debemos primeiro aplicar e logo volver meternos e validar.</p> <p>\u26a0\ufe0f Lembra gardar os cambios antes de validar. A maior\u00eda dos controis val\u00eddanse coa configuraci\u00f3n anterior sen gardar a non ser que os gardemos expl\u00edcitamente.</p> <p></p>"},{"location":"apache-nifi-1-primeiros-pasos/#netflix","title":"Netflix","text":"<p>Imos \u00e1 p\u00e1xina de Netflix. New to Watch e prememos Ctrl+Shift+i para acceder \u00e1 consola do desenvolvedor. Unha vez ah\u00ed imos a Network e despois filtramos por Fetch/XHR (XMLHttpRequest).</p> <p></p> <p>Despois cambiamos na web de lapela entre Pel\u00edculas e series por exemplo e veremos que aparece unha nova li\u00f1a cunha petici\u00f3n. Facemos click dereito nela: Copy \u2192 Copy URL.</p> <p></p> <p>Se pegamos esa URL nunha nova lapela, veremos que nos da un JSON paxinado. Sen embargo, se tratamos de pegar esa URL no Nifi, dar\u00e1 un erro 403 (prohibido) xa que a web non permite que ferramentas autom\u00e1ticas se conecten a ela.</p> <p>Podemos baixar o arquivo JSON a man e subilo a un servidor web noso para probar a descargalo dende ah\u00ed.</p> <p>Ollo! Non t\u00f3dolos datos que son p\u00fablicos te\u00f1en licencia para ser empregados e voltos a publicar.</p>"},{"location":"apache-nifi-1-primeiros-pasos/#montar-un-servidor-web-para-meter-arquivos","title":"Montar un servidor web para meter arquivos","text":"<p>Pode serche \u00fatil para non saturar os servidores dos que queiras baixarte informaci\u00f3n ou se che proh\u00edben o acceso dende Nifi ou curl.</p> <p>Con estes dous comandos crear\u00e1s un directorio \"web\" dentro do teu home de usuario. Ah\u00ed poder\u00e1s mover os documentos que queiras accesibles (por exemplo arquivos .json previamente descargados).</p> <pre><code>mkdir -p $HOME/web\n\ndocker run --name nginx -p 80:80 \\\n  -v $HOME/web:/usr/share/nginx/html:ro \\\n  --restart unless-stopped -d nginx\n</code></pre>"},{"location":"apache-nifi-1-primeiros-pasos/#conexion-coas-diferentes-bases-de-datos","title":"Conexi\u00f3n coas diferentes bases de datos","text":"<p>Imos ver un par de exemplos de conexi\u00f3n:</p> <ul> <li>DBCPConnectionPool: Para conectar por JDBC a unha base de datos relacional.</li> <li>MongoDBControllerService: Para conectar a MongoDB, unha BBDD NO-SQL.</li> </ul>"},{"location":"apache-nifi-1-primeiros-pasos/#dbcpconnectionpool-conexion-coa-bbdd","title":"DBCPConnectionPool: Conexi\u00f3n coa BBDD","text":"<p>Os controles m\u00ednimos que precisamos para transformar de modo sinxelo os datos descargados dun servizo web en JSON e pasalos \u00e1 nosa base de datos relacional son:</p> <p></p> <ul> <li>Procesador InvokeHTTP / GetFile / GetFileResource / ... /: Precisamos un procesador que nos devolva un JSON en formato FlowFile. As propiedades do exemplo son para o InvokeHTTP:<ul> <li>Lapela Properties \u2192 HTTP URL: https://thronesapi.com/api/v2/Characters</li> <li>En Relationships en todo o que non sexa Response marca Terminate.</li> </ul> </li> <li>Procesador ConvertRecord: Para pasar de JSON a CSV.<ul> <li>Lapela Properties:<ul> <li>Record Reader: Tres puntos \u2192 Create New Service \u2192 JsonTreeReader.</li> <li>Record Writer: Tres puntos \u2192 Create New Service \u2192 CSVRecordSetWriter.</li> </ul> </li> <li>En Relationships, en Failure marca Terminate.</li> </ul> </li> <li>Procesador PutDatabaseRecord: Para meter o Recordset na base de datos.<ul> <li>Lapela Properties:<ul> <li>Record Reader: Tres puntos \u2192 Create New Service \u2192 CSVReader.</li> <li>Database Type: MySQL.</li> <li>Statement Type: INSERT.</li> <li>Database Connection Pooling Service: DBCPConnectionPool.</li> <li>Table Name: nifi.</li> </ul> </li> <li>En Relationships, en Failure e Retry marca Terminate.</li> </ul> </li> </ul> <p>Precisamos saber a IP do servidor de base de datos:</p> <pre><code>docker inspect mysql4nifi\n</code></pre> <p>Neste exemplo imaxinamos que \u00e9: 172.17.0.4.</p> <p>Para averiguar Driver Class Name, se temos instalado DBeaver podemos facer unha nova conexi\u00f3n de base de datos e premer en \"Editar conexi\u00f3n\", logo premeremos no bot\u00f3n \"Driver settings\" e miramos despois o nome de clase.</p> <p>Agora teremos que facer click dereito no canvas (dentro do grupo de procesamento) e ir a Controller Services en DBCPConnectionPool configuraremos o seguinte:</p> <ul> <li>Database Connection URL: jdbc:mysql://172.17.0.4:3306/nifi</li> <li>Database Driver Class Name: com.mysql.cj.jdbc.Driver</li> <li>Database Driver Location(s):<ul> <li>Para versi\u00f3n 8: /opt/nifi/compartido/jdbc/mysql-connector-j-8.4.0.jar</li> <li>Para versi\u00f3n 9: /opt/nifi/compartido/jdbc/mysql-connector-j-9.2.0.jar</li> </ul> </li> <li>Database User: nifi</li> <li>Password: Nifi.Abc123</li> </ul> <p>Despois de aplicar os cambios, debemos meternos en cada un dos Controller Services facendo click nos tres puntos e logo en Edit e premer no check ao lado de Verification. Se todo funciona correctamente, prememos no bot\u00f3n Close, volvemos aos tres puntos e seleccionamos Enable e logo confirmamos con bot\u00f3n Enable de novo.</p> <p>Para volver \u00e1 pantalla anterior, prememos en Back to Proccess Group.</p> <p></p>"},{"location":"apache-nifi-1-primeiros-pasos/#mongodbcontrollerservice-conexion-con-atlas","title":"MongoDBControllerService: Conexi\u00f3n con Atlas","text":"<p>Para poder conectar ao noso servicio de Mongo na nube (Atlas) teremos que configurar unha conexi\u00f3n.</p> <p>Neste exemplo veremos un procesador PutMongoRecord conectado a trav\u00e9s dun MongoDBControllerService a atlas a unha BBDD chamada nifi.</p> <p></p> <ol> <li>Conectamos a atlas \u2192 Sign In.</li> <li>Se non temos un cluster gratuito, cre\u00e1molo e engadimos o dataset de exemplo.</li> <li>Imos a Security \u2192 Network Access e engadimos a IP externa sa\u00ednte ou rango de IPs saintes do servidor Apache Nifi. Se non sabes qu\u00e9 IP de sa\u00edda est\u00e1s a empregar podes empregar calquera destes servizos:     <pre><code>curl ifconfig.me\ncurl icanhazip.com\ncurl api.ipify.org\n</code></pre></li> <li>En Security \u2192 Database Access \u2192 Prememos no bot\u00f3n Add new database user e seleccionamos:<ol> <li>Authentication Method: Password.</li> <li>Password authentication \u2192 Escollemos un usuario e un contrasinal.</li> <li>Builtin role \u2192 Atlas Admin. Esto far\u00e9molo como proba, m\u00e1is deber\u00edase seleccionar s\u00f3 a base de datos a que necesitemos ter acceso e os permisos necesarios (lectura, escritura, ambos...).</li> <li>Marcamos temporary user e lle damos 6 horas de duraci\u00f3n ao usuario.</li> <li>\u26a0\ufe0f Cando te\u00f1as todo configurado e funcionando, deber\u00e1s volver aqu\u00ed e crear un usuario definitivo con acceso \u00e1s bases de datos que precises.</li> </ol> </li> <li>En Cluster \u2192 Bot\u00f3n Connect \u2192 Prememos na opci\u00f3n Drivers \u2192 E copiamos o servizo sen usuario e contrasinal que ser\u00e1 de tipo:      <pre><code>mongodb+srv://NomeElexidoPorTi.SubdominioAleatorio.mongodb.net\n</code></pre></li> <li>Imos a Cluster \u2192 Browse collections. Logo prememos no bot\u00f3n + Create Database. Po\u00f1emos en Database Name nifi e en Collection proba.</li> <li>En Apache Nifi arrastramos un novo procesador de tipo: PutMongoRecord.<ol> <li>En Client Service \u2192 Nos tres puntos \u2192 + Create New Service... \u2192 MongoDBControllerService.</li> <li>Mongo Database Name: nifi.</li> <li>Mongo Collection Name: nomeDaColeccion.</li> <li>Record Reader: JsonTreeReader.</li> </ol> </li> </ol>"},{"location":"apache-nifi-1-primeiros-pasos/#ligazons-para-mais-informacion","title":"Ligaz\u00f3ns para mais informaci\u00f3n","text":"<ul> <li>Titorial de Tutorial's Point: https://www.tutorialspoint.com/apache_nifi/index.htm</li> <li>Documentaci\u00f3n oficial. Inicio r\u00e1pido: https://nifi.apache.org/docs/nifi-docs/html/getting-started.html</li> <li>Documentaci\u00f3n oficial. Manual do usuario: https://nifi.apache.org/docs/nifi-docs/html/user-guide.html</li> <li>Documentaci\u00f3n oficial. Nifi en profundidade: https://nifi.apache.org/docs/nifi-docs/html/nifi-in-depth.html</li> <li>Titoriais en Youtube de InsightByte https://www.youtube.com/playlist?list=PLkp40uss1kSI66DA_aDCfx02gXipoRQHc</li> </ul>"},{"location":"apache-nifi-2-parametros/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83c\udfaf Par\u00e1metros e segredos","text":""},{"location":"apache-nifi-2-parametros/#parametros-parameters-e-contextos-parameter-context","title":"Par\u00e1metros (Parameters) e Contextos (Parameter Context)","text":"<p>Un par\u00e1metro pode ser un usuario, servidor, contrasinal, axuste ou texto que vaiamos repetir ou queramos mudar dependendo da execuci\u00f3n. Tes un axuste que introduces en varios sitios? Xa tes un par\u00e1metro!</p> <p>Estes par\u00e1metros pod\u00e9molos agrupar en contextos chamados Parameter Context.</p> <p>Propiedades dos contextos:</p> <ul> <li>So podemos asociar un contexto por grupo de procesamento.</li> <li>Un contexto pode herdar os par\u00e1metros doutros contextos (\u00fatil para aplicar \"varios\" contextos a un grupo de procesamento).</li> <li>Un contexto p\u00f3dese aplicar de xeito recursivo a un grupo de procesadores (ou ao principal Nifi Flow para que se aplique a todo).</li> </ul> <p>Un exemplo dun par\u00e1metro \u00e9 a ruta a onde est\u00e1 gardado o driver JDBC que se emprega na conexi\u00f3n a unha BBDD.</p>"},{"location":"apache-nifi-2-parametros/#creando-un-contexto-de-parametros","title":"Creando un contexto de par\u00e1metros","text":"<p>Imos ao Menu principal (as tres raias horizontais de arriba \u00e1 dereita) \u2192 e prememos en Parameter Context.</p> <p>Dende esta secci\u00f3n da p\u00e1xina prememos \u00e1 dereita no bot\u00f3n + e introducimos:</p> <ul> <li>Lapela Settings:<ul> <li>Name: Drivers MySQL.</li> </ul> </li> <li>Lapela Parameters, crearemos dous par\u00e1metros:<ul> <li>Name: MYSQL8_JDBC. Value: <code>/opt/nifi/compartido/jdbc/mysql-connector-j-8.4.0.jar</code>.</li> <li>Name: MYSQL9_JDBC. Value: <code>/opt/nifi/compartido/jdbc/mysql-connector-j-9.2.0.jar</code>.</li> <li>Name: MYSQL_CLASSNAME.Value: <code>com.mysql.cj.jdbc.Driver</code>.</li> </ul> </li> </ul>"},{"location":"apache-nifi-2-parametros/#asociando-un-contexto-de-parametros-a-grupo-de-procesamento","title":"Asociando un contexto de par\u00e1metros a grupo de procesamento","text":"<p>Hai d\u00faas opci\u00f3ns:</p> <ul> <li>Na creaci\u00f3n dun grupo de procesamento: Elexiremos do despregable o Parameter Context.</li> <li>Despois da creaci\u00f3n \u2192 Click dereito no grupo \u2192 Configure \u2192 Na lapela Settings escoll\u00e9molo no despregable Parameter Context.</li> </ul>"},{"location":"apache-nifi-2-parametros/#herdanza-de-contextos","title":"Herdanza de contextos","text":"<p>Un contexto de par\u00e1metros pode herdar doutro. Por exemplo podemos ter un contexto Kafka e outro Mongo para ter os axustes de cada servidor organizados e ter outro chamado BBDD que conte\u00f1a ambos.</p> <ol> <li>Vai ao Menu principal \u2192 Parameter Context.</li> <li>Preme no + para crear un novo contexto.</li> <li>Lapela Settings \u2192 Name: MySQL Nifiniano.</li> <li>Lapela Parameters creamos os seguintes par\u00e1metros:<ul> <li>MYSQL_SERVER: <code>jdbc:mysql://X.X.X.X:3306/nifi</code>. Substit\u00fae X.X.X.X pola IP do teu contedor.</li> <li>MYSQL_USER: <code>nifi</code>.</li> <li>MYSQL_PASSWORD: <code>Nifi.Abc123</code>. Marca a opci\u00f3n: Sensitive Value como Yes.</li> </ul> </li> <li>Lapela Inheritance \u2192 Arrastramos o contexto Drivers MySQL da zona Available Parameter Contexts a Selected Parameter Contexts.</li> <li>Finalmente prememos en Apply para gardar e pechar.</li> </ol> <p>A opci\u00f3n de sensitive value permite d\u00faas cousas: Por unha banda que non se exporten os segredos e por outra que nos permita po\u00f1er ese par\u00e1metro nun campo sensible (por exemplo de contrasinal).</p>"},{"location":"apache-nifi-2-parametros/#empregando-os-paramentros-nun-procesador","title":"Empregando os par\u00e1mentros nun procesador","text":"<p>Escolle un grupo de procesamento no que configuraras un DBCPConnectionPool.</p> <p>Agora imos ao grupo de procesamento e prememos Click dereito \u2192 Configure (opcionalmente tam\u00e9n click dereito \u2192 Configure dende dentro do grupo, nunha parte libre do Canvas).</p> <p>Dentro da lapela Settings, en Parameter Context poderemos seleccionar o contexto que temos creado: MySQL Nifiniano. Finalmente prememos en Apply para gardar e pechar.</p> <p>Dentro do grupo de procesamento \u2192 click dereito nunha parte libre do canvas \u2192 Controller Services e editamos o DBCPConnectionPool. Na lapela Properties en Database Driver Location(s) escribimos #{ e logo prememos Ctrl+Espacio para poder ver a lista de par\u00e1metros a seleccionar. Escollemos: <code>#{MYSQL8_JDBC}</code>.</p> <p>Agora, se por calquer motivo mudamos a ruta onde gardamos o JDBC e dita ruta est\u00e1 en varios controis, bastar\u00eda con cambiar unha soa vez o par\u00e1metro. Adem\u00e1is, para meter esta ruta en novos controis, se nos autocompletar\u00eda.</p>"},{"location":"apache-nifi-2-parametros/#e-agora-ti","title":"E agora ti...","text":"<p>Engade un novo contexto chamado MongoDB cos seguintes par\u00e1metros (obt\u00e9n os datos dun servidor de mongo que te\u00f1as montado):</p> <ul> <li>MONGO_SERVER: <code>mongodb+srv://xxx.yyy.mongodb.net</code>.</li> <li>MONGO_USER: <code>usuario_mongo</code>.</li> <li>MONGO_PASSWORD: <code>Contrasinal_Mongo</code>.  Marca a opci\u00f3n: Sensitive Value como Yes.</li> </ul> <p>Por \u00faltimo crea un contexto chamado BBDD onde mediante herdanza metas todos os par\u00e1metros de MySQL e MongoDB.</p>"},{"location":"apache-nifi-2-parametros/#xestor-de-parametros","title":"Xestor de par\u00e1metros","text":"<p>(en elaboraci\u00f3n)</p> <ul> <li>DatabaseParameterProvider</li> </ul>"},{"location":"apache-nifi-2-parametros/#xestion-de-segredos","title":"Xesti\u00f3n de segredos","text":"<p>(en elaboraci\u00f3n)</p> <ul> <li> <p>Xestor de contrasinais: 1Password, AWS, Google Cloud...</p> </li> <li> <p>HashiCorpVaultParameterProvider</p> </li> </ul> <p>Mentres os par\u00e1metros podemos almacenalos en bases de datos, para os contrasinais \u00e9 recomendable empregar un xestor de segredos espec\u00edfico, xa ben sexa un do estilo dos empregados por docker/kubernetes/etc ou un xestor de contrasinais que admita API.</p>"},{"location":"apache-nifi-3-codificacion/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83c\udf10 Codificaci\u00f3n de caracteres","text":"<p>Fallan acentos/tildes/e\u00f1es? Probablemente esteas a ler ou escribir nunha codificaci\u00f3n de caracteres incorrecta.</p> <p>Codificaci\u00f3ns de caracteres m\u00e1is habituais:</p> <ul> <li>UTF-8</li> <li>ISO-8859-1 / ISO-8859-15</li> <li>LATIN1</li> <li>ASCII</li> <li>UTF-16</li> </ul> <p>Procesador ConvertRecord:</p> <ul> <li>Record Reader: CSVReader  \u2192 Propiedade Character Set.</li> <li>Record Writer: CSVRecordSetWriter \u2192 Propiedade Character Set.</li> </ul> <p>\ud83d\udcdd A m\u00e1xima \u00e9: Le na codificaci\u00f3n correcta, escribe na desexada.</p>"},{"location":"apache-nifi-3-codificacion/#mais-informacion","title":"Mais informaci\u00f3n","text":"<p>Se desexas obter m\u00e1is informaci\u00f3n acerca das diferentes codificaci\u00f3ns de caracteres, podes consultar a p\u00e1xina da Wikipedia:</p> <ul> <li>https://es.wikipedia.org/wiki/Codificaci%C3%B3n_de_caracteres</li> </ul>"},{"location":"apache-nifi-4-procesadores/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83d\udc77 Procesadores","text":""},{"location":"apache-nifi-4-procesadores/#procesadores-mais-habituais","title":"Procesadores m\u00e1is habituais","text":"<p>Imos ver as configuraci\u00f3ns b\u00e1sicas e comentar os procesadores mais habituais.</p>"},{"location":"apache-nifi-4-procesadores/#tipos-de-procesadores","title":"Tipos de procesadores","text":"<p>Poden clasificarse de moitas maneiras, sen embargo os m\u00e1is relevantes poder\u00edan resumirse en:</p> <ul> <li>Inxesta de datos: GetFile, GetFTP, GetKAFKA, GetHTTP, InvokeHTTP, PostHTTP, ListenHTTP...</li> <li>Enrutamento: RouteOnAttribute, RouteOnContent, ControlRate, RouteText...</li> <li>Base de datos: ExecuteSQL, PutSQL, PutDatabaseRecord, ListDatabaseTables...</li> <li>De interacci\u00f3n co sistema operativo: ExecuteScript, ExecuteProcess, ExecuteGroovyScript, ExecuteStreamCommand...</li> <li>Transformaci\u00f3n de datos: ReplaceText, JoltTransformJSON...</li> <li>Extracci\u00f3n de atributos: UpdateAttribute, EvaluateJSONPath, ExtractText, AttributesToJSON...</li> <li>Env\u00edo de datos: PutEmail, PutKafka, PutSFTP, PutFile, PutFTP...</li> <li>Divisi\u00f3n e agregaci\u00f3n: SplitText, SplitJson, SplitXml, MergeContent, SplitContent...</li> </ul>"},{"location":"apache-nifi-4-procesadores/#getfile","title":"GetFile","text":""},{"location":"apache-nifi-4-procesadores/#executesql","title":"ExecuteSQL","text":""},{"location":"apache-nifi-4-procesadores/#replacetext","title":"ReplaceText","text":"<p>...</p>"},{"location":"apache-nifi-z-control-versions/","title":"\ud83d\udca7 Apache Nifi \u2014 \ud83d\ude3c Control de versi\u00f3ns","text":"<p>Apache Nifi permite gardar as versi\u00f3ns dos grupo de procesamento ou ben no Nifi Registry, Github ou Gitlab. Esto permite gardar o estado de cada grupo de procesamento permitindo volver atr\u00e1s.</p> <p>Tam\u00e9n se poder\u00eda facer un backup do arquivo flowfile.xml.gz pero isto implica facer unha copia manual de cada vez. Se queremos so unha copia, podemos facer click dereito no Canvas \u2192 Download Flow Definition \u2192 With/Without External Services.</p> <p>Se queremos configurar calquera das opci\u00f3ns, iremos ao men\u00fa \u2192 Controller Settings \u2192 Registry Clients \u2192 +</p>"},{"location":"apache-nifi-z-control-versions/#configuracion-dun-rexistro","title":"Configuraci\u00f3n dun rexistro","text":"<p>Actualmente as explicaci\u00f3ns completas est\u00e1n dispo\u00f1ibles so para GitHub.</p>"},{"location":"apache-nifi-z-control-versions/#github","title":"GitHub","text":"<ul> <li>GitHub: GitHubFlowRegistryClient. Na lapela Properties:<ul> <li>Repository Owner: Usuario de github.</li> <li>Authentication Type: Personal Access Token.</li> <li>Personal Access Token: Pegar o token xerado en GitHub.</li> <li>Default Branch: main (ollo, se creamos manualmente master).</li> <li>Repository Path: No caso de gardar nun directorio.</li> </ul> </li> </ul> <p>Se s\u00f3 precisamos acceso de lectura, non precisamos xerar un PAT, neste caso seleccionamos como Autentication type: None.</p> <p>Creamos un directorio no repositorio que se chame: BucketTrono.</p> <p>Xerar un Personal Access Token</p> <p>En GitHub: Settings -&gt; Developer Settings -&gt; Men\u00fa dereito: Personal Access Tokens -&gt; Fine-grained tokens -&gt; Generate new Token.</p> <p>Darlle un nome, unha expiraci\u00f3n e en Repository access -&gt; Only select repositories -&gt; Marcar os repos aos que queremos darlle acceso.</p> <p>Marcar os permisos:</p> <ul> <li>Content \u2192 Access Read and Write.</li> <li>Commit statuses  \u2192 Access Read and Write.</li> </ul> <p>Premer no bot\u00f3n de Generate token.</p>"},{"location":"apache-nifi-z-control-versions/#gitlab","title":"GitLab","text":"<p>(en elaboraci\u00f3n) GitLabFlowRegistryClient</p>"},{"location":"apache-nifi-z-control-versions/#apache-nifi-registry","title":"Apache Nifi Registry","text":"<p>(en elaboraci\u00f3n) Para montar un Nifi Registry empregado polo NifiRegistryFlowRegistryClient, existe unha imaxe co Nifi Registry: https://hub.docker.com/r/apache/nifi-registry.</p>"},{"location":"apache-nifi-z-control-versions/#versionar-grupo","title":"Versionar grupo","text":"<p>Dende o canvas principal, facemos click dereito no Proccess Group que nos interesa, por exemplo Tronos \u2192 Version \u2192 Start Version Control.</p> <p></p> <p>Se nos fixamos, agora o grupo ten un check en verde ao principio do nome indic\u00e1ndonos de este feito que est\u00e1 baixo o control de versi\u00f3ns.</p> <p></p> <p>Se temos varios grupos de procesamento no mesmo \"Bucket\" (directorio ou cubo de almacenamento) cada un ter\u00e1 un nome diferente (Flow Name) rematado en .json.</p> <p>Se facemos calquer cambio no grupo de procesamento e despois volvemos ao Canvas principal e prememos de novo con click dereito no grupo e vamos \u00e1s opci\u00f3ns de versi\u00f3ns, podemos face run commit (e push) ao repositorio.</p> <p></p> <p>Se prememos en commit, podemos indicar a mensaxe.</p> <p></p> <p>E se imos ao repositorio, ver\u00edamos no directorio correspondente os arquivos .json.</p> <p></p>"},{"location":"apache-nifi-z-control-versions/#volver-a-unha-version-anterior","title":"Volver a unha versi\u00f3n anterior","text":"<p>Podemos volver a unha versi\u00f3n anterior premendo con click dereito e seleccionando: Version \u2192 Change version.</p> <p></p> <p>Tam\u00e9n veremos unha marca conforme hai unha nova versi\u00f3n dispo\u00f1ible (\u00fatil por si actualizamos o repo dende outro sitio ou estamos empregando un fluxo doutra persoa).</p> <p></p>"},{"location":"apache-nifi-z-control-versions/#importar-un-fluxo-dun-rexistro","title":"Importar un fluxo dun rexistro","text":"<p>Na barra de ferramentas, dende a opci\u00f3n Import from Registry tam\u00e9n podemos arrastrar e crear un grupo de procesamento que xa estea no repositorio. Arrastramos a opci\u00f3n ao Canvas e seleccionamos o que queremos importar.</p> <p></p> <p>E como vemos, podemos ter d\u00faas versi\u00f3ns do mesmo grupo de procesamento para probalas.</p> <p></p>"},{"location":"apache-spark-0-instalacion/","title":"\u269d Apache Spark \u2014 \ud83e\uddfe Instalaci\u00f3n","text":"<p>Faremos unha instalaci\u00f3n de Apache Spark en 4 m\u00e1quinas con ClusterShell, un programa que permite enviar \u00e1 vez comandos a varias m\u00e1quinas.</p> <p>A presente instalaci\u00f3n contempla 1 master e 3 nodos (ou 4 nodos de actuar o m\u00e1ster tam\u00e9n como worker). Se tes un n\u00famero diferente de m\u00e1quinas, deber\u00e1s mudar nos comandos a parte do [1-4] ou [2-4] adapt\u00e1ndoo \u00e1s t\u00faas necesidades.</p> <p>Consideraremos os seguintes nomes de m\u00e1quinas:</p> /etc/hosts<pre><code>10.X.Y.101 hadoop1 hadoop1.local master1.local\n10.X.Y.102 hadoop2 hadoop2.local\n10.X.Y.103 hadoop3 hadoop3.local\n10.X.Y.104 hadoop4 hadoop4.local\n</code></pre> <p>Imos empregar Rocky 8.5 v2, sen embargo, en caso de empregar Debian, podemos empregar <code>apt</code> en lugar de <code>dnf</code>. Consideramos tam\u00e9n o contorno do cesga con usuario por defecto: <code>cesgaxuser</code> e <code>$HOME</code> en <code>/home/cesgaxuser/</code>.</p> <p>Se est\u00e1s nun contorno Cloud no que debes destruir as instancias por tema de custes e p\u00f3dense asignar distintos enderezos IP, lembra sempre facer:</p> <ol> <li> <p>Editar o arquivo <code>/etc/hosts</code> cos nomes que correspondan \u00e1s novas IP.</p> </li> <li> <p>Borrar o known_hosts:     <pre><code>rm ~/.ssh/known_hosts\n</code></pre></p> </li> <li> <p>Rexenerar o <code>/etc/hosts</code>:</p> <pre><code>for servidor in $(cat /etc/hosts|grep hadoop); do \\\n  ssh-keyscan -H $servidor; done &gt;&gt; /home/cesgaxuser/.ssh/known_hosts\n</code></pre> </li> <li> <p>Copialo ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  --copy $HOME/.ssh/known_hosts \\\n  --dest $HOME/.ssh/known_hosts\n</code></pre> </li> <li> <p>Copia o <code>/etc/hosts</code> ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] --copy /etc/hosts --dest /tmp\nclush -l cesgaxuser -bw hadoop[2-4] sudo cp /tmp/hosts /etc/hosts\n</code></pre> </li> </ol>"},{"location":"apache-spark-0-instalacion/#instalacion-de-clustershell","title":"Instalaci\u00f3n de Clustershell","text":"<ol> <li> <p>Activar repo:</p> <pre><code>sudo yum --enablerepo=extras install epel-release\n</code></pre> </li> <li> <p>Instalaci\u00f3n de paquete:</p> <pre><code>sudo yum install clustershell\n</code></pre> </li> </ol>"},{"location":"apache-spark-0-instalacion/#descargar-a-maquina-de-java-amazon-corretto","title":"Descargar a m\u00e1quina de Java (Amazon Corretto)","text":"<p>Configuramos o repo de Amazon Corretto e instalamos o paquete de Java en t\u00f3dolos nodos:</p> <ol> <li> <p>Importamos a chave do repositorio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo rpm --import https://yum.corretto.aws/corretto.key\n</code></pre> </li> <li> <p>Baixamos o repositorio e o configuramos nos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo curl -L -o /etc/yum.repos.d/corretto.repo \\\n  https://yum.corretto.aws/corretto.repo\n</code></pre> </li> <li> <p>Instalamos o paquete de Java deste novo repostorio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo dnf install -y java-11-amazon-corretto-devel\n</code></pre> </li> <li> <p>Configuramos as variables do contorno: <code>nano .bashrc</code> as li\u00f1as:</p> .bashrc<pre><code>export JAVA_HOME='/usr/lib/jvm/java-11-amazon-corretto/'\nexport EDITOR=nano\nexport PATH=$PATH:$JAVA_HOME/bin\n</code></pre> <ul> <li> <p>Se non temos o editor nano, podemos empregar vi. Lembra para gardar e sair en nano: Ctrl+O [ENTER], Ctrl + X. En vi: [ESC] :wq! [ENTER]</p> </li> <li> <p>Logo de gardar, lembra recargar as variables de contorno!</p> </li> </ul> <pre><code>source ~/.bashrc\n</code></pre> </li> <li> <p>Copia ao resto de nodos esta configuraci\u00f3n:     <pre><code>clush -l cesgaxuser -bw hadoop[1-4] --copy $HOME/.bashrc \\\n  --dest $HOME/.bashrc\n</code></pre></p> </li> </ol>"},{"location":"apache-spark-0-instalacion/#descarga-de-apache-spark","title":"Descarga de Apache Spark","text":"<p>Se non che funciona a descarga, pode ser que te\u00f1as que averiguar a nova ruta por existir unha nova versi\u00f3n. Podes ir ao nivel superior da p\u00e1xina e buscar a nova versi\u00f3n: https://dlcdn.apache.org/spark/.</p> <p>Segundo as t\u00faas necesidades podes ter que escoller entre a versi\u00f3n con ou sen Apache Hadoop.</p> <p>Outra opci\u00f3n se contas con pouco ancho de banda \u00e9 baixar unha vez o arquivo dende o master e facer un --copy  a --dest con Clustershell.</p> <ol> <li> <p>Baixamos Apache Spark (actualizado a 20 de abril de 2024):</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo curl -L -O https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz \\\n  -o /home/cesgaxuser/spark-bin-hadoop3.tgz\n  sudo mv spark-3.5.5-bin-hadoop3.tgz spark-bin-hadoop3.tgz\n</code></pre> <ul> <li>G\u00e1rdase no arquivo <code>spark-bin-hadoop3.tar.gz</code> para que futuras versi\u00f3ns destes apuntes non te\u00f1an que ser mudados t\u00f3dolos comandos por mor da versi\u00f3n.</li> </ul> </li> <li> <p>Descomprimimos simult\u00e1neamente en t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo tar xzvf spark-bin-hadoop3.tgz\n</code></pre> </li> <li> <p>Configuramos as variables de contorno por comodidade <code>nano .bashrc</code>:</p> .bashrc<pre><code>export SPARK_HOME=$HOME/spark-bin-hadoop3\nexport PATH=$PATH:$SPARK_HOME/sbin/:$SPARK_HOME/bin/\n</code></pre> <ul> <li>Logo de gardar, lembra recargar as variables do contorno!</li> </ul> <pre><code>source ~/.bashrc\n</code></pre> </li> <li> <p>Copia ao resto de nodos esta configuraci\u00f3n:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] --copy $HOME/.bashrc \\\n  --dest $HOME/.bashrc\n</code></pre> </li> <li> <p>Copiamos o template de configuraci\u00f3n:</p> <pre><code>sudo cp $SPARK_HOME/conf/spark-defaults.conf.template \\\n  $SPARK_HOME/conf/spark-defaults.conf\n</code></pre> </li> <li> <p>Editamos o novo arquivo de configuraci\u00f3n:</p> <pre><code>sudo nano $SPARK_HOME/conf/spark-defaults.conf\n</code></pre> <ul> <li>Dentro do arquivo, mudamos a configuraci\u00f3n de Apache Spark para que empregue YARN (Yet Another Resource Negociator):</li> </ul> $SPARK_HOME/conf/spark-defaults.conf<pre><code>spark.master yarn\n</code></pre> </li> <li> <p>No nodo master executamos o script <code>start-master.sh</code> (estamos a executar todo como root):</p> <pre><code>sudo start-master.sh\n</code></pre> </li> <li> <p>Nos nodos slaves executamos o <code>start-worker.sh</code>:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  sudo $SPARK_HOME/sbin/start-worker.sh spark://hadoop1:7077\n</code></pre> </li> </ol>"},{"location":"apache-spark-0-instalacion/#instalacion-de-pyspark","title":"Instalaci\u00f3n de PySpark","text":"<ol> <li> <p>Instalamos Python 3.9:</p> <p><pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo dnf install -y python39\n</code></pre> - Lembra que a nivel sistema podes seleccionar o python por defecto que queres cos comandos:</p> <pre><code>sudo /usr/sbin/alternatives --config python\nsudo /usr/sbin/alternatives --config python3\n</code></pre> <ul> <li>\u26a0\ufe0f Considera que quiz\u00e1s a mellor opci\u00f3n sexa instalar miniconda e dende ah\u00ed ter un contorno estable que poidas importar a t\u00f3dolos nodos cunha versi\u00f3n concreta de funcional de: Python, ipython, pyspark, jupyterlab, ipykernel, nbclassic, nbconvert, py4j, pandas, numpy, pyarrow, fastparquet... </li> </ul> </li> <li> <p>Lanzar pyspark:</p> <pre><code>pyspark --master spark://hadoop1:7077\n</code></pre> </li> <li> <p>Configurar para que o worker arranque no inicio do servidor:</p> <pre><code>sudo crontab -e\n</code></pre> <ul> <li>De iniciarseche vi, preme a tecla INS para habilitar inserci\u00f3n de texto neste editor. Lembra que para gardar debes premer a tecla ESC e despois <code>:wq!</code> e logo premer ENTER.</li> </ul> <pre><code>@reboot /home/cesgaxuser/spark-bin-hadoop3/sbin/start-worker.sh spark://hadoop1:7077\n</code></pre> </li> <li> <p>E no master o mesmo, pero con comando master:</p> <pre><code>sudo crontab -e\n</code></pre> <ul> <li>E meter no arquivo:</li> </ul> <pre><code>@reboot /home/cesgaxuser/spark-bin-hadoop3/sbin/start-master.sh\n@reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-yarn.sh\n</code></pre> </li> <li> <p>Lembra darlle un reboot a t\u00f3dalas m\u00e1quinas para ver que todo se est\u00e1 a executar ben ao inicio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] reboot\n</code></pre> </li> </ol> <p></p>"},{"location":"apache-spark-0-instalacion/#configurando-spark-para-que-funcione-con-hadoop","title":"Configurando Spark para que funcione con Hadoop","text":"<p>O arquivo <code>.bashrc</code> tam\u00e9n debe ter a config de Apache Hadoop do exercicio anterior: En <code>.bashrc</code> aseg\u00farate que tes:</p> .bashrc<pre><code>export HADOOP_HOME='/home/cesgaxuser/hadoop-3.2.4'\nexport HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\nexport PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin\nexport LD_LIBRARY_PATH=${HADOOP_HOME}/lib/native:$LD_LIBRARY_PATH\n</code></pre> <p>E lembra ter todas as variables definidas nos arquivos -env.sh correspondentes.</p>"},{"location":"apache-spark-0-instalacion/#lanzando-traballos-con-spark-submit","title":"Lanzando traballos con spark-submit","text":"<p>Executamos dende o master con spark-submit un traballo, que deber\u00eda enviarse ao hadoop.</p> <p>Modo cluster seleccionando manualmente master de hadoop:</p> <pre><code>spark-submit --deploy-mode cluster \\\n  --master spark://hadoop1:7077\n  --class org.apache.spark.examples.SparkPi \\\n  $SPARK_HOME/examples/jars/spark-examples_2.14-3.4.2.jar 2\n</code></pre> <p>Modo cliente:</p> <pre><code>spark-submit --deploy-mode client \\\n  --class org.apache.spark.examples.SparkPi \\\n  $SPARK_HOME/examples/jars/spark-examples_2.14-3.4.2.jar 2\n</code></pre> <p>Miramos nos logs de hadoop que se executara.</p>"},{"location":"apache-spark-0-instalacion/#lendo-arquivos-do-hdfs-dende-jupyterlab","title":"Lendo arquivos do HDFS dende jupyterlab","text":"<p>Para ler arquivos do HDFS dende yarn / jupyterlab / pyspark hai que:</p> <ol> <li> <p>Crear o directorio de usuario no HDFS:</p> <pre><code>hdfs dfs -mkdir /user/\nhdfs dfs -mkdir /user/cesgaxuser\n</code></pre> </li> <li> <p>Po\u00f1er a ruta completa no c\u00f3digo:</p> ler_csv_dende_spark.py<pre><code>df = spark.read.csv(\"hdfs://hadoop1:9000/user/cesgaxuser/arquivo.csv\")\n</code></pre> <ul> <li>Ollo! se probas dende pyspark, mira que acceda ao cluster e non cree unha instancia nova propia.</li> </ul> </li> </ol>"},{"location":"apache-spark-0-instalacion/#lanzando-exemplos","title":"Lanzando exemplos","text":"<p>Se tes Apache Hadoop instalado do paso anterior, lembra que tam\u00e9n podes probar os exemplos con:</p> <pre><code>yarn jar hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar \\\n  wordcount \"books/*\" output\n</code></pre>"},{"location":"apache-spark-0-instalacion/#comandos-e-outros","title":"Comandos e outros","text":"<p>Haber\u00e1 que documentar:</p> <ul> <li> <p>hdfs dfs -put ARQUIVO</p> </li> <li> <p>hdfs dfs -ls</p> </li> <li> <p>yarn top</p> </li> <li> <p>yarn node -list</p> </li> <li> <p>yarn application (-list/-kill)</p> </li> <li> <p>jps -&gt; De java (non Spark ou Hadoop)</p> </li> </ul>"},{"location":"apache-spark-1-comandos/","title":"\u269d Apache Spark \u2014 \ud83d\udd32 Comandos","text":""},{"location":"apache-spark-1-comandos/#enviar-traballos-spark-submit","title":"Enviar traballos: spark-submit","text":"<p>Contorno CESGA:</p> <pre><code>spark-submit --driver-memory 4g --executor-memory 2g --num-executors 4 programa.py\n</code></pre> <p>Contorno propio:</p> <pre><code>spark-submit --deploy-mode cluster programa.py\n</code></pre> <p>Exemplo de c\u00f3digo para definir a variable <code>sc</code> (sparkContext)</p> programa.py<pre><code>from pyspark.sql import SparkSession\nfrom pyspark import SparkContext\n\nif __name__ == '__main__':\n    spark = SparkSession \\\n        .builder \\\n        .appName('My Application') \\\n        .getOrCreate()\n    sc = spark.sparkContext\n    # ...\n    # Aqu\u00ed vai o c\u00f3digo do teu programa\n    # ..\n    spark.stop()\n</code></pre>"},{"location":"apache-spark-1-comandos/#yarn-yet-another-resource-negotiator","title":"YARN \u2014 Yet Another Resource Negotiator","text":"<p>Mirar os logs: <pre><code>yarn logs -applicationId [APPID]\n</code></pre></p> <p>Ver t\u00f3dolos nodos</p> <pre><code>yarn node -list -all\n</code></pre> <p>Finalizar unha aplicaci\u00f3n</p> <pre><code>yarn application -kill APP_ID\n</code></pre>"},{"location":"apache-spark-1-comandos/#jps","title":"jps","text":""},{"location":"apache-sqoop-0-resumo/","title":"\ud83c\uddf8 Apache Sqoop","text":"<p>Apache Sqoop \u00e9 un proxecto xa obsoleto, a \u00faltima publicaci\u00f3n data do 18 de xaneiro de 2019. En 2021, foi movido ao \"\u00e1tico\" de Apache, o lugar onde se atopan os proxectos retirados ou que finalizaron o seu ciclo de vida ou non te\u00f1en suficientes desenvolvedores activos involucrados.</p> <p>Este proxecto perm\u00edtenos mover datos entre o HDFS (Hadoop Distributed File System) e un RDBMS (Relational Database Management System).</p> <p>Hai d\u00faas operaci\u00f3ns b\u00e1sicas que nos interesan:</p> <ul> <li>import: Importar datos ao HDFS dende un RDBMS (direcci\u00f3n: do RDBMS ao HDFS).</li> <li>export: Exportar datos do HDFS ao RDBMS (direcci\u00f3n: do HDFS ao RDBMS).</li> </ul>"},{"location":"apache-sqoop-0-resumo/#instalacion","title":"Instalaci\u00f3n","text":"<ol> <li> <p>Sigue as instrucci\u00f3ns para instalar Amazon Corretto.</p> </li> <li> <p>Baixamos a \u00faltima versi\u00f3n de Apache Sqoop: 1.4.7, descomprim\u00edmola e met\u00e9mola no PATH:   <pre><code>wget https://archive.apache.org/dist/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz\ntar -xzf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz\necho PATH=\\$PATH:\\$HOME/sqoop-1.4.7.bin__hadoop-2.6.0/bin/ &gt;&gt; $HOME/.bashrc\nsource ~/.bashrc\n</code></pre></p> </li> <li>Agora, se executamos sqoop teremos que configurar o $HADOOP_COMMON_HOME: <pre><code>Error: /home/user/sqoop-1.4.7.bin__hadoop-2.6.0/bin/../../hadoop does not exist!\nPlease set $HADOOP_COMMON_HOME to the root of your Hadoop installation.\n</code></pre></li> </ol>"},{"location":"apache-sqoop-0-resumo/#manexo","title":"Manexo","text":"<p>Imos ver o funcionamento con estes dous drivers:</p> <ul> <li>MySQL/MariaDB</li> <li>PostgreSQL</li> </ul>"},{"location":"apache-sqoop-0-resumo/#proba-de-conexion","title":"Proba de conexi\u00f3n","text":"<p>Imos probar a conectar coa BBDD world. Todos os exemplos incl\u00faen esa BBDD. Podes ver a instalaci\u00f3n de MySQL coa base de datos de proba aqu\u00ed.</p> MySQLPostgreSQL <pre><code>sqoop list-tables --username USUARIO-BD \\\n   -P --connect jdbc:mysql://IP-SERVIDOR/world\n</code></pre> <pre><code>sqoop list-tables --username USUARIO-BD \\\n   -P --connect jdbc:postgresql://IP-SERVIDOR/world\n</code></pre>"},{"location":"apache-sqoop-0-resumo/#importar-datos-no-hdfs","title":"Importar datos no HDFS","text":"<p>Direcci\u00f3n: RDBMS (BBDD) \u2192 HDFS.</p> MySQLPostgreSQL <pre><code>sqoop import --username USUARIO-BD --password abc123. \\\n  --connect jdbc:mysql://IP-SERVIDOR/world \\\n  --table country \\\n  --target-dir /user/USUARIO-HADOOP/world \\\n  --num-mappers 1\n</code></pre> <pre><code>sqoop import --username USUARIO-BD --password abc123. \\\n  --connect jdbc:postgresql://IP-SERVIDOR/world \\\n  --table country \\\n  --target-dir /user/USUARIO-HADOOP/world \\\n  --num-mappers 1\n</code></pre>"},{"location":"apache-sqoop-0-resumo/#importar-compatible-con-hive","title":"Importar compatible con HIVE","text":""},{"location":"apache-sqoop-0-resumo/#crear-taboas-en-hive","title":"Crear t\u00e1boas en HIVE","text":"<pre><code>sqoop create-hive-table \\\n  --username USUARIO-BD --password PASSWORD-BD \\\n  --connect jdbc:mysql://IP-SERVIDOR/world \\\n  --table country\n</code></pre>"},{"location":"apache-sqoop-0-resumo/#meter-os-datos-na-estrutura-creada","title":"Meter os datos na estrutura creada","text":"<pre><code>sqoop import \\\n  --username USUARIO-BD --password PASSWORD-BD \\\n  --connect jdbc:mysql://IP-SERVIDOR/world \\\n  --table country \\\n  --target-dir /user/USUARIO-HADOOP/country \\\n  --num-mappers 1 \\\n  --hive-import\n</code></pre>"},{"location":"apache-sqoop-0-resumo/#exportar-datos-do-hdfs","title":"Exportar datos do HDFS","text":"<p>Direcci\u00f3n: HDFS \u2192 RDBMS (BBDD).</p> MySQLPostgreSQL <pre><code>sqoop export \\\n  --username USUARIO-BD --password PASSWORD-BD \\\n  --connect jdbc:mysql://IP-SERVIDOR/world \\\n  --table country \\\n  --export-dir /user/USUARIO-HADOOP/country \\\n  --input-fields-terminated-by ',' \\\n  --num-mappers 1\n</code></pre> <pre><code>sqoop export \\\n  --username USUARIO-BD --password PASSWORD-BD \\\n  --connect jdbc:postgresql://IP-SERVIDOR/world \\\n  --table country \\\n  --export-dir /user/USUARIO-HADOOP/country \\\n  --input-fields-terminated-by ',' \\\n  --num-mappers 1\n</code></pre> <p>Resultado (HADOOP):</p> <pre><code>hdfs dfs -ls world\n</code></pre>"},{"location":"apache-sqoop-0-resumo/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://sqoop.apache.org/</li> <li>https://attic.apache.org/projects/sqoop.html</li> <li>https://bigdata.cesga.es/tutorials/sqoop.html#/</li> </ul>"},{"location":"apache-superset/","title":"\u267e\ufe0f Apache Superset","text":"<p>\u00c9 unha ferramenta/plataforma para visualizaci\u00f3n e exploraci\u00f3n de datos. \u00c9 compatible con innumerables SXBD.</p> <p>Permite crear paneis de instrumentos / paneis de visualizaci\u00f3n de datos / paneis de control (dashboards). Na forma de construcci\u00f3n dos paneis ten certo parecido con Microsoft Power Bi.</p>"},{"location":"apache-superset/#instalacion","title":"Instalaci\u00f3n","text":"<p>Baseado na imaxe oficial: https://hub.docker.com/r/apache/superset</p> <ul> <li>https://superset.apache.org/docs/installation/docker-builds</li> </ul> <p>Normalmente empr\u00e9gase Kubernetes para despregar supernet por mor da s\u00faa arquitectura.</p> <p>(en elaboraci\u00f3n)</p>"},{"location":"apache-superset/#exemplo","title":"Exemplo","text":"<ul> <li>https://superset.apache.org/docs/using-superset/creating-your-first-dashboard</li> </ul>"},{"location":"apache-superset/#historia","title":"Historia","text":"<p>Comezou na incubadora de proxectos de Apache en 2017. En novembro de 2024 sacou a s\u00faa primeira versi\u00f3n estable.</p>"},{"location":"apache-superset/#ligazons","title":"Ligaz\u00f3ns","text":"<ul> <li>https://superset.apache.org</li> <li>https://superset.apache.org/docs/quickstart</li> <li>https://github.com/apache/superset</li> </ul>"},{"location":"clickhouse/","title":"Clickhouse","text":"<p>Base de datos columnar e distribuida OLAP (On-Line Analytical Processing) de c\u00f3digo aberto.</p> <p>Permite xerar anal\u00edticas en tempo real empregando consultas SQL.</p>"},{"location":"clickhouse/#ligazons","title":"Ligaz\u00f3ns","text":"<ul> <li>https://clickhouse.com/</li> <li>https://github.com/ClickHouse/ClickHouse</li> </ul>"},{"location":"conda-0-config-basica/","title":"\ud83d\udc0d Conda: Contorno BigData","text":"<p>Este contorno permite facer os exercicios da clase. Imos instalar algunhas librar\u00edas b\u00e1sicas, o jupyterlab (para os notebook) e configurar o Visual Studio Code (vscode/code) por comodidade.</p> <p>Pasos:</p> <ol> <li> <p>Baixa miniconda https://repo.anaconda.com/miniconda/ e inst\u00e1lao no teu equipo. Para Microsoft Windows baixa o instalable, para GNU/Linux emprega:     <pre><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nchmod a+rx Miniconda3-latest-Linux-x86_64.sh\n./Miniconda3-latest-Linux-x86_64.sh\n</code></pre></p> </li> <li> <p>(Opcional) Mete miniconda no PATH de Microsoft Windows. O instalador di que pode dar problemas, pero \u00e9 s\u00f3 se temos configuraci\u00f3ns previas que empreguen Python e nalg\u00fans casos moi especiais (mira os pasos abaixo).</p> </li> <li> <p>Actualiza t\u00f3dolos paquetes do contorno base para que non dea problemas:     <pre><code>conda update --all\n</code></pre></p> </li> <li> <p>Borra o contorno bigdata anterior:     <pre><code>conda env remove -n bigdata\n</code></pre></p> </li> <li> <p>Crea o novo contorno bigdata e act\u00edvao:     <pre><code>conda create -n bigdata python=3.11\nconda activate bigdata\n</code></pre></p> </li> <li> <p>Instala os paquetes m\u00ednimos que imos precisar     <pre><code>conda install -c conda-forge jupyterlab ipykernel ipython \\\n   nbconvert pandas numpy pyarrow fastparquet wordcloud nltk \\\n   pymysql ipython-sql sqlalchemy selenium requests beautifulsoup4 \\\n   psycopg2\n</code></pre></p> <pre><code>conda install pip\n</code></pre> </li> </ol>"},{"location":"conda-0-config-basica/#engadir-miniconda-ao-path","title":"Engadir miniconda ao PATH","text":""},{"location":"conda-0-config-basica/#gnulinux","title":"GNU/Linux","text":"<p>O instalador ofr\u00e9cenos por defecto inicializar conda e metela no PATH, deber\u00edamos optar por esta opci\u00f3n.</p> <p>Se non o fixemos e non queremos executar de novo o instalador coa opci\u00f3n -u, ent\u00f3n podemos engadir ao final do .bashrc (considerando que ocnda estea instalado na ruta por defecto e a nivel usuario):</p> <pre><code>export PATH=$PATH:$HOME/miniconda3\n</code></pre>"},{"location":"conda-0-config-basica/#microsoft-windows","title":"Microsoft Windows","text":"<p>O instalador tam\u00e9n ofrece a posibilidade de meter conda no PATH pero o desaconsella, se non o fixeches (non \u00e9 unha opci\u00f3n por defecto) ent\u00f3n, p\u00f3delo meter manualmente como se indica a continuaci\u00f3n.</p> <p>Men\u00fa inicio -&gt; Editar las variables de entorno de esta cuenta</p> <p></p> <p></p> <p>Premer en \"Editar...\"</p> <p></p> <p>Logo en \"Nuevo\" e engadir unha entrada por li\u00f1a</p> <p>Mirar cal das d\u00faas aplica (mira os directorios e busca onde tes conda instalado) <pre><code>%USERPROFILE%\\AppData\\Local\\miniconda3\\condabin\n%USERPROFILE%\\Miniconda3\\bin\n</code></pre></p>"},{"location":"conda-0-config-basica/#configurar-visual-studio-code-vscode-con-conda-e-jupyterlab","title":"Configurar Visual Studio Code (vscode) con conda e jupyterlab","text":""},{"location":"conda-0-config-basica/#instalar-plugin-de-jupyterlab","title":"Instalar plugin de jupyterlab","text":"<p>Selecciona na roda de configuraci\u00f3n (abaixo, esquerda) a opci\u00f3n \"Extensiones\".</p> <p>Busca \"Jupyter\" do autor \"Microsoft\" e inst\u00e1lao.</p> <p></p>"},{"location":"conda-0-config-basica/#configurar-a-ruta-base-de-conda","title":"Configurar a ruta base de conda","text":"<ol> <li>Vai \u00e1 roda de configuraci\u00f3n e selecciona configuraci\u00f3n (En GNU/Linux: Ctrl+,).</li> <li>Busca <code>conda path</code>.</li> <li>No cadro pon a ruta ao executable de conda (conda.bat en Microsoft Windows)</li> </ol> <p><pre><code>/home/USUARIO/miniconda3/bin/conda\n</code></pre> </p>"},{"location":"conda-0-config-basica/#configurar-a-terminal","title":"Configurar a terminal","text":"<ol> <li>Abre o code.</li> <li> <p>Abre unha terminal (En GNU/Linux: Ctrl+Shift+`, en Microsoft Windows: Ctrl+\u00f1) e escribir o comando (en Windows podemos especificar tam\u00e9n powershell ao final):     <pre><code>conda init\n</code></pre></p> </li> <li> <p>Pecha t\u00f3dolos terminais e xa podes abrir un que ser\u00e1 inicializado no contorno base.</p> </li> </ol>"},{"location":"dbeaver-tunel-ssh/","title":"\ud83e\uddab DBeaver e t\u00faneles SSH","text":"<p>DBeaver \u00e9 un programa cliente SQL que permite ver, administrar e xestionar bases de datos. Emprega JDBC para conectarse.</p> <p>\u00c9 especialmente \u00fatil porque detecta e descarga autom\u00e1ticamente os drivers para moitos tipos diferentes de bases de datos.</p> <p>Imos ver paso a paso como configurar unha conexi\u00f3n facendo uso dun t\u00fanel SSH simple (sen saltar por m\u00e1is dun host).</p> <p>Neste exemplo configuraremos un servidor de MySQL que temos instalado mediante docker</p> <ol> <li> <p>Seleccionamos o tipo de base de datos MySQL.</p> <p></p> </li> <li> <p>Na lapela General metemos a configuraci\u00f3n b\u00e1sica: Usuario e contrasinal de base de datos, a propia base de datos \u00e1 que imos conectar (employees) e metemos como servidor localhost e porto 3306 posto que imos redireccionar un porto hacia nos.</p> <p></p> </li> <li> <p>Na lapela Driver properties mudamos o valor de allowPublicKeyRetrieval a TRUE posto que \u00e9 necesario no caso de empregar cifrado. Segundo a configuraci\u00f3n, pode ser necesario.</p> <p></p> </li> <li> <p>Na lapela SSH d\u00e1moslle ao l\u00e1piz de editar (arriba \u00e1 dereita, despois de profile). O motivo de facelo dende ah\u00ed \u00e9 poder reutilizar este perfil con m\u00e1is conexi\u00f3ns a BBDD.</p> <p></p> </li> <li> <p>Abrirase unha nova ventana, activamos o check Use SSH tunnel.</p> <p></p> </li> <li> <p>Activaranse t\u00f3dalas casi\u00f1as a curbir. Na parte de Settings, no Host/IP meteremos o enderezo IP do servidor de SSH e o porto por defecto 22. Cubrimos o usuario e seleccionamos o m\u00e9todo de autenticaci\u00f3n Private Key. Prememos no \ud83d\udcc1 cartafol laranxa e buscamos a nosa chave privada (id_rsa ou equivalente se empregas outra diferente a RSA). No passphrase ir\u00e1 o contrasinal desta chave privada (se o arquivo est\u00e1 protexido).</p> <p></p> </li> <li> <p>Seguimos cubrindo datos na parte de Advanced settings. En Local host metemos a nosa IP do interfaz de loopback (127.0.0.1) para non expo\u00f1er o servizo \u00e1 nosa rede, deixamos o porto por defecto 3306 posto que o puxemos no paso 2. En remote host metemos o servidor de BBDD ao que nos queremos conectar: 172.17.0.2 e porto por defecto: 3306.</p> <p></p> </li> <li> <p>Co perfil xa seleccionado, podemos premer no bot\u00f3n Probar conexi\u00f3n e finalmente en Finalizar</p> <p></p> </li> </ol> <p>O programa ten opci\u00f3ns para m\u00faltiples saltos no caso que precises conectarte a varios servidores ata chegar \u00e1 rede de producci\u00f3n.</p> <p>Ollo, ten en conta que se fas m\u00faltiples saltos, a velocidade poder\u00eda verse diminuida.</p>"},{"location":"docker-0-base-simple/","title":"\ud83d\udd35 Docker \u2014 Gu\u00eda b\u00e1sica","text":"<ul> <li>Baseado en: https://docs.docker.com/engine/install/debian/</li> <li>Tam\u00e9n hai dispo\u00f1ible unha presentaci\u00f3n de \ud83d\udc33 Docker / Contedores</li> </ul>"},{"location":"docker-0-base-simple/#instalacion-de-docker-en-debian","title":"Instalaci\u00f3n de docker en Debian","text":"<ol> <li> <p>Crear a m\u00e1quina en AWS / GCloud / Azure / CESGA Cloud ou instalaci\u00f3n local en Microsoft Windows con WSL (Debian ou Ubuntu) e conectarse a ela por SSH. De ser unha instancia na nube, trataremos de elexir unha distribuci\u00f3n Debian (recom\u00e9ndase a \u00faltima estable).</p> </li> <li> <p>Actualizamos ata o final a m\u00e1quina: <pre><code>sudo apt update\nsudo apt -y dist-upgrade\nsudo apt -y install curl\n</code></pre></p> </li> <li> <p>Executamos o script (gui\u00f3n) recomendado pola p\u00e1xina oficial de docker: <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh ./get-docker.sh\n</code></pre></p> </li> <li> <p>Engadimos o noso usuario ao grupo docker (para evitar empregar sudo): <pre><code>sudo usermod -a -G docker $USER\n</code></pre></p> </li> <li> <p>Sa\u00edmos da sesi\u00f3n e volvemos abrila (ou abrimos unha sesi\u00f3n sobre a actual como se indica a continuaci\u00f3n): <pre><code>sudo su - $USER\n</code></pre></p> </li> <li> <p>Probamos o docker de exemplo de hola-mundo: <pre><code>docker run hello-world\n</code></pre></p> </li> <li> <p>Xa podes probar a instalar o primeiro docker con MySQL.</p> </li> </ol> <p>Se est\u00e1s nun contorno WSL coa distribuci\u00f3n GNU/Debian instalada e recibes o erro:</p> /var/log/docker.log<pre><code>failed to start daemon: Error initializing network controller: error obtaining controller instance: failed to register \"bridge\" driver: unable to add return rule in DOCKER-ISOLATION-STAGE-1 chain:  (iptables failed: iptables --wait -A DOCKER-ISOLATION-STAGE-1 -j RETURN: iptables v1.8.9 (nf_tables):  RULE_APPEND failed (No such file or directory): rule in chain DOCKER-ISOLATION-STAGE-1\n</code></pre> <p>\u00c9 debido a que docker emprega iptables cunha versi\u00f3n modificada de nftables. Para arranxalo, podemos empregar as legacy iptables:</p> <pre><code>sudo update-alternatives --set iptables /usr/sbin/iptables-legacy\nsudo update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy\n</code></pre> <p>Despois de cambialas, dockerd deber\u00eda iniciarse correctamente (Fonte: GitHub).</p> <pre><code>sudo service docker restart\n</code></pre>"},{"location":"docker-0-base-simple/#conceptos-basicos-de-dockers","title":"Conceptos b\u00e1sicos de dockers","text":"<p>Podes ver a presentaci\u00f3n de: \ud83d\udce6 Docker / Contedores</p> <p>\u26a0\ufe0f Este resumo cont\u00e9n imprecisi\u00f3ns porque pretende ser breve.</p> <p><pre><code>mindmap\n  root((Docker))\n    Contedores\n    Imaxes\n    Volumes\n    Redes</code></pre> En docker existen os conceptos de: Contedores, imaxes, volumes e redes.</p> <p>Cando executamos un \"docker run\", cr\u00e9ase un contedor baseado nunha imaxe que se descarga de internet e arr\u00e1ncase. Este contedor \u00e9 como unha m\u00e1quina virtual xa configurada e funcionando.</p> <p>Hai imaxes xa listas en internet: https://hub.docker.com/ ou ben podemos facer a nosa.</p> <p>Unha vez creado un contedor pod\u00e9molo parar ou arrancar.</p> <p>Podemos gardar os datos en volumes ou directorios compartidos. Se non especificamos nada a informaci\u00f3n queda no contedor ou no volume que cree por defecto (se o crea).</p>"},{"location":"docker-0-base-simple/#contedores","title":"Contedores","text":"<ul> <li>Ver contedores en execuci\u00f3n: <code>docker ps</code></li> <li>Ver t\u00f3dolos contedores: <code>docker ps -a</code></li> <li>Crear un contedor: <code>docker run hello-world</code><ul> <li><code>-d</code>: modo dettached (execuci\u00f3n en segundo plano).</li> <li><code>--rm</code>: borra a instancia cando se para.</li> </ul> </li> <li>Parar un contedor: <code>docker stop [ID ou NOME]</code></li> <li>Iniciar un contedor: <code>docker start [ID ou NOME]</code></li> <li>Executar un comando dentro do contenedor: <code>docker exec -it [ID ou NOME] [COMANDO]</code><ul> <li><code>-it</code>: Modo interactivo</li> </ul> </li> <li>Ver t\u00f3dalas opci\u00f3ns do contedor: <code>docker inspect [ID ou NOME]</code></li> <li>Borrar un contedor: <code>docker rm [ID ou NOME]</code></li> </ul> <p>\ud83d\udc41\ufe0f Se queremos que os contedores volvan executarse cando a m\u00e1quina se reinicie, cando no momento da creaci\u00f3n (run) do contedor podemos especificar a opci\u00f3n: <code>--restart unless-stopped</code></p>"},{"location":"docker-0-base-simple/#imaxes","title":"Imaxes","text":"<ul> <li>Ver imaxes: <code>docker image ls</code></li> <li>Borrar imaxe: <code>docker image rm [ID ou NOME]</code></li> </ul>"},{"location":"docker-0-base-simple/#volumes","title":"Volumes","text":"<ul> <li>Ver volume: <code>docker volume ls</code></li> <li>Borrar volume: <code>docker volume rm [ID ou NOME]</code></li> </ul>"},{"location":"docker-0-base-simple/#volumes-en-cada-contedor","title":"Volumes en cada contedor","text":"<p>Se queremos ver qu\u00e9 volumes est\u00e1n asociados a que contedor:</p> <pre><code>docker ps -a --no-trunc --format \"{{.Names}}: {{.Mounts}}\"\n</code></pre>"},{"location":"docker-0-base-simple/#recuperando-datos-dun-volume","title":"Recuperando datos dun volume","text":"<p>\ud83d\udc41\ufe0f Se queremos ver os datos dun volume que xa non est\u00e1 asociado a un contedor, podemos crear un contedor temporal para velos: <code>docker run -it --rm -v [ID do volume]:/vol busybox ls -l /vol</code></p>"},{"location":"docker-0-base-simple/#asociar-un-volume-previo-a-un-contedor","title":"Asociar un volume previo a un contedor","text":"<pre><code>docker run -p 9907:3306 --name contedor_mariadb \\\n  -v ID_VOLUME:/var/lib/mysql \\\n  --restart unless-stopped \\\n  -d mariadb:latest\n</code></pre> <p>Se <code>ID_VOLUME</code> o cambiamos por un directorio, estar\u00edamos a mapear un directorio do anfitri\u00f3n.</p>"},{"location":"docker-0-base-simple/#estados-dun-contedor","title":"Estados dun contedor","text":"<pre><code>---\ntitle: Estados dun contenedor docker\n---\nstateDiagram-v2\n    [*] --&gt; Creado\n    Creado --&gt; En_Execuci\u00f3n\n    En_Execuci\u00f3n --&gt; Parado_Rematado\n    En_Execuci\u00f3n --&gt; Erro\n    En_Execuci\u00f3n --&gt; Pausado\n    Pausado --&gt; En_Execuci\u00f3n\n    Parado_Rematado --&gt; Erro\n    Parado_Rematado --&gt; En_Execuci\u00f3n\n    Parado_Rematado --&gt; Borrado\n    Parado_Rematado --&gt; Morto\n    Erro --&gt; En_Reinicio\n    En_Reinicio --&gt; Erro\n    En_Reinicio --&gt; En_Execuci\u00f3n\n    Morto --&gt; Borrado\n    Borrado --&gt; [*]\n</code></pre> <p>Realmente existen 6 estados. O estado borrado \u00e9 para que se vexa mellor no diagrama m\u00e1is non \u00e9 un estado. O <code>Erro</code> ou <code>Morto</code> poden ser o mesmo estado nalgunhas circunstancias.</p> <p>M\u00e1is informaci\u00f3n acerca dos estados en: https://www.baeldung.com/ops/docker-container-states.</p>"},{"location":"docker-0-base-simple/#imaxes-oficiales-para-docker-que-podes-probar","title":"Imaxes oficiales para docker que podes probar","text":"<p>Nesta p\u00e1xina tes algunhas configuraci\u00f3ns r\u00e1pidas (exemplos xa feitos) baseados nestas imaxes:</p> <ul> <li>https://hub.docker.com/_/mysql</li> <li>https://hub.docker.com/_/mariadb</li> <li>https://mariadb.com/kb/en/installing-and-using-mariadb-via-docker/</li> <li>https://hub.docker.com/_/microsoft-mssql-server</li> <li>https://hub.docker.com/_/mongo</li> <li>https://hub.docker.com/_/redis</li> <li>https://hub.docker.com/_/postgres</li> <li>https://hub.docker.com/_/cassandra</li> </ul>"},{"location":"docker-1-my-maria/","title":"\ud83e\uddfe MySQL / MariaDB","text":"<ul> <li>Baseado nas imaxes oficiais:<ul> <li>MySQL: https://hub.docker.com/_/mysql</li> <li>MariaDB: https://hub.docker.com/_/mariadb</li> </ul> </li> </ul>"},{"location":"docker-1-my-maria/#instalacion","title":"Instalaci\u00f3n","text":"<p>\u00c9 recomendable crear previamente un volume cun nome para ter localizado onde temos os datos e que non se borre se executamos un <code>docker volume prune</code>.</p> <p>Tam\u00e9n imos crear un directorio compartido, deste xeito resultar\u00e1 m\u00e1is f\u00e1cil importar as bases de datos de proba sen ter que instalar outro cliente ou ter problemas por non estar no directorio correcto durante a importaci\u00f3n.</p> <pre><code>docker volume create bbddvol\nmkdir -p $HOME/bd\n</code></pre> <p>Agora creamos o contedor. O volume estar\u00e1 asociado ao directorio coa base de datos:</p> <p>\u26a0\ufe0f Emprega o bot\u00f3n copiar da dereita para que non fallen os saltos de li\u00f1as e caracteres especiais nas diferentes terminais.</p> MySQLMariaDB <pre><code>docker run -p 9906:3306 --name bbdd \\\n  -v bbddvol:/var/lib/mysql \\\n  -v $HOME/bd:/bd \\\n  -e MYSQL_RANDOM_ROOT_PASSWORD=1 \\\n  -e MYSQL_DATABASE=basededatos \\\n  -e MYSQL_USER=usuario \\\n  -e MYSQL_PASSWORD=ContrasinalMariano123. \\\n  --restart unless-stopped \\\n  -d mysql:8\n</code></pre> <pre><code>docker run -p 9906:3306 --name bbdd \\\n  -v bbddvol:/var/lib/mysql \\\n  -v $HOME/bd:/bd \\\n  -e MARIADB_RANDOM_ROOT_PASSWORD=1 \\\n  -e MARIADB_DATABASE=basededatos \\\n  -e MARIADB_USER=usuario \\\n  -e MARIADB_PASSWORD=ContrasinalMariano123. \\\n  --restart unless-stopped \\\n  -d mariadb:latest\n</code></pre> <p>Aclaraci\u00f3ns:</p> <ul> <li><code>-p 9906:3306</code> redirixe o porto <code>9906</code> do anfitri\u00f3n ao porto <code>3306</code> do contedor.</li> <li><code>--env</code> ou <code>-e</code> serven para definir variables de entorno (configuraci\u00f3n) presentes na imaxe.</li> <li><code>-v</code> permite asociar (montar) un directorio local a un directorio de dentro do contedor. Poder\u00edamos asociado un directorio local <code>/home/user/mysqldatos</code> ao contedor en <code>/var/lib/mysql</code> co par\u00e1metro: <code>-v /home/user/mysqldatos:/var/lib/mysql</code>. Tam\u00e9n poder\u00edamos mapear un volume anterior con: <code>-v ID_DO_VOLUME:/var/lib/mysql</code>.</li> <li><code>--restart unless-stopped</code> Recupera no reinicio o estado do contedor (volve arrancalo) salvo que se parase expl\u00edcitamente.</li> <li><code>-d</code> Executa o contedor en modo dettached (devolve o control \u00e1 consola tras a s\u00faa execuci\u00f3n).</li> </ul> <p>\u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f NON ESQUEZAS APUNTAR O CONTRASINAL DE ROOT:</p> <p>Para saber o contrasinal de root asignado aleatoriamente debemos buscar nos logs unha li\u00f1a que conte\u00f1a: <code>\"[Note] [Entrypoint]: GENERATED ROOT PASSWORD:\"</code>. Tras executar o contedor, dalle 20 segundos para que arranque de todo e executa:</p> <p><pre><code>docker logs bbdd\n</code></pre> Tam\u00e9n precisaremos o enderezo IP do contedor, p\u00f3delo averiguar con:</p> <pre><code>docker inspect bbdd\n</code></pre> <p>E buscar a li\u00f1a \"IPAddress\": \"XXX.XXX.XXX.XXX\" dentro de \"NetworkSettings\" (as X son n\u00fameros).</p> <p>Apunta nun arquivo o enderezo IP e o contrasinal de root. Vas necesitalo varias veces!</p> <p>Se est\u00e1s executando unha instancia ou m\u00e1quina, tam\u00e9n \u00e9 conveniente que averigues e apuntes o seu enderezo IP.</p> <p>Por \u00faltimo comprobamos que te\u00f1amos correctamente asociado o volume de datos ao noso contedor:</p> <pre><code>docker ps -a --no-trunc --format \"{{.Names}}: {{.Mounts}}\"\n</code></pre>"},{"location":"docker-1-my-maria/#recuperar-instancia-de-mysql-co-seu-volume","title":"Recuperar instancia de MySQL co seu volume","text":"<p>Se queremos recuperar unha instancia borrada, sempre e cando non borr\u00e1semos o seu volume de datos, anterior (non fai falta especificar usuarios ou contrasinais):</p> MySQLMariaDB <pre><code>docker run -p 9906:3306 --name bbdd \\\n  -v bbddvol:/var/lib/mysql \\\n  -v $HOME/bd:/bd \\\n  --restart unless-stopped \\\n  -d mysql:8\n</code></pre> <pre><code>docker run -p 9906:3306 --name bbdd \\\n  -v bbddvol:/var/lib/mysql \\\n  -v $HOME/bd:/bd \\\n  --restart unless-stopped \\\n  -d mariadb:latest\n</code></pre>"},{"location":"docker-1-my-maria/#cli-conexion-directa-co-cliente","title":"(CLI) Conexi\u00f3n directa co cliente","text":"Conectar co cliente do docker (MySQL)Conectar cun cliente doutro host (MySQL)Conectar co cliente do docker (MariaDB)Conectar cun cliente doutro host (MariaDB) <pre><code>docker exec -it bbdd mysql -uusuario -pContrasinalMariano123.\n</code></pre> <ul> <li>Podemos engadir <code>-hX.X.X.X</code> para conectar con outro equipo.</li> </ul> <pre><code>mysql -hX.X.X.X -P9906 -uusuario -pContrasinalMariano123.\n</code></pre> <ul> <li><code>X.X.X.X</code> \u00e9 a IP do servidor ao que queremos conectar.</li> </ul> <pre><code>docker exec -it bbdd mariadb -uusuario -pContrasinalMariano123.\n</code></pre> <ul> <li>Podemos engadir <code>-hX.X.X.X</code> para conectar con outro equipo.</li> </ul> <pre><code>mariadb -hX.X.X.X -P9906 -uusuario -pContrasinalMariano123.\n</code></pre> <ul> <li><code>X.X.X.X</code> \u00e9 a IP do servidor ao que queremos conectar.</li> </ul> <p>Nota: Dende consola, en caso de certos caracteres especiais, p\u00f3dense escapar con barra invertida ou po\u00f1er todo o contrasinal entre comillas simples.</p>"},{"location":"docker-1-my-maria/#gui-conectar-a-mariadbmysql-con-dbeaver","title":"(GUI) Conectar a MariaDB/MySQL con DBeaver","text":"<p>Se queremos conectar dende DBeaver na nosa m\u00e1quina local e temos instalado o contedor de MariaDB/MySQL nunha m\u00e1quina remota, tampouco debemos esquecer configurar o porto:</p> <p></p> <p>Na lapela Driver properties lembra mudar o valor de allowPublicKeyRetrieval a TRUE posto que \u00e9 necesario no caso de empregar cifrado. Segundo a configuraci\u00f3n, pode ser necesario.</p> <p>Podes acceder a un manual m\u00e1is detallado en \ud83e\uddab DBeaver e t\u00faneles SSH onde tam\u00e9n aprender\u00e1s como realizar un t\u00fanel SSH. Este t\u00fanel pode ser necesario si o servidor de base de datos est\u00e1 detr\u00e1s dun firewall.</p>"},{"location":"docker-1-my-maria/#comandos-basicos","title":"Comandos b\u00e1sicos","text":"<ul> <li>Ver as bases de datos:     <pre><code>show databases;\n</code></pre></li> <li>Seleccionar unha base de datos:      <pre><code>use database;\n</code></pre></li> <li>Ver as t\u00e1boas da BBDD actual seleccionada:      <pre><code>show tables;\n</code></pre></li> <li>Ver informaci\u00f3n do estado do servidor:     <pre><code>\\s\n</code></pre></li> <li>Sa\u00edr do cliente. Tam\u00e9n funcionar\u00eda: <code>quit</code> ou <code>Crtl+D</code>:     <pre><code>\\q\n</code></pre></li> <li>Executar un arquivo .sql (\u00fatil para recuperar un backup)     <pre><code>source /ruta/ao/arquivo.sql\n</code></pre></li> </ul>"},{"location":"docker-1-my-maria/#crear-usuario-bbdd-e-permisos","title":"Crear usuario, BBDD e permisos","text":"<pre><code>CREATE USER 'usuario-a-crear'@'%' IDENTIFIED BY 'contrasinal-abc123.';\nGRANT ALL PRIVILEGES ON base-de-datos.* TO 'usuario-a-crear'@'%';\nFLUSH PRIVILEGES;\n</code></pre>"},{"location":"docker-1-my-maria/#importar-bbdd-de-proba","title":"Importar BBDD de proba","text":"<p>Debes saber o contrasinal de root (mira arriba).</p> <p>Este exemplo funciona se seguiches as instrucci\u00f3ns e hai un directorio compartido no contedor.</p> <p>Descargamos dende a m\u00e1quina as d\u00faas bases de datos de proba</p> <pre><code>cd $HOME/bd\nwget https://github.com/datacharmer/test_db/releases/download/v1.0.7/test_db-1.0.7.tar.gz\nwget https://downloads.mysql.com/docs/world-db.tar.gz\ntar -xzf test_db-1.0.7.tar.gz\ntar -xzf world-db.tar.gz\ncd test_db\ndocker exec -it bbdd /bin/bash\n</code></pre> <p>Agora estamos dentro do docker, conectamos co cliente:</p> MySQLMariaDB <pre><code>cd /bd/test_db\nmysql -hlocalhost -uroot -p\n</code></pre> <pre><code>cd /bd/test_db\nmariadb -hlocalhost -uroot -p\n</code></pre> <p>Escribe o contrasinal que tes apuntado para acceder e entrar\u00e1s na consola de MySQL/MariaDB, despois executa os scripts para crear as bases de datos, os usuarios e dar permisos.</p> <pre><code>SOURCE employees.sql\nCREATE USER 'empregado'@'%' IDENTIFIED BY 'Exemplar.123';\nGRANT ALL PRIVILEGES ON employees.* TO 'empregado'@'%';\nSOURCE ../world-db/world.sql\nCREATE USER 'mundo'@'%' IDENTIFIED BY 'MundoMundial.456';\nGRANT ALL PRIVILEGES ON world.* TO 'mundo'@'%';\nFLUSH PRIVILEGES;\nSHOW DATABASES;\n</code></pre> <p>Webgraf\u00eda:</p> <ul> <li>https://dev.mysql.com/doc/employee/en/employees-installation.html (https://github.com/datacharmer/test_db)</li> <li>https://downloads.mysql.com/docs/world-db.tar.gz</li> </ul>"},{"location":"docker-1-my-maria/#backup-con-mysqldump","title":"Backup con MySQLdump","text":"Backup dunha BBDDBackup de todas as BBDD <pre><code>mysqldump -uUSUARIO -pCLAVE --databases BASE_DATOS &gt; YYYY-mm-dd_mysql_backup.sql\n</code></pre> <pre><code>mysqldump -uUSUARIO -pCLAVE --all-databases &gt; YYYY-mm-dd_mysql_backup.sql\n</code></pre>"},{"location":"docker-1-my-maria/#conectar-a-mysql-dende-python","title":"Conectar a MySQL dende Python","text":"<ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/mysql.ipynb</li> </ul> <p>\u26a0\ufe0f AVISO: Esta configuraci\u00f3n NON pretende ser segura, o seu obxectivo \u00e9 montar de xeito r\u00e1pido un contorno para a aprendizaxe. Entre outras cousas deber\u00edamos deshabilitar o usuario root para conexi\u00f3ns remotas, borrar as BBDD de proba e impedir o acceso directo ao servidor de base de datos.</p>"},{"location":"docker-1-my-maria/#adicional","title":"Adicional","text":"<p>Env\u00edo de arquivo a servidor remoto por scp</p> <p>Se estiveras a conectar a un servidor remoto que non permite descargar arquivos externos, deber\u00e1s baixar o script en local e logo copialo ao servidor:</p> <pre><code>scp -i chave-ssh.key employees_db-full-1.0.7.tar.gz usuario@IP-DO-SERVIDOR:/tmp/\n</code></pre> <p>Problemas de versi\u00f3n (engine)</p> <p>Se est\u00e1s a traballar coa versi\u00f3n: employees_db-full-1.0.6.tar.bz2 pode ser que te\u00f1as alg\u00fan problema co engine. Neste caso, engadir \"default_\" diante das d\u00faas li\u00f1as en employees.sql axuda. Fonte: stackoverflow.</p> <p>Porto aberto?</p> <p>En GNU/Linux podes ver qu\u00e9 portos est\u00e1n abertos con:</p> <pre><code>netstat -atun\n</code></pre> <p>En docker podes ver as redirecci\u00f3ns de portos don <code>docker inspect</code>.</p> <p>No caso de instalaci\u00f3n con docker, se ves que non tes aberto o 9906/9907 (segundo o exemplo) no anfitri\u00f3n ou o 3306 onde te\u00f1as MySQL, probablemente debas cambiar o bind-address na configuraci\u00f3n de MySQL ou MariaDB.</p> <p>Edita o arquivo correspondente (en MySQL: /etc/mysql/mysql.conf.d/mysqld.cnf) e mete ou descomenta esta li\u00f1a:</p> <pre><code>bind-address por 0.0.0.0\n</code></pre> <p>Ollo! Si \u00e9 que non conectas ao porto 3306 pero o ves aberto, moi probablemente estea filtrado no firewall (na computaci\u00f3n na nube \u00e1s veces filtran ese porto a\u00ednda que t\u00ed o abras expl\u00edcitamente).</p>"},{"location":"docker-2-mongodb/","title":"\ud83e\uddfe MongoDB","text":"<ul> <li> <p>Baseado na imaxe oficial: https://hub.docker.com/_/mongo</p> </li> <li> <p>Se queres instalar mongo en modo replica set ou sharded cluster, consulta a presentaci\u00f3n.</p> </li> </ul>"},{"location":"docker-2-mongodb/#introducion","title":"Introduci\u00f3n","text":"<p>Podemos executar MongoDB de tres modos diferentes:</p> <ul> <li>Standalone server: Un s\u00f3 servidor, \u00fatil para desenvolvemento e probas.</li> <li>Replica set (ou cluster simple): \u00datil en produci\u00f3n, varias instancias de servidor en execuci\u00f3n. Engade redundancia e dispo\u00f1ibilidade (escalado horizontal).</li> <li>Sharded cluster: \u00datil en produci\u00f3n, varias instancias de servidor en execuci\u00f3n. Engade a posibilidade de particionar os datos. Permite un manexo de alto volume de datos e operaci\u00f3ns.</li> </ul> <p>Non confundamos estes modos de operaci\u00f3n coa licencia ou version de mongo:</p> <ul> <li>Community: Gratuita.</li> <li>Enterprise: Versi\u00f3n comercial con soporte e optimizaci\u00f3ns. Gratuita para desenvolvemento.</li> <li>Atlas: Versi\u00f3n na nube. Gratuita ata 512MB.</li> </ul>"},{"location":"docker-2-mongodb/#instalacion-en-modo-standalone-server-simple","title":"Instalaci\u00f3n en modo standalone server (simple):","text":"<ul> <li> <p>Instalaci\u00f3n:</p> <pre><code>docker run -d --name mongo \\\n  -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \\\n  -e MONGO_INITDB_ROOT_PASSWORD=abc123Secret \\\n  -p 27017:27017 \\\n  mongo\n</code></pre> </li> <li> <p>Conexi\u00f3n con par\u00e1metros:</p> <pre><code>docker exec -it mongo \\\nmongosh --host localhost --port 27017 --apiVersion 1 \\\n--username mongoadmin --password abc123Secret\n</code></pre> </li> <li> <p>Conexi\u00f3n con URL:</p> <pre><code>docker exec -it mongo mongosh \\\n  \"mongodb://mongoadmin:abc123Secret@localhost:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000\"\n</code></pre> </li> </ul> <p>No docker de instalaci\u00f3n, podes mapear un cartafol co host para ver como almacena mongo os datos coa opci\u00f3n: <code>-v /root/mongo:/data/db</code>, m\u00e1is o recomendado \u00e9 gardar os datos nun volume.</p> <p>Webgraf\u00eda:</p> <ul> <li>https://hub.docker.com/_/mongo</li> <li>https://www.mongodb.com/docs/mongodb-shell/connect/</li> </ul>"},{"location":"docker-2-mongodb/#conexion-a-mongodb-cliente","title":"Conexi\u00f3n a mongodb (cliente)","text":"<p>Estas instrucci\u00f3n son s\u00f3 no caso de querer instalar o cliente en local. Lembremos que sempre podemos conectar co cliente mongosh de dentro do contedor.</p> <p>Instrucci\u00f3ns para GNU/Linux Debian 12 Bookworm:</p> <ol> <li> <p>Instalaci\u00f3n de dependencias:     <pre><code>sudo apt-get install gnupg curl\n</code></pre></p> </li> <li> <p>Baixar a chave GNUpg que firma os paquetes do repositorio:</p> <pre><code>curl -fsSL https://www.mongodb.org/static/pgp/server-7.0.asc | \\\n sudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg \\\n --dearmor\n</code></pre> </li> <li> <p>Engadir o novo repositorio:</p> <pre><code>echo \"deb [ signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] http://repo.mongodb.org/apt/debian bookworm/mongodb-org/7.0 main\" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list\n</code></pre> </li> <li> <p>Actualizar a informaci\u00f3n de paquetes dos repositorios:</p> <pre><code>sudo apt-get update\n</code></pre> </li> <li> <p>Instalar os paquetes:</p> <pre><code>sudo apt-get install -y mongodb-org\n</code></pre> </li> </ol> <p>Coidado co ulimit! O n\u00famero de arquivos abertos m\u00e1ximos debe ser superior a 64.000.</p> <p>Webgraf\u00eda: - https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-debian/</p>"},{"location":"docker-2-mongodb/#gui-conectar-con-compass","title":"(GUI) Conectar con Compass","text":"<p>Compass \u00e9 un cliente gr\u00e1fico gratuito oficial que nos permite conectar con Mongo e mesmo ver algunhas estat\u00edsticas do servidor. Debido a que mongodb \u00e9 amplamente empregado no mundo empresarial, moitos clientes de base de datos que te\u00f1en versi\u00f3n community soen ser de pago con mongo (exemplo: DBeaver).</p> <p>Podes baixar compass da s\u00faa p\u00e1xina oficial: - https://www.mongodb.com/products/tools/compass</p> <p>E para conectar, podes empregar a cadea de conexi\u00f3n:</p> <p><code>mongodb://mongoadmin:abc123Secret@localhost:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000</code></p> <p>Lembra premer no bot\u00f3n de \"Save and connect\" para gardar a conexi\u00f3n co usuario e contrasinal \u00e1 esquerda e non ter que volver introducilos manualmente (ou ter que introducir a cadea de conexi\u00f3n que tam\u00e9n incl\u00fae eses datos).</p>"},{"location":"docker-2-mongodb/#conectar-contra-atlas-servidor-na-nube","title":"Conectar contra Atlas (servidor na nube)","text":""},{"location":"docker-2-mongodb/#cli-mongosh-contra-atlas","title":"(CLI) Mongosh contra atlas","text":"<ul> <li> <p>Chamamos \u00e1 consola mongosh cos par\u00e1metros:</p> <pre><code> mongosh \"mongodb+srv://.../\" --apiVersion 1 --username USUARIO\n</code></pre> </li> </ul>"},{"location":"docker-2-mongodb/#cli-cliente-atlas","title":"(CLI) Cliente Atlas","text":"<ul> <li> <p>Instalaci\u00f3n:</p> <pre><code>sudo apt install mongodb-atlas-cli\n</code></pre> </li> <li> <p>Iniciar sesi\u00f3n:</p> <pre><code>atlas auth login\n</code></pre> </li> </ul>"},{"location":"docker-2-mongodb/#lecturas-complementarias","title":"Lecturas complementarias","text":"<ul> <li>Apuntes de MongoDB en formato presentaci\u00f3n</li> <li>Conectar a MongoDB dende Python (notebook)</li> <li>Como securizar un servidor mongo accesible en internet (ingl\u00e9s, p\u00e1xina oficial)</li> </ul>"},{"location":"docker-2-mongodb/#creando-un-clusterreplica-set-de-mongo-en-docker","title":"Creando un cluster/replica set de mongo en docker","text":"<p>Fai falta seguir uns pasos l\u00f3xicos: Crear una nova rede en docker para que se comuniquen os contedores entre eles, executar alomenos tres contedores de mongo asociados a esa rede e finalmente facer que se unan entre eles nun replica set.</p>"},{"location":"docker-2-mongodb/#crear-a-rede-en-docker","title":"Crear a rede en docker","text":"<p>Como en calquer caso, creamos unha nova rede cun nome que nos guste:</p> <pre><code>docker network create mongoReplicado\n</code></pre>"},{"location":"docker-2-mongodb/#lanzar-os-contedores","title":"Lanzar os contedores","text":"<pre><code>docker run -d -p 27017:27017 --name mongoVermello --network mongoReplicado mongo mongod --replSet replicados --bind_ip localhost,mongoVermello\ndocker run -d -p 27027:27017 --name mongoVerde --network mongoReplicado mongo mongod --replSet replicados --bind_ip localhost,mongoVerde\ndocker run -d -p 27037:27017 --name mongoAzul --network mongoReplicado mongo mongod --replSet replicados --bind_ip localhost,mongoAzul\n</code></pre> <p>Os portos redirixidos do anfitri\u00f3n ao contedor van ser os seguintes:</p> <ul> <li>27017: mongoVermello (o por defecto)</li> <li>27027: mongoVerde</li> <li>27037: mongoAzul</li> </ul>"},{"location":"docker-2-mongodb/#unir-os-servidores","title":"Unir os servidores","text":"<pre><code>docker exec -it mongoVermello mongosh --eval \"rs.initiate({\n _id: \\\"replicados\\\",\n members: [\n   {_id: 0, host: \\\"mongoVermello\\\"},\n   {_id: 1, host: \\\"mongoVerde\\\"},\n   {_id: 2, host: \\\"mongoAzul\\\"}\n ]\n})\"\n</code></pre>"},{"location":"docker-2-mongodb/#probar-que-estean-funcionando-en-modo-replica-set","title":"Probar que estean funcionando en modo replica set","text":"<pre><code>docker exec -it mongoVermello mongosh --eval \"rs.status()\"\n</code></pre> <p>E se paramos o \"principal\":</p> <pre><code>docker stop mongoVermello\n</code></pre> <p>E consultamos os outros, todo deber\u00eda seguir funcionando igual, os datos seguen dispo\u00f1ibles:</p> <pre><code>docker exec -it mongoVerde mongosh --eval \"rs.status()\"\ndocker exec -it mongoAzul mongosh --eval \"rs.status()\"\n</code></pre> <p>Webgraf\u00eda:</p> <ul> <li>https://www.mongodb.com/resources/products/compatibilities/deploying-a-mongodb-cluster-with-docker</li> <li>https://www.mongodb.com/docs/manual/tutorial/convert-standalone-to-replica-set/</li> <li>https://www.mongodb.com/docs/manual/reference/replica-configuration/#std-label-replica-set-configuration-document</li> </ul>"},{"location":"docker-2-mongodb/#conversion-do-replica-set-a-sharded-cluster","title":"Conversi\u00f3n do Replica Set a Sharded Cluster","text":"<p>O principal obxectivo deste tipo de configuraci\u00f3n \u00e9 ter particionado os datos cunha shard key.</p> <p>Hai un titorial na web oficial de mongodb sobre como pasar dun replica set (con autenticaci\u00f3n habilitada) a un sharded cluster:</p> <ul> <li>https://www.mongodb.com/docs/manual/tutorial/convert-replica-set-to-replicated-shard-cluster/</li> </ul>"},{"location":"docker-3-redis/","title":"\ud83e\uddfe Redis","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/r/redis/redis-stack-server</li> </ul> <p>Creamos o volume para persisitir os datos (opcional):</p> <pre><code>docker volume create redis-data\n</code></pre>"},{"location":"docker-3-redis/#creamos-o-docker","title":"Creamos o docker:","text":"<pre><code>docker run -d --name redis-stack \\\n    -v redis-data:/data \\\n    -e REDIS_ARGS=\"--requirepass 123quetal123\" \\\n    -p 6379:6379 -p 8001:8001 \\\n    redis/redis-stack:latest\n</code></pre>"},{"location":"docker-3-redis/#cli-conectando-a-redis-dende-o-propio-docker","title":"(CLI) Conectando a redis dende o propio docker:","text":"<pre><code>docker exec -it redis-stack \\\n    redis-cli -h localhost -p 6379 -a 123quetal123\n</code></pre> <p>Se non especificamos o contrasinal con <code>-a 123quetal123</code> en li\u00f1a de comandos, para autenticarnos deberemos po\u00f1er o comando: <code>AUTH 123quetal123</code> dentro do cliente de redis.</p> <p>Dentro da consola de texto de redis, creamos un usuario:</p> <pre><code>acl setuser usuarioredis &gt;contrasinal123inseguro on allchannels allkeys +get +set +del +info +scan +exists +hset +type +expire +getrange +hlen +hscan +hdel +sadd +srem +scard +sscan +sismember +lpush +llen +lset +rpushx +lrange +zrange +zadd +xadd +zcard +json.set +json.get +slowlog +hget|get +config|get +xinfo|stream\n</code></pre> <pre><code>docker exec -it redis-stack \\\n    redis-cli --user usuarioredis --pass contrasinal123inseguro\n</code></pre>"},{"location":"docker-3-redis/#gui-conexion-contra-redisinsight","title":"(GUI) Conexi\u00f3n contra redisinsight","text":"<p>Se empregaches a configuraci\u00f3n de docker de enriba, s\u00f3 tes que conectar \u00e1 IP da m\u00e1quina do docker ao porto 8081. Por exemplo: http://localhost:8001. Inicia sesi\u00f3n co usuario <code>usuarioredis</code> e o contrasinal <code>contrasinal123inseguro</code>.</p>"},{"location":"docker-3-redis/#outras-variables-de-contorno-do-docker","title":"Outras variables de contorno do docker","text":"<p>Segundo a documentaci\u00f3n da imaxe oficial, temos acceso a modificar as seguintes variables de contorno:</p> <ul> <li>REDIS_ARGS: Redis</li> <li>REDISEARCH_ARGS: RediSearch</li> <li>REDISJSON_ARGS: RedisJSON</li> <li>REDISGRAPH_ARGS: RedisGraph</li> <li>REDISTIMESERIES_ARGS: RedisTimeSeries</li> <li>REDISBLOOM_ARGS: RedisBloom</li> </ul> <p>Por exemplo, se quix\u00e9ramos persistir os datos no RedisTimeSeries, podemos engadir unha variable de contorno \u00e1 creaci\u00f3n do docker:</p> <p><code>-e REDISTIMESERIES_ARGS=\"RETENTION_POLICY=20\"</code></p>"},{"location":"docker-3-redis/#comandos-utiles","title":"Comandos \u00fatiles:","text":"<ul> <li>Autenticarse: <code>AUTH contrasinal</code></li> <li>Probar se estamos conectados: <code>PING</code></li> <li>Almacenar unha clave (KEY-VALUE): <code>set clave valor</code> </li> <li>Recuperar unha clave: <code>get clave</code></li> <li>Almacenar datos JSON: <code>JSON.SET clave $ valor_json</code></li> <li>Recuperar datos JSON: <code>JSON.GET clave $</code></li> <li>Recuperar datos HASH: <code>HGET clave $</code></li> <li>Establecer ou mudar o contrasinal: <code>config set requirepass 123quetal123</code></li> <li>Crear un usuario: <code>acl setuser ...</code></li> <li>Pedir clave no CLI: <code>config set requirepass 123quetal123</code></li> <li>Mostrar as claves: <code>keys *</code></li> </ul>"},{"location":"docker-3-redis/#uso-con-python","title":"Uso con Python","text":"<p>Instalar as librar\u00edas con conda para poder conectar a redis:</p> <pre><code>!conda install -y -c conda-forge redis-py sqlalchemy\n</code></pre> <p>C\u00f3digo de python:</p> redis.py<pre><code>#from redis import Redis\nempregamos_docker=True\n\nimport redis\n\ndata = {\n    'dog': {\n        'scientific-name' : 'Canis familiaris'\n    }\n}\n\nr = redis.Redis(password=\"123quetal123\")\n#r.auth(\"123quetal123\")\nr.ping()\n#Non instalado no escenario a extensi\u00f3n JSON\n\nif (empregamos_docker):\n    r.json().set('doc', '$', data)\n    doc = r.json().get('doc', '$')\n    dog = r.json().get('doc', '$.dog')\n    scientific_name = r.json().get('doc', '$..scientific-name')\n    print(scientific_name)\n</code></pre> <p>Podes descargar o notebook de:</p> <ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/redis.ipynb</li> </ul>"},{"location":"docker-3-redis/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://redis.io/docs/latest/develop/data-types/</li> </ul>"},{"location":"docker-4-postgresql/","title":"\ud83e\uddfe PostgreSQL","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/_/postgres</li> </ul>"},{"location":"docker-4-postgresql/#instalacion-co-docker","title":"Instalaci\u00f3n co docker","text":"<pre><code>docker run --name de-postre-sql -e POSTGRES_PASSWORD=Cl431Ns3gur4 \\\n    -p 5432:5432 -p 5433:5433 -d postgres\n</code></pre> <p>Se non che funciona a conexi\u00f3n dende o exterior, cambia o porto a outro que non sexa co\u00f1ecido. Alg\u00fans servizos poden bloquear, por seguridade, portos co\u00f1ecidos.</p>"},{"location":"docker-4-postgresql/#conexion-simple-co-cliente-nativo","title":"Conexi\u00f3n simple co cliente nativo","text":"<pre><code>docker exec -it de-postre-sql psql -U postgres\n</code></pre>"},{"location":"docker-4-postgresql/#comandos-utiles","title":"Comandos \u00fatiles","text":"<p>Amosar bases de datos</p> <pre><code>\\l\n</code></pre> <p>Seleccionar base de datos a empregar</p> <pre><code>\\c postgres\n</code></pre> <p>Amosar t\u00e1boas</p> <pre><code>\\dt\n</code></pre> <p>Crear base de datos</p> <pre><code>CREATE DATABASE sobremesa;\n</code></pre> <p>Crear un usuario</p> <pre><code>CREATE USER lambon WITH PASSWORD 'Fl4nD3C4f3';\n</code></pre> <p>Dar permisos</p> <p>Damos os permisos sobre a BBDD ao usuario:</p> <pre><code>GRANT ALL PRIVILEGES ON DATABASE sobremesa to lambon;\n</code></pre> <p>\u26a0\ufe0f Conectamos \u00e1 base de datos: \u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f EXECUTA ESTE COMANDO OU NON ASIGNAR\u00c1S PERMISOS NO SEGUINTE</p> <pre><code>\\c sobremesa\n</code></pre> <p>Damos permiso ao esquema public:</p> <pre><code>GRANT ALL ON SCHEMA public TO lambon;\n</code></pre> <p>Conectar co usuario, contrasinal e BBDD creadas</p> <p>Se temos aberta a conexi\u00f3n \u00e1 BBDD, pech\u00e1mola.</p> <pre><code>docker exec -it de-postre-sql \\\n    psql postgresql://lambon:Fl4nD3C4f3@localhost/sobremesa\n</code></pre>"},{"location":"docker-4-postgresql/#conexion-dende-python","title":"Conexi\u00f3n dende Python","text":"<ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/postgresql-psycopg2-sqlalchemy.ipynb</li> </ul>"},{"location":"docker-4-postgresql/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://www.postgresql.org/</li> <li>https://www.w3schools.com/postgresql/index.php</li> <li>https://www.postgresql.org/docs/current/datatype.html</li> </ul>"},{"location":"docker-5-mssql-server/","title":"\ud83e\uddfe Microsoft SQL Server","text":""},{"location":"docker-5-mssql-server/#microsoft-sql-server-en-ubuntu-con-docker","title":"Microsoft SQL Server en Ubuntu (con docker).","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/_/microsoft-mssql-server</li> </ul>"},{"location":"docker-5-mssql-server/#instalacion-con-docker","title":"Instalaci\u00f3n con docker","text":"<pre><code>docker run \\\n -e \"ACCEPT_EULA=Y\" \\\n -e \"MSSQL_SA_PASSWORD=Abc12300\" \\\n -e \"MSSQL_PID=Evaluation\" \\\n -p 41433:1433  \\\n --name sqlpreview \\\n --hostname sqlpreview \\\n -d mcr.microsoft.com/mssql/server:2022-preview-ubuntu-22.04\n</code></pre>"},{"location":"docker-5-mssql-server/#datos-de-conexion","title":"Datos de conexi\u00f3n","text":"<ul> <li>Usuario por defecto (admin): sa</li> <li>Contrasinal de exemplo: Abc12300. Advertencia: O contrasinal debe ter alomenos unha letra mai\u00fascula, unha min\u00fascula, un n\u00famero e alomenos oito caracteres, do contrario o docker finalizar\u00e1.</li> <li>Porto ao que conectarse de forma exterior: <code>41433</code>: El\u00edxese este porto posto que o habitual <code>1433</code> est\u00e1 bloqueado no contorno que empregamos por alg\u00fans filtros autom\u00e1ticos que non se pode abrir no grupo de seguridade.</li> <li>Existe o cliente: mssql-cli que se pode instalar con pip:</li> </ul> <pre><code>pip install mssql-cli\npip install --upgrade cli_helpers\npip install --upgrade tabulate\nexport DOTNET_SYSTEM_GLOBALIZATION_INVARIANT=true\n</code></pre>"},{"location":"docker-5-mssql-server/#como-conectar-dende-python","title":"C\u00f3mo conectar dende Python","text":"<ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/mssql-pyodbc.ipynb</li> </ul>"},{"location":"docker-6-oracle/","title":"\ud83e\uddfe Oracle Free","text":"<p>\u26a0\ufe0f AVISO: Apuntes en elaboraci\u00f3n. Incompletos.</p> <ul> <li>Baseado en: https://www.oracle.com/es/database/free/get-started/</li> </ul>"},{"location":"docker-6-oracle/#1-instalacion","title":"1. Instalaci\u00f3n","text":""},{"location":"docker-6-oracle/#11-baixar-a-imaxe","title":"1.1. Baixar a imaxe","text":"<pre><code>docker pull container-registry.oracle.com/database/free:latest\n</code></pre>"},{"location":"docker-6-oracle/#12-executar-o-contenedor","title":"1.2. Executar o contenedor","text":"<pre><code>docker run -p 5560:5560 -d --name oracle_free \\\n    container-registry.oracle.com/database/free\n</code></pre>"},{"location":"docker-6-oracle/#2-conexion","title":"2. Conexi\u00f3n","text":"<pre><code>docker exec -it oracle_free sqlplus / as sysdba\n</code></pre> <p>Para conectar a Oracle, dependendo se o temos instalado directamente ou nun docker, podemos empregar os seguintes comandos.</p>"},{"location":"docker-6-oracle/#3-comandos-para-conexion-directa","title":"3. Comandos para conexi\u00f3n directa:","text":"<pre><code>sqlplus sys@localhost:1521/FREEPDB1 as sysdba\nsqlplus sys@localhost:1521/FREE as sysdba\n</code></pre>"},{"location":"docker-6-oracle/#4-comandos-para-docker","title":"4. Comandos para docker:","text":"<pre><code>docker exec -it dbname sqlplus / as sysdba\ndocker exec -it dbname sqlplus sys/cdb-user-password@cdb-sid as sysdba\ndocker exec -it dbname sqlplus system/cdb-user-password@cdb-sid\ndocker exec -it dbname sqlplus pdbadmin/pdb-user-password@pdbname\n</code></pre>"},{"location":"docker-6-oracle/#5-exemplo-de-creacion-de-usuario-e-asignacion-de-permisos","title":"5. Exemplo de creaci\u00f3n de usuario e asignaci\u00f3n de permisos","text":"<pre><code>CREATE USER oraclefreeuser\n  IDENTIFIED BY Abc12300 \n  DEFAULT TABLESPACE tablespace\n  TEMPORARY TABLESPACE tbs_temp_01\n  QUOTA UNLIMITED on tablespace;\n</code></pre> <pre><code>GRANT CREATE VIEW, CREATE PROCEDURE,\n    CREATE SEQUENCE, CREATE TRIGGER to oraclefreeuser;\n\nGRANT ALTER ANY TABLE to oraclefreeuser;\nGRANT ALTER ANY PROCEDURE to oraclefreeuser;\nGRANT ALTER ANY TRIGGER to oraclefreeuser;\nGRANT DELETE ANY TABLE to oraclefreeuser;\nGRANT DROP ANY PROCEDURE to oraclefreeuser;\nGRANT DROP ANY TRIGGER to oraclefreeuser;\nGRANT DROP ANY VIEW to oraclefreeuser;\nGRANT CREATE TABLE to oraclefreeuser;\n</code></pre> <ul> <li>M\u00e1is informaci\u00f3n sobre a creaci\u00f3n de usuarios: https://blog.devart.com/how-to-create-oracle-user.html</li> </ul>"},{"location":"docker-6-oracle/#6-conexion-dende-python","title":"6. Conexi\u00f3n dende Python","text":"oracle.py<pre><code>import oracledb\n\nconn = oracledb.connect(user=\"[Username]\", password=\"[Password]\", \\\n                             dsn=\"localhost:1521/FREEPDB1\")\nwith conn.cursor() as cur:\n   cur.execute(\"SELECT 'Hello World!' FROM dual\")\n   res = cur.fetchall()\n   print(res)\n</code></pre>"},{"location":"docker-6-oracle/#7-limitacions-de-oracle-free","title":"7. Limitaci\u00f3ns de Oracle Free:","text":"<ul> <li>Uso m\u00e1ximo de memoria RAM: 2 GB</li> <li>Cores que emprega como m\u00e1ximo: 2</li> <li>Tama\u00f1o m\u00e1ximo de BD: 12 GB</li> <li>Unha soa instancia por medio l\u00f3xico.</li> </ul>"},{"location":"docker-6-oracle/#8-mais-informacion","title":"8. M\u00e1is informaci\u00f3n:","text":"<ul> <li>https://www.oracle.com/es/database/free/get-started/</li> <li>https://docs.oracle.com/en/database/oracle/oracle-database/21/deeck/index.html</li> <li>https://docs.oracle.com/en/database/oracle/oracle-database/23/xeinl/licensing-restrictions.html</li> </ul>"},{"location":"docker-7-kafka/","title":"Arquivo movido \u27bf Apache Kafka","text":""},{"location":"docker-8-apache-nifi/","title":"Esta p\u00e1xina xuntouse coa instalaci\u00f3n completa. Podes premer aqu\u00ed para ir \u00e1 p\u00e1xina nova","text":""},{"location":"docker-z-guia-refinitiva/","title":"\ud83d\udcd8 Docker: La gu\u00eda \"re\"finitiva","text":"<p>\u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f Esta gu\u00eda est\u00e1 desordenada, es el resultado de varios cursos, investigaci\u00f3n por mi cuenta e ir apuntando pasos. La idea es ir orden\u00e1ndola poco a poco. Puede contener errores, repeticiones y no ser exacta.</p>"},{"location":"docker-z-guia-refinitiva/#componentes","title":"Componentes","text":"<ul> <li>Docker Host: M\u00e1quina que ejecutar\u00e1 docker.</li> <li>Docker CLI: Cliente con el que conectamos y administramos dockers.</li> <li>Rest API: Permite administrar docker con peticiones GET/POST.</li> <li>Docker Daemon: El servidor de docker.</li> </ul>"},{"location":"docker-z-guia-refinitiva/#contenedores","title":"Contenedores","text":"<p>Un contenedor es una capa donde se ejecutan las im\u00e1genes.</p> <p>Las im\u00e1genes son la base del sistema, se las supone stateless (sin estado) y se usan para desplegar varios contenedores. Una imagen es de s\u00f3lo lectura mientras que el contenedor permite escritura.</p> <p>Un contenedor es temporal. Si queremos guardar los cambios necesitamos un volumen de datos. Adem\u00e1s de RAM y procesador, un contenedor puede emplear: Im\u00e1genes, vol\u00famenes y redes.</p> <p>Los vol\u00famenes permiten almacenar informaci\u00f3n a los contenedores. Esta informaci\u00f3n no deber\u00eda almacenarse directamente en el contenedor, ya que de borrarse, se eliminar\u00edan los datos.</p> <p>Un contenedor puede tener acceso a todos los procesadores y RAM del host (por defecto) o se pueden establecer l\u00edmites.</p> <p>Pueden crearse varias redes para relacionar unos contenedores con otros. Un docker puede estar en una o varias redes.</p>"},{"location":"docker-z-guia-refinitiva/#ejemplo-lanzar-el-servidor-de-bbdd-mariadb-oficial","title":"Ejemplo: Lanzar el servidor de BBDD MariaDB oficial","text":"<pre><code>    docker run --detach --name maria1 --env MARIADB_USER=unusuario \\\n    --env MARIADB_PASSWORD=unacontrasena \\\n    --env MARIADB_ROOT_PASSWORD=clavederoot \\\n    mariadb:latest\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#asociar-una-carpeta-local-a-una-carpeta-del-contenedor","title":"Asociar una carpeta local a una carpeta del contenedor","text":"<p>Por ejemplo: <code>/tmp/mariadatos</code> al <code>/var/lib/mysql</code> del docker</p> <p>Este ejemplo crea un contenedor con la \u00faltima versi\u00f3n de mariadb y por medio de las variables de entorno que permite su imagen, le pasa un usuario, una clave, una clave de administrador y asocia una carpeta de nuestro host dentro del contenedor.</p> <pre><code>    docker run -v /tmp/mariadatos:/var/lib/mysql/ --detach \\\n    --name maria2 --env MARIADB_USER=unusuario \\\n    --env MARIADB_PASSWORD=unacontrasena \\\n    --env MARIADB_ROOT_PASSWORD=clavederoot \\\n    mariadb:latest\n</code></pre> <p>Comando <code>run</code>:</p> <p>Descarga una imagen (si no existe) y crea e inicia el contenedor.</p> <p>Opci\u00f3n <code>--detach</code>:</p> <p>Libera la terminal, no nos deja la consola bloqueada, lo pasa a segundo plano.</p> <p>Pasar una variable de entorno:</p> <pre><code>    docker exec -e var='value' CONTENEDOR COMANDO\n</code></pre> <p>Leyenda: -e: Environment.</p>"},{"location":"docker-z-guia-refinitiva/#asociar-carpeta-del-contenedor-a-un-volumen","title":"Asociar carpeta del contenedor a un volumen","text":"<pre><code>    docker run -v VOLUMENNUEVO:/var/lib/mysql/ \\\n    --detach --name maria3 \\\n    --env MARIADB_USER=unusuario \\\n    --env MARIADB_PASSWORD=unacontrasena \\\n    --env MARIADB_ROOT_PASSWORD=clavederoot \\\n    mariadb:latest\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#volumenes","title":"Vol\u00famenes","text":"<p>Existen tres tipos b\u00e1sicos de vol\u00famenes:</p> <ul> <li>Vol\u00famenes Host.</li> <li>Vol\u00famenes an\u00f3nimos.</li> <li>Vol\u00famenes nombrados.</li> </ul> <p>Por defecto se guardan en: <code>/var/lib/docker/volumes</code></p> <p>Conviene acceder a ellos s\u00f3lo con herramientas de docker. https://docs.docker.com/storage/volumes/</p> <p>Comandos \u00fatiles (se ver\u00e1n de nuevo en los ejemplos) <pre><code>    docker volume ls\n    docker inspect VOLUMEN\n</code></pre></p> <p>Por defecto emplearemos el driver <code>local</code> para los vol\u00famenes, sin embargo hay otras opciones como flocker o convoy con opciones interesantes. Por ejemplo: Sacar snapshots del volumen de datos.</p> <p>Se permiten pasar opciones a <code>volume</code> para especificar tama\u00f1o (o guardar el volumen de forma vol\u00e1til con tmpfs)</p>"},{"location":"docker-z-guia-refinitiva/#nombrado","title":"Nombrado","text":"<p>Para acceder a los contendores o bien podemos referirnos por su nombre (crea un nombre aleatorio si no le especificamos uno con <code>--name</code>) o por su <code>CONTAINER ID</code>. En el caso del <code>CONTAINER ID</code> podemos escribir tan s\u00f3lo los dos o tres primeros caracteres (siempre que no haya otro contenedor en el que coincidan estos y con ello se pueda inferir inequ\u00edvocamente el contenedor referenciado).</p>"},{"location":"docker-z-guia-refinitiva/#ejemplos-de-comandos-basicos","title":"Ejemplos de comandos b\u00e1sicos","text":"<p>En CONTENEDOR puede valer el nombre asignado o los primeros d\u00edgitos/letras de su identificador \u00bfCuantos caracteres hay que poner del identificador? F\u00e1cil, tantos como permitan identificarlo de forma \u00fanica.</p>"},{"location":"docker-z-guia-refinitiva/#listar-volumenes","title":"Listar vol\u00famenes:","text":"<pre><code>    docker volume ls\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#listar-imagenes","title":"Listar im\u00e1genes:","text":"<pre><code>    docker image ls\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#listar-contenedores-en-ejecucion-opciones","title":"Listar contenedores (en ejecuci\u00f3n). Opciones:","text":"<pre><code>    docker ps\n    docker container ls\n    docker container ps\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#listar-contenedores-en-ejecucion-y-finalizados-opciones","title":"Listar contenedores (en ejecuci\u00f3n y finalizados). Opciones:","text":"<pre><code>    docker ps -a\n    docker container ls -a\n    docker container ps -a\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#parar-un-contenedor","title":"Parar un contenedor:","text":"<pre><code>    docker container stop CONTENEDOR\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#inciar-un-contenedor-que-este-previamente-creado-y-exista","title":"Inciar un contenedor (que est\u00e9 previamente creado y exista):","text":"<pre><code>    docker container start CONTENEDOR\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#volumenes-creacion-explicita","title":"Vol\u00famenes. Creaci\u00f3n expl\u00edcita","text":"<pre><code>    docker volume create mi-volumen\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#volumenes-ver-informacion","title":"Vol\u00famenes. Ver informaci\u00f3n","text":"<pre><code>    docker volume inspect mi-volumen\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#asociar-un-volumen-a-un-contenedor-en-la-creacion-del-contenedor","title":"Asociar un volumen a un contenedor (en la creaci\u00f3n del contenedor)","text":"<pre><code>    docker run -d \\\n      --name entornoDES \\\n      --mount source=mi-volumen,target=/app \\\n      nginx:latest\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#mapearredirigir-un-puerto","title":"Mapear/Redirigir un puerto","text":"<p>Si necesitamos asignar un puerto del anfitri\u00f3n al contenedor, podemos hacerlo con la opci\u00f3n: <code>-p PUERTO_ANFITRI\u00d3N:PUERTO_INVITADO</code>.</p> <pre><code>docker run -it -d -p 3001:3000 imagen/tag\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#borrar-un-contenedor","title":"Borrar un contenedor","text":"<pre><code>    docker container rm CONTENEDOR\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#borrar-un-volumen","title":"Borrar un volumen","text":"<pre><code>    docker volume rm VOLUMEN\n</code></pre> <p>Al borrar un contenedor, por defecto, no se borra el volumen asociado.</p>"},{"location":"docker-z-guia-refinitiva/#borrar-una-imagen","title":"Borrar una imagen","text":"<pre><code>    docker image rm IMAGEN\n</code></pre> <p>Al borrar un contenedor, por defecto, no se borra la imagen asociada a partir de la cual se ha hecho el contenedor.</p> <p>Salvo que forcemos el borrado, no se puede borrar una imagen si tiene asociado alg\u00fan contenedor.</p>"},{"location":"docker-z-guia-refinitiva/#ejecutando-un-comando-dentro-del-contenedor","title":"Ejecutando un comando dentro del contenedor","text":"<p>Una de los casos m\u00e1s t\u00edpicos es ejecutar un bash para cambiar o consultar algo dentro del contenedor.</p> <p>Crear el contenedor y que nos devuelva una terminal:</p> <pre><code>    docker run -it ubuntu:18.04 bash\n</code></pre> <ul> <li><code>-it</code>: nos conecta (attach) a una sesi\u00f3n interactiva de forma que podamos ver e interactuar con ella).</li> <li><code>run</code>: Descarga la imagen, crea el contenedor y lo arranca.</li> </ul> <p>Conectarnos a una terminal de un contenedor ya creado: <pre><code>    docker exec -it CONTENEDOR /bin/bash\n</code></pre></p> <ul> <li><code>exec</code>: Ejecuta el comando /bin/bash en el CONTENEDOR.</li> </ul> <p>En el caso que no necesitemos una sesi\u00f3n interactiva, podemos ejecutar un comando directamente:</p> <pre><code>    docker exec CONTENEDOR ls\n</code></pre> <p>La diferencia entre <code>docker run</code> y <code>docker exec</code> es que <code>docker exec</code> ejecuta el comando que le especifiquemos en un contenedor ya creado y en ejecuci\u00f3n, mientras que <code>docker run</code> crea y ejecuta un contenedor temporal, ejecuta el comando y para el contenedor cuando acaba.</p>"},{"location":"docker-z-guia-refinitiva/#bajar-la-imagen","title":"Bajar la imagen","text":"<p>Este comando baja la imagen sin usarla en ning\u00fan contenedor. Con posterioridad podr\u00e1 ser utilizada.</p> <pre><code>docker pull IMAGEN\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#archivo-dockerfile","title":"Archivo Dockerfile","text":"<p>Ejemplo Dockerfile:</p> <pre><code>FROM node:16-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nESXPOSE 3000\nCMD [\"node\", \"server.js\"]\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#from","title":"FROM","text":"<ul> <li> <p>Inicia una nueva etapa de construcci\u00f3n: <code>FROM &lt;image&gt;[:&lt;tag&gt;][AS &lt;NAME&gt;]</code></p> </li> <li> <p><code>AS &lt;NAME&gt;</code> nombra la etapa de compilaci\u00f3n.</p> </li> <li>Puede aparecer varias veces (varias im\u00e1genes o indicar dependencia).</li> <li>Los tags son opcionales, por defecto <code>latest</code>.</li> </ul> <p>Se pueden tener m\u00faltiples fases de construcci\u00f3n (multistage). Por ejemplo: La primera baja de un repo, baja dependencias, ejecuta maven/ant/compila y la segunda con el resultado generado (por ejemplo un jar) puede construir una imagen m\u00ednima con ese jar y una MV de java para su ejecuci\u00f3n.</p> <p>Es decir, podr\u00edamos en este ejemplo tener una m\u00e1quina para compilar un programa (con todas las dependencias nesarias) y otra con las dependencias m\u00ednimas para ejecutar ese programa.</p>"},{"location":"docker-z-guia-refinitiva/#run","title":"RUN","text":"<p>Ejecuta un comando en la capa actual. Por defecto se emplea: - En GNU/Linux: <code>/bin/sh -c</code> - En Microsoft Windows: <code>cmd /S /C</code></p>"},{"location":"docker-z-guia-refinitiva/#copyadd","title":"COPY/ADD","text":"<p><code>COPY/ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt; ... &lt;dest&gt;</code></p> <ul> <li><code>&lt;src&gt;</code>: El origen del archivo.</li> <li> <p><code>&lt;dest&gt;</code>: Indica la ruta dentro del contenedor.</p> </li> <li> <p>GNU/Linux admite par\u00e1metro <code>chown</code>.</p> </li> <li> <p><code>ADD</code> permite copiar un archivo desde una URL. Si src es un archivo comprimido, lo descomprime en destino.</p> </li> </ul>"},{"location":"docker-z-guia-refinitiva/#entrypoint","title":"ENTRYPOINT","text":"<p>El ejecutable del contenedor Ejemplo: <code>ENTRYPOINT [\"executable\",\"param1\",\"param2\"]</code></p> <p>Si luego hay un CMD, se le pasa al entrypoint.</p>"},{"location":"docker-z-guia-refinitiva/#cmd","title":"CMD","text":"<p>S\u00f3lo puede haber un CMD en el <code>Dockerfile</code>. Si hay m\u00e1s de uno, s\u00f3lo se aplicar\u00e1 el \u00faltimo.</p> <p>Indica el comando que levanta el servicio. Debe levantarse en primer plano para mantener vivo el contenedor.</p> <p>Ejemplo: <code>CMD [\"executable\",\"param1\",\"param2\"]</code></p>"},{"location":"docker-z-guia-refinitiva/#env","title":"ENV","text":"<p>Sirve para indicar variables de entorno con valores por defecto. El usuario puede cambiar estas variables para personalizar los ajustes a su gusto.</p>"},{"location":"docker-z-guia-refinitiva/#otros","title":"Otros","text":"<p>El archivo <code>.dockerignore</code> permite que no se copien al contenedor los archivos y/o directorios especificados como no necesarios para acelerar el proceso de construcci\u00f3n.</p>"},{"location":"docker-z-guia-refinitiva/#contenedores_1","title":"Contenedores","text":"<ul> <li>Variables de entorno: <code>-e</code></li> <li>Limitar recursos</li> </ul> <p>Limitar memoria:  <pre><code>--memory 200m (200 MiB)\n</code></pre></p> <p>Limitar al procesador 0 (el primero):  <pre><code>--cpuset-cpus 0\n</code></pre></p> <p>Renombrar un docker <pre><code>docker rename \n</code></pre></p> <p>Copiar archivos desde/hacia contenedor/host</p> <pre><code>docker cp\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#docker-logs","title":"Docker logs","text":"<p>Nos va a permitir ver los logs de un contenedor. - <code>-f</code> permite verlos en tiempo real - <code>-t</code> a\u00f1ade el timestamp al log (aunque la aplicaci\u00f3n de log no lo haga). \u00datil para tiempos sincronizados.</p>"},{"location":"docker-z-guia-refinitiva/#crear-unha-imagen-a-partir-de-un-contenedor","title":"Crear unha imagen a partir de un contenedor","text":""},{"location":"docker-z-guia-refinitiva/#construir-una-imagen","title":"Construir una imagen","text":"<pre><code>docker build -t imagen/tag .\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#docker-commit","title":"Docker commit","text":"<p>Permite crear una imagen a partir de un contenedor.</p>"},{"location":"docker-z-guia-refinitiva/#ejecutar-una-imagen-en-un-contenedor","title":"Ejecutar una imagen en un contenedor","text":"<pre><code>    docker run -it -d imagen/tag\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#imagenes-propias","title":"Im\u00e1genes propias","text":"<p>Si creas una cuenta en dockerhub puedes subir tu imagen:</p> <pre><code>    docker push imagen/tag\n</code></pre> <p>Con eso puedes bajar la imagen desde cualquier sitio:</p> <pre><code>    docker pull usuario/imagen/tag\n</code></pre> <p>En base a una imagen se pueden crear varios contenedores, por ejemplo:</p> <pre><code>    docker run -it -d -p 3001:3000 imagen/tag\n    docker run -it -d -p 3002:3000 imagen/tag\n</code></pre> <p>Cuando eliminamos un contenedor, su sistema de archivos e informaci\u00f3n tambi\u00e9n son eliminadas.</p> <p>Si se quieren guardar los datos al eliminar el docker, debemos guardar los vol\u00famenes de docker (normalmente se crean mediante opci\u00f3n de forma expl\u00edcita o se puede asociar un directorio).</p> <p>Tambi\u00e9n se pueden crear redes para comunicar distintos dockers entre ellas.</p> <p>Podemos utilizar <code>docker-compose</code> (o <code>docker compose</code>, dependiendo de la versi\u00f3n) cuando queremos que varios contenedores de docker se inicien al mismo tiempo (y adem\u00e1s establecer dependencias entre ellos).</p> <p>Para administrar muchos contenedores, podemos emplear orquestadores (por ejemplo Kubernetes).</p> <p>Ejemplos \u00fatiles de dockers: - Imagen de gitlab: https://docs.gitlab.com/ee/install/docker.html - Imagen de tensorflow/serving: https://www.tensorflow.org/install/docker?hl=es-419</p>"},{"location":"docker-z-guia-refinitiva/#pets-vs-cattle-mascotas-versus-ganado","title":"Pets vs cattle (mascotas versus ganado)","text":"<p>Si un servidor se cae, deber\u00eda ser reemplazo autom\u00e1ticamente y de forma transparente al usuario (los servidores son ganado).</p> <p>Para esto ayuda tener la aplicaci\u00f3n distribu\u00edda en microservicios.</p> <p>Si la ca\u00edda de un servidor origina un problema probablemente tengas una mascota, puesto que seguramente conozcas a ese servidor por su nombre: Afrodita, Zeus, MrBurns... lo mantengas y arregles cuando falla y planifiques su mantenimiento como pieza cr\u00edtica en tu organizaci\u00f3n.</p> <p>Si por el contrario tienes un grupo de servidores sin nombre o con nombres: svr1, svr2... del modo en que se ponen etiquetas en las orejas del ganado, a los que aplicas configuraciones autom\u00e1ticas (probablemente a todos las mismas) cuando uno cae, simplemente lo reemplazas por otro, como el ganado. Ejemplos de esto pueden ser: Clusters NO-SQL, servidores de bigdata, clusters de b\u00fasqueda, etc.</p> <p>Las organizaciones que poseen hardware en sus instalaciones, tienen hoy d\u00eda varios servidores en su rack y necesitan automatizar su instalaci\u00f3n, configuraci\u00f3n y uso. Existen herrameintas como Kubernetes, Pupper, Chef o Ansible que permiten automatizar y sacarle m\u00e1s rendimiento a nuestro ganado.</p> <p>M\u00e1s informaci\u00f3n:</p> <ul> <li>https://www.hava.io/blog/cattle-vs-pets-devops-explained</li> <li>https://www.ilimit.com/blog/orquestracion-cloud-pets-cattles/</li> </ul>"},{"location":"docker-z-guia-refinitiva/#imagenes-de-docker","title":"Im\u00e1genes de docker","text":"<ul> <li>Docker Hub</li> <li>Dockerfile: From, Run, Copy, Add, Entrypoint, Cmd y .dockerignore</li> <li>Danling Images: Im\u00e1genes no referenciadas, sin nombre o tag pero ocupan espacio.</li> </ul>"},{"location":"docker-z-guia-refinitiva/#redes-en-docker","title":"Redes en docker","text":"<p>Existen 5 tipos de driver: - none - bridge - host - macvlan - ipvlan - overlay</p> <p>https://docs.docker.com/network/</p> <p>Por defecto se usa bridge (crea el dispositivo: docker0).\\ No se puede hacer ping por nombre de contenedor (habr\u00e1 que poner la IP).</p> <pre><code>    docker network create NOMBRE --subnet 192.168.0.0/24 --gateway 192.168.0.1\n\n    docker network ls\n\n    docker run -d (--network NOMBRE) nginx (--ip 192.168.0.200) .\n</code></pre> <p>En las redes que nosotros creamos se permite hacer ping por nombre de host.</p> <p>A\u00f1ade contenedor a una red: <pre><code>    docker network connect NOMBRE contenedor\n</code></pre></p>"},{"location":"docker-z-guia-refinitiva/#estadisticas","title":"Estad\u00edsticas","text":"<p>Nos permiten ver estad\u00edsticas del contenedor: RAM, procesador en uso, uso de red y si tienen alg\u00fan l\u00edmite de uso de RAM.</p> <pre><code>    docker stats\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#docker-compose-o-docker-compose","title":"Docker Compose \u00f3 docker-compose","text":"<p>Para organizar/orquestar contenedores. Crear contenedores que trabajen juntos. Es decir, aplicaciones multicontenedor para deplegar r\u00e1pidamente. Usa docker-compose.yml. Emplea formato YAML.</p>"},{"location":"docker-z-guia-refinitiva/#etiquetas-en-docker-composeyml","title":"Etiquetas en docker-compose.yml","text":"<ul> <li>version</li> <li>services</li> <li>volumes</li> <li>networks</li> </ul>"},{"location":"docker-z-guia-refinitiva/#moviendo-dockers","title":"Moviendo dockers","text":"<ul> <li> <p>Opci\u00f3n 1: Exportando e importando <pre><code>    docker export container-name | gzip &gt; container-name.gz\n    zcat container-name.gz | docker import - container-name\n</code></pre></p> </li> <li> <p>Opci\u00f3n 2: Migrando la imagen <pre><code>    docker commit container-id image-name\n</code></pre></p> </li> <li> <p>Opci\u00f3n 3: Salvando y creando im\u00e1genes <pre><code>    docker save image-name &gt; image-name.tar\n\n    cat image-name.tar | docker load\n</code></pre></p> </li> <li> <p>Opci\u00f3n 4: Hacer backup del volumen de datos y restaurarlo <pre><code>    docker run --rm --volumes-from datavolume-name -v $(pwd):/backup image-name tar cvf  backup.tar /path-to-datavolume\n\n    docker run --rm --volumes-from datavolume-name -v $(pwd):/backup image-name bash -c \"cd /path-to-datavolume &amp;&amp; tar xvf /backup/backup.tar --strip 1\"\n</code></pre></p> </li> </ul> <p>Si queremos mover varios todos los dockers, otra opci\u00f3n ser\u00eda copiar el directorio de trabajo de docker:</p> <p><code>/var/lib/docker</code></p> <p>Habr\u00eda que tener en cuenta que debemos:</p> <ol> <li>Tener la misma versi\u00f3n de docker en los host de origen y destino.</li> <li>Preservar los permisos y propietarios de archivos y carpetas.</li> <li>Parar el servicio docker antes de copiar nada: <code>service socker stop</code></li> <li>Si hay otras rutas a carpetas, deben existir, tener los permisos adecuados y asegurarnos que no dan otros problemas.</li> </ol> <p>Lo l\u00f3gico en estos casos es planificar la migraci\u00f3n, probarla y ejecutar finalmente un script de migraci\u00f3n con los pasos necesarios para minimizar el tiempo de esta migraci\u00f3n.</p>"},{"location":"docker-z-guia-refinitiva/#extensiones-para-vscode","title":"Extensiones para VSCODE","text":"<ul> <li>Una extensi\u00f3n para gobernarlas a todas: Remote development</li> <li>https://code.visualstudio.com/remote/advancedcontainers/develop-remote-host</li> <li>https://code.visualstudio.com/docs/devcontainers/containers#installation</li> <li>https://code.visualstudio.com/docs/remote/ssh#_connect-to-a-remote-host</li> </ul>"},{"location":"docker-z-guia-refinitiva/#contenedores-interesantes-para-probar","title":"Contenedores interesantes para probar","text":"<ul> <li>rednode</li> <li>jenkins</li> <li>tensorflow</li> </ul> <p>Ejemplo con docker compose. Moodle:</p> <p>Bajar el <code>docker-compose.yml</code> de moodle hecho por bitnami.</p> <pre><code>curl -sSL https://raw.githubusercontent.com/bitnami/containers/main/bitnami/moodle/docker-compose.yml &gt; docker-compose.yml\n</code></pre> <p>Lanzalo:</p> <pre><code>    docker-compose up -d\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#herramientas-relacionadas-con-dockers","title":"Herramientas relacionadas con dockers","text":"<ul> <li>Docker Desktop: Cliente oficial de docker en modo gr\u00e1fico. Para Windows/Linux/Mac. Es de pago para empresas grandes.</li> <li>Portainer.io: Panel de control web para contenedores (de pago). Gratis 5 contenedores con registro previo</li> <li>Podman.io: \"Sustituto\" de docker. Se ejecuta como programa (y no demonio o servicio). Con o sin root ejecuta los contenedores usando libpod (im\u00e1genes, vol\u00famenes, contenedores \"pod\"). Tambi\u00e9n tiene su versi\u00f3n podman desktop, que es opensource. Mantenido por RedHat. Herramientas relacionadas: Buildah, Skopeo. https://www.redhat.com/es/topics/containers/what-is-podman </li> <li>Rancher Desktop: Cliente open-source para gesti\u00f3n de Containers y Kubernetes para Windows, Linux y Mac.</li> <li>vaultproject.io: Hashicorp vault. Permite almacenar credenciales y usarlas como parte del proceso CD/CI para no tener que almacenarlas en el repositorio directamente.</li> </ul>"},{"location":"docker-z-guia-refinitiva/#plonk-stack","title":"PLONK Stack","text":"<p>Consiste en los siguientes elementos:</p> <ul> <li> <p>Prometheus.io: Monitorea y gestiona alertas. Soporta m\u00e9tricas en tiempo real y usa una BBDD con series temporales.</p> </li> <li> <p>Linux:</p> </li> <li> <p>OpenFaaS: \"Function as a service\". Haciendo uso de una arquitectura de microservicios podemos desarrollar, ejecutar y administrar funcionalidades en una aplicaci\u00f3n olvid\u00e1ndonos de la parte de la infraestructura (\"serverless\"). Ejemplos en los que se puede aplicar esta t\u00e9cnica son: procesos batch (por lotes), procesamiento en stream (flujo), procesos ETL, IoT (Internet de las cosas), apps para m\u00f3viles, aplicaciones web, APIs, etc. La diferencia con PaaS es que el desarrollador/admnistrador ni siquiera debe preocuparse por el escalado o aumentar los servidores.</p> </li> <li> <p>NATS: Mensajer\u00eda de alto rendimiento. Comunica sistemas/procesos/servicios. Partes: NATS Core, Jet Stream.</p> </li> <li> <p>Kubernetes: Orquestador para desplegar los contenedores en servidores.</p> </li> </ul> <p>M\u00e1s informaci\u00f3n: https://www.openfaas.com/blog/plonk-stack/</p>"},{"location":"docker-z-guia-refinitiva/#mirar-tambien","title":"Mirar tambi\u00e9n...","text":"<ul> <li>https://www.youtube.com/watch?v=MIl-LJodYUU</li> <li>https://bobcares.com/blog/move-docker-container-to-another-host/</li> </ul>"},{"location":"nube-0-intro/","title":"\u2601\ufe0f Computaci\u00f3n na nube","text":""},{"location":"nube-0-intro/#que-e-a-computacion-na-nube","title":"Que \u00e9 a computaci\u00f3n na nube","text":"<p>Se executas os teus servizos, programas, m\u00e1quinas virtuais ou contedores en servidores de outros ent\u00f3n \"est\u00e1s nas nubes\". Este uso de servidores remotos en distintas redes que poden estar localizadas en centros de datos en varios pa\u00edses \u00e9 o que co\u00f1ecemos por \"computaci\u00f3n na nube\".</p>"},{"location":"nube-0-intro/#vantaxes","title":"Vantaxes","text":"<ul> <li>Mellor conectividade: Velocidade, latencia, etc.</li> <li>Redundancia e tolerancia a fallos: Moitos fallos de hardware mesmo son imperceptibles.</li> <li>Escalabilidade e flexibilidade: Inversi\u00f3n inicial case cero.</li> <li>Centros de datos ben adaptados: Electricidade, seguridade f\u00edsica, l\u00f3xica, etc.</li> <li>Distintas ubicaci\u00f3ns xeogr\u00e1ficas: Podemos acceder nos proveedores grandes a distintos centros de datos ubicados en t\u00f3dolos continentes para garantir unha boa conectividade.</li> </ul>"},{"location":"nube-0-intro/#desvantaxes","title":"Desvantaxes","text":"<ul> <li>Custos: Manter un gran n\u00famero de recursos a medio/longo prazo \u00e9 moito m\u00e1is caro, incluso contando os custos de persoal. Este punto \u00e9 controvertido, posto que soe dicirse o contrario. Hai que analizar a situaci\u00f3n en cada caso particular e non basearse s\u00f3 nunha opini\u00f3n dun comercial.</li> <li>Protecci\u00f3n de datos: Normalmente os acordos para a protecci\u00f3n de datos, que permiten mover os datos a datacenters de f\u00f3ra de Europa, adoitan ser ef\u00e9meros e esot\u00e9ricos. Exemplos desto son: Safe Harbour e Privacy Seal, que demostran unha vez m\u00e1is a grande diferencia de concepto de protecci\u00f3n de datos e o distinto tratamento entre Europa e EEUU.</li> <li>Dependencia dun terceiro: Cambios de condici\u00f3ns unilaterais, fallos, prohibici\u00f3n de uso dos seus servizos (sic), bloqueos...</li> </ul>"},{"location":"nube-0-intro/#principais-proveedores-de-cloud-computing-computacion-na-nube","title":"Principais proveedores de Cloud Computing / Computaci\u00f3n na nube","text":"<ul> <li>Amazon AWS: https://aws.amazon.com/</li> <li>Microsoft Azure: https://azure.microsoft.com/</li> <li>Google Cloud: https://cloud.google.com/</li> </ul> <p>Segundo varios informes de operadoras, as grandes tecnol\u00f3xicas xeran entre o 55% e o 80% do tr\u00e1fico das redes mundiais. Estes informes adoitan a forma de notas de prensa e poden ofrecer resultados interesados, m\u00e1is probablemente se supere o 50% do tr\u00e1fico mundial total dado o tama\u00f1o destas megacorporaci\u00f3ns.</p> <p>Habitualmente esc\u00f3itase falar do termo GAFAM polos nomes das principais empresas tecnol\u00f3xicas: Google, Apple, Facebook, Amazon e Microsoft para referirse ao tr\u00e1fico e conexi\u00f3ns que prove\u00f1en delas.</p>"},{"location":"nube-0-intro/#platform-as-a-service-paas","title":"Platform as a Service (PaaS)","text":""},{"location":"nube-0-intro/#pago-por-uso-e-usos-idoneos","title":"Pago por uso e usos id\u00f3neos","text":"<p>O prezo da nube pode chegar a ser moi variable e est\u00e1 \u00edntimamente ligado ao uso de recursos. Se ben \u00e9 unha das grandes vantaxes porque non require unha inversi\u00f3n inicial en hardware, redes, acondicionamento, instalaci\u00f3n e persoal, esta vantaxe vaise diluindo co tempo.</p> <p>O uso m\u00e1is adecuado da nube \u00e9 para aquelas operaci\u00f3ns nas que \u00e9 impredecible o uso de recursos e son momentos puntuais. Tam\u00e9n para incrementar puntualmente os recursos ou para garantir un SLA superior ao que obter\u00edamos con servidores in-house.</p> <p>Sen embargo, cando unha empresa co\u00f1ece ben os seus recursos computacionais e ten persoal adicado \u00e9 indiscutible que a nube resulta m\u00e1is cara en pr\u00e1cticamente a totalidade dos escenarios, inclu\u00edndo os custes de persoal. Non todos os escenarios requiren as mesmas consideraci\u00f3ns e o prezo non \u00e9 sempre o elemento determinante \u00e1 hora de escoller entre unha ou outra opci\u00f3n.</p> <p>Outro uso moi adecuado ser\u00eda o de gardar unha copia de seguridade dos datos (cifrada) noutra localizaci\u00f3n. O ideal, se a t\u00faa empresa \u00e9 grande \u00e9 gardar os datos en distintos continentes para garantir o acceso en todo momento.</p> <p>Ante unha cat\u00e1strofe (como a ocorrida nas Torres Xemelgas no 2001) non dependeremos que os nosos datos e servidores estean nunha das Torres e o backup na outra. Tam\u00e9n deber\u00edamos ter en conta maremotos, terremotos e outras cat\u00e1strofes naturais as\u00ed como guerras e a situaci\u00f3n xeopol\u00edtica de onde gardamos os datos.</p> <p>Se temos adem\u00e1is unha copia dos datos na nube, outra vantaxe \u00e9 poder levantar as m\u00e1quinas necesarias en pouco tempo (se temos implementado e practicado un plan de continxencias) para continuar cos servizos. Evidentemente falamos de empresas grandes e que normalmente act\u00faan en varios pa\u00edses.</p> <p>Normalmente os servizos de virtualizaci\u00f3n na nube cobran polo uso de recursos: Procesador, memoria RAM, tr\u00e1fico de rede entrante e sa\u00ednte, GPU, almacenamento de datos, operaci\u00f3ns de lectura/escritura sobre eles...</p> <p>Non sempre precisamos todos os servizos activos, polo que se queremos aforrar custos, debemos reducir recursos. Unha boa idea se non precisamos as m\u00e1quinas \u00e9 destruilas e gardar os volumes de almacenamento ou os datos, tendo en conta o tempo que leva levantar unha m\u00e1quina cos servizos activos de novo.</p>"},{"location":"nube-0-intro/#nomes-dos-servizos-mais-habituais","title":"Nomes dos servizos m\u00e1is habituais","text":"<p>As correspondencias cos nomes poden non ser exactas xa que as veces o concepto cambia un pouco (sobre todo cos nomes xen\u00e9ricos por nomearse varias alternativas).</p> <ul> <li> <p>Computaci\u00f3n (CPU+RAM):</p> <ul> <li>Amazon Web Services (AWS):<ul> <li>Amazon EC2: Amazon Elastic Compute Cloud.</li> <li>Lightsail: Tipo VPS (Virtual Private Server). Facturaci\u00f3n simplificada, elecci\u00f3n limitada.</li> </ul> </li> <li>Google Cloud Platform (GCP):<ul> <li>GCE: Google Compute Engine.</li> </ul> </li> <li>Microsoft Azure:<ul> <li>Azure Virtual Machine / M\u00e1quina Virtual.</li> </ul> </li> <li>OpenStack / Nome xen\u00e9rico:<ul> <li>Instancia / M\u00e1quina Virtual.</li> <li>Contedor.</li> </ul> </li> </ul> </li> <li> <p>Almacenamento:</p> <ul> <li>Amazon Web Services (AWS):<ul> <li>EBS en instancias.</li> <li>S3 Obxectos de almacenamento.</li> <li>Glacier Obxectos de almacenamento con menor redundancia e de acceso lento.</li> </ul> </li> <li>Google Cloud Platform (GCP):<ul> <li>Persistent Disk / Durable Block Storage</li> <li>Cloud Storage.</li> </ul> </li> <li>Microsoft Azure:<ul> <li>Azure Blob Storage.</li> </ul> </li> <li>OpenStack / Nome xen\u00e9rico:<ul> <li>Object Storage (tam\u00e9n pode configurarse algo similar a un \"Cold Storage\").</li> <li>Block/Volume Storage (snapshots...).</li> </ul> </li> </ul> </li> </ul> <p>Hai un mont\u00f3n de servizos m\u00e1is con nomes comerciais baseados en soluci\u00f3ns de software co\u00f1ecidas. Tr\u00e1tase de vender unha soluci\u00f3n con procesamento para case cada nicho de mercado: IA, colas, DNS, Bases de Datos, etc. Cada proveedor tenta po\u00f1erlle os seus propios nomes.</p>"},{"location":"nube-0-intro/#alternativas","title":"Alternativas","text":"<ul> <li>As soluci\u00f3ns in-house (servidores f\u00edsicos na oficina ou en centro propio).</li> <li>Montar a t\u00faa propia nube:<ul> <li>Openstack</li> <li>Citrix CloudPlatform</li> <li>Eucalyptus</li> <li>Microsoft Azure Stack</li> <li>Red Hat OpenShift</li> <li>VMware vSphere</li> </ul> </li> </ul>"},{"location":"nube-0-intro/#a-nube-en-europa-cloud-en-europa","title":"A nube en Europa / Cloud en Europa","text":"<p>Europa trata de reducir a dependencia das grandes tecnol\u00f3xicas estadounidenses.</p> <ul> <li>ComputerHoy: O poder das grandes tecnol\u00f3xicas</li> <li>El Pa\u00eds: A UE blind\u00e1ndose contra as tecnol\u00f3xicas</li> <li>Informe de Oliver Wyman: EUROPEAN DIGITAL SOVEREIGNTY</li> <li>EU. Cloud Strategy</li> <li>Dataset da penetraci\u00f3n da nube nos distintos pa\u00edses da UE</li> <li>EU. Futures of big tech in Europe. Scenarios and policy implications: Foresight</li> </ul> <p>En China ter\u00e1s o\u00eddo falar seguramente das prohibici\u00f3ns en internet \u00e1s que se enfrentan os seus cidad\u00e1ns e do \"Gran Firewall Chin\u00e9s\". Este movemento dalles tam\u00e9n unha certa vantaxe competitiva e perm\u00edtelles desenvolver os seus propios servizos e redes sociais: QQ, Tiktok, etc.</p> <p>Estamos nunha econom\u00eda global, os prezos da nube dependen da enerx\u00eda, comunicaci\u00f3ns, redes, custos de persoal e pol\u00edticas de cada pa\u00eds. Na ecuaci\u00f3n tam\u00e9n entran os datos.</p> <p>Un dos activos m\u00e1is importantes das empresas son os datos. En Europa e EEUU xogamos en diferentes ligas. Cando os datos son en teor\u00eda dos cidad\u00e1ns (Europa) e non das empresas (EEUU) as empresas en Europa te\u00f1en un menor valor, posto que os datos non son un activo propiedade destas e deben ser m\u00e1is garantistas co seu uso.</p>"},{"location":"nube-0-intro/#proveedores-de-cloud","title":"Proveedores de Cloud","text":""},{"location":"nube-0-intro/#proveedores-de-cloud-computing-en-europa","title":"Proveedores de Cloud Computing en Europa","text":"Empresa Pa\u00eds de orixe Ano de comezo Contabo Alema\u00f1a 2003 Fuga Cloud Holanda 2006 Hetzner Alema\u00f1a 1997 OVH Francia 1999 Scaleway Francia 1999 Server Space Pa\u00edses Baixos 2008 Upcloud Finlandia 2012"},{"location":"nube-0-intro/#outros-proveedores-de-cloud-computing","title":"Outros proveedores de Cloud Computing","text":"Empresa Pa\u00eds de orixe Ano de comezo Cloud Sigma Su\u00edza 2009 Digital Ocean EEUU 2012 Ionos EEUU 1988 (1&amp;1) Linode EEUU 2003 Rack Space EEUU 1998 Vultr EEUU 2014 V2 Cloud Canad\u00e1 2012 <p>/!\\ O ano de comezo pode ser noutras actividades, as empresas m\u00e1is antigas non se adicaron sempre ao cloud e mesmo as modernas tentan sempre pasar por m\u00e1is antigas con trucos cosm\u00e9ticos para que se vexa que levan tempo no sector.</p> <p>Fonte: Elaboraci\u00f3n propia a partir dos datos presentes nas webs das empresas, pode haber erros.</p>"},{"location":"nube-0-intro/#elixindo-unha-compania-de-cloud-computing","title":"Elixindo unha compa\u00f1\u00eda de cloud computing","text":"<p>Elixir unha compa\u00f1\u00eda (ou varias) non \u00e9 tarefa sinxela. Seguramente ter\u00e1s o\u00eddo comentarios de todo tipo. Por exemplo:</p> <p>No caso de OVH ten tido problemas no pasado: incendios e incidentes en materia de datos persoais, adem\u00e1is non ten moi boa publicidade nas comunidades en internet por alg\u00fans erros e formas.</p> <p>Hetzner tam\u00e9n ten tido alg\u00fan problema, parece que moito m\u00e1is limitado coa s\u00faa KonsoleH nalg\u00fans servidores f\u00f3ra de Europa.</p> <p>1&amp;1, agora Ionos tam\u00e9n ten tido mala publicidade por algunhas das s\u00faas pol\u00edticas cos contratos.</p> <p>En xeral non hai empresas exentas de problemas. Se \u00e9 unha empresa grande e aguanta no tempo, vai ter sempre alg\u00fan problema. \u00c9 importante valorar estes incidentes e a s\u00faa resposta \u00e1 hora de elexir un servizo. \u00c9 conveniente mirar foros especializados en estas empresas de servizos, noticias e experiencias.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/","title":"\u2601\ufe0f OpenStack \u2014 \u2795 Crear instancias","text":"<p>Imos aprender a lanzar unha ou varias instancias en Openstack, un contorno de nube/cloud empregado en varias empresas e tam\u00e9n no CESGA.</p> <p>Se buscas recuperar unha instancia destru\u00edda en base a un volume gardado, consulta a secci\u00f3n \u2601\ufe0f OpenStack: Volumes \u2192 Como lanzar unha instancia a partir dun volume.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#configuracion-previa","title":"Configuraci\u00f3n previa","text":""},{"location":"nube-1-openstack-crear-lanzar-instancia/#acerca-de-openstack","title":"Acerca de Openstack","text":"<p>Por si tes curiosidade, Openstack ten moitos compo\u00f1entes, imos relacionarnos a trav\u00e9s do interfaz web con todos eles, para que te fagas unha idea:</p> <ul> <li>Horizon: O contorno de usuario (GUI). B\u00e1sicamente o panel de control ou dashboard que manexamos.</li> <li>Keystone: Provee autenticaci\u00f3n mediante diversos mecanismos (como usuario e contrasinal). Soporta: LDAP, OAuth, OpenID Connect, SAML e SQL</li> <li>Nova: Para acceso a recursos de computaci\u00f3n. Unha especie de meta-hypervisor que soporta: KVM, LXC (libvirt), QEMU, VMWare, Virtuozzo, zVM e Ironic. Fonte: docs openstack.</li> <li>Neutron: Xestiona as diferentes redes.</li> <li>Designate: Servizo de DNS.</li> <li>Barbicam: Ofrece almacenamento seguro de chaves, credenciais, certificados X509, chaves de cifrado...</li> <li>Ceilometer: Para monitorizar os recursos e ver que pasa. Saca m\u00e9tricas e garda o emprego hist\u00f3rico de recursos.</li> <li>Cinder: Provee almacenamento en bloques.</li> <li>Glance: Almacena e recupera imaxes do disco da m\u00e1quina virtual. Permite recuperar os datos dende distintas ubicaci\u00f3ns.</li> <li>Ironic: Permite o aprovisionamento de recursos hardware directamente, m\u00e1quinas virtuais ou contedores.</li> <li>Placement: Acceso API ao inventario e uso de recursos. Axuda a outros servizos a aprovisionar recursos.</li> <li>Swift: Permite o almacenamento de obxectos e provee de tolerancia a fallos.</li> <li>Octavia: Balanceador de carga.</li> <li>AODH: Servizo de alarmas. Provee disparadores e regras.</li> <li>Heat: Para orquestaci\u00f3n.</li> <li>Magnum: Fai posible a orquestaci\u00f3n de: Docker Swarm, Kubernetes e Apache Mesos en Openstack. Emprega heat para orquestar o Sistema Operativo.</li> <li>Manilla: Provee de acceso coordinado ou compartido a sistemas de arquivos compartidos ou distribuidos.</li> <li>Trove: Provee de bases de datos como servizo (relacionais e non relacionais).</li> <li>Zaqar: Servizo de mensaxer\u00eda.</li> <li>Mistral: Servizo de workflow/fluxo de traballo. Permite ordear e executar pasos. Xestiona o estado, a orde correta de execuci\u00f3n, paralelismo, sincronizaci\u00f3n e alta dispo\u00f1ibilidade.</li> <li>Zun: Servizo de contendores a trav\u00e9s de API.</li> </ul> <p>Podes atopar m\u00e1is informaci\u00f3n b\u00e1sica no artigo de redhat de informaci\u00f3n b\u00e1sica acerca de Openstack e se queres facer unha instalaci\u00f3n de Openstack, tam\u00e9n podes consultar este outro artigo en ingl\u00e9s de Daniel Persson.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#partes-do-panel-web-horizon","title":"Partes do panel web Horizon","text":"<p>Antes de comezar lembra que debes estar conectado \u00e1 VPN en caso necesario. No caso do CESGA, este panel de control est\u00e1 en: https://cloud.srv.cesga.es noutros casos de empresas que venden o servizo, debes crear o usuario de OpenStack antes de comezar.</p> <p>Inicia sesi\u00f3n no panel de control.</p> <p></p> <p>Se est\u00e1s no contorno do CESGA lembra empregar o dominio <code>hpc</code> e autenticar mediante <code>KeyStone Credentials</code>.</p> <p>ANtes de lanzar unha instancia \u00e9 unha boa pr\u00e1ctica e aforrar\u00e1s traballo se creas antes un par de chaves e defines correctamente un grupo de seguridade.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#creacion-do-par-de-chaves","title":"Creaci\u00f3n do par de chaves","text":"<p>Imos conectar sen contrasinal, cun par de claves p\u00fablica/privada. Podes ler m\u00e1is informaci\u00f3n acerca delas en: \ud83d\udd11 SSH e t\u00faneles. Esta forma de conectar \u00e9 o modo recomendado. Non se recomenda empregar contrasinais para conectar a servidores.</p> <p>Temos d\u00faas formas de crear este par de chaves. O habitual ser\u00eda telas xa creadas e empregar o comando <code>ssh-keygen</code> dende GNU/Linux ou dende PowerShell en Microsoft Windows. Este comando enc\u00e1rgase xa de crear os arquivos de chave p\u00fablica e privada cos permisos adecuados. Despois de creadas, poder\u00edamos subir a chave p\u00fablica (arquivo que rematar\u00e1 en .pub) que estar\u00eda dentro do directorio .ssh do noso directorio de usuario.</p> <p>Sen embargo, desta vez, imos facer que nos autoxenere unha clave SSH o propio panel web. Unha vez iniciemos sesi\u00f3n imos \u00e1: Computaci\u00f3n \u2192 Pares de claves.</p> <p></p> <p>Nesta p\u00e1xina podemos ver a lista de chaves (a parte p\u00fablica) que podemos asociar na creaci\u00f3n de instancias. As chaves que asociemos ser\u00e1n as que se po\u00f1an ao final do arquivo \ud83d\udcc4 $HOME/.ssh/authorized_keys para que poidamos conectar coas instancias que creemos.</p> <p>Se queremos crear un par novo, prememos no bot\u00f3n \"Crear Par de Claves\" e seleccionamos en \"Tipo de clave\" a opci\u00f3n \"Clave SSH\" e en Nombre de Par de Claves un nome calquera que nos sirva para identificar a clave.</p> <p></p> <p>Esto deber\u00eda baixarnos un arquivo co nome que lle te\u00f1amos dado rematado en .pem. Debemos gardalo, xa que cont\u00e9n a chave privada e non se poder\u00e1 volver a baixar. O que se env\u00eda ao servidor \u00e9 a parte p\u00fablica da chave.</p> <p>Podemos ter tantos pares de chaves como queiramos. \u00c9 recomendable empregar ou ben un xestor de chaves como KeepassXC conectado a un axente e sincronizar as chaves entre os equipos que traballemos ou ben xerar unha chave por equipo.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#creacion-do-grupo-de-seguridade","title":"Creaci\u00f3n do grupo de seguridade","text":"<p>Cando lanzamos unha instancia, esta debe ter un firewall. O grupo de seguridade \u00e9 o equivalente na nube a este firewall.</p> <p>Un grupo de seguridade ten un conxunto de regras de filtrado por protocolo, IP de orixe/destino e porto/s. Cada grupo de seguridade pode ter as s\u00faas propias regras.</p> <p>Unha instancia ten alomenos un grupo de seguridade.</p> <p>Imaxinemos un exemplo onde temos servidores de base de datos e servidores web. Probablemente non queiramos expo\u00f1er o porto 3306 dun MySQL a internet, pero si a alg\u00fans servidores web. Neste exemplo poder\u00edamos crear dous grupos de seguridade:</p> <ul> <li> <p>Servidores_web:</p> <ul> <li>Porto TCP 80 entrante aberto a 0.0.0.0/0.</li> <li>Porto TCP 3306 sa\u00ednte aberto a 0.0.0.0/0.</li> <li>Protocolo ICMP aberto a 0.0.0.0/0.</li> <li>Porto TCP 22 aberto a: 172.18.0.1/24.</li> </ul> </li> <li> <p>Servidores_bbdd:</p> <ul> <li>Porto TCP 3306 entrante aberto a 10.133.1.1/24.</li> <li>Protocolo ICMP aberto a 10.133.1.1/24 e 1.2.3.4/32.</li> <li>Porto UDP 1194 aberto a 1.2.3.4/32.</li> <li>Porto TCP 22 aberto a: 172.18.0.1/24.</li> </ul> </li> </ul> <p>Para crear estes dous grupos de seguridade de proba, debemos ir a: Red \u2192 Grupos de Seguridad.</p> <p></p> <p>Prememos no bot\u00f3n: \u2795 Crear grupo de seguridad.</p> <p></p> <p>Por defecto crear\u00e1 d\u00faas regras b\u00e1sicas que permiten todo o tr\u00e1fico sa\u00ednte, pero non o entrante. Hai que ter en conta ambos protocolos de rede: IPv4 e IPv6.</p> <p>.</p> <p>Se queremos engadir unha nova regra, prememos no bot\u00f3n Agregar regla.</p> <p>.</p> <p>Podemos elexir as opci\u00f3ns da direcci\u00f3n (entrante ou sa\u00ednte) porto ou rango de portos e os remotos, que tam\u00e9n poden ser outros grupos de seguridade.</p> <p>Unha vez engadida a regra, podemos borrala, pero non editala.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#lanzando-unha-ou-varias-instancias","title":"Lanzando unha ou varias instancias","text":"<p>Paso a paso</p> <p>Computaci\u00f3n \u2192 Instancias \u2192 Bot\u00f3n \"Lanzar instancia\"</p> <p></p> <p>Paso 1: Nome da instancia, n\u00famero de instancias a lanzar</p> <p></p> <p>Paso 2: Escollendo a imaxe base</p> <p></p> <p>Paso 3: Sabor da instancia (recursos)</p> <p></p> <p>Paso 4: Redes \u00e1s que se conectar\u00e1</p> <p></p> <p>Paso 5: Portos de rede</p> <p></p> <p>Paso 6: Grupos de seguridade</p> <p></p> <p>Paso 7: Autenticaci\u00f3n. Elexindo o par de chaves</p> <p></p> <p>Paso 8: Script de configuraci\u00f3n tras a instalaci\u00f3n</p> <p></p> <p>Paso 9: Grupo de servidores</p> <p></p> <p>Paso 10: Sugerencias de planificaci\u00f3n</p> <p></p> <p>Paso 11: Metadatos e executar instancia</p> <p></p>"},{"location":"nube-2-openstack-volumes/","title":"\u2601\ufe0f OpenStack \u2014 \ud83d\udcbf Volumes","text":"<p>Normalmente os servizos de virtualizaci\u00f3n na nube cobran polo uso de recursos: Procesador, memoria RAM, rede, GPU, espacio en disco...</p> <p>Non sempre necesitamos todos os servizos activos, polo que se queremos aforrar custos, debemos reducir recursos.</p> <p>Un volume \u00e9 o disco duro virtual onde se almacenan os datos das instancias en OpenStack.</p> <p>Imos ver unhas operaci\u00f3ns b\u00e1sicas sobre volumes en OpenStack empregando o interfaz web Horizon de Nova.</p> <ul> <li>Como cambiarlle o nome do volume a unha instancia.</li> <li>Como asociar/desasociar un volume dunha instancia.</li> <li>Como extender un volume.</li> <li>Como clonar un volume.</li> <li>Como borrar unha instancia.</li> <li>Como lanzar unha instancia a partir dun volume.</li> </ul>"},{"location":"nube-2-openstack-volumes/#como-cambiarlle-o-nome-do-volume-a-unha-instancia","title":"Como cambiarlle o nome do volume a unha instancia.","text":"<p>Non \u00e9 preciso nin desasociar o volume da instancia nin parala para renomear os volumes. Isto \u00e9 \u00fatil para localizalos con posterioridade.</p> <ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos no nome da instancia e nos sair\u00e1 informaci\u00f3n sobre a mesma, imos ao final da p\u00e1xina e veremos os volumes asociados:</p> <p></p> </li> <li> <p>Tras premer no volume ao que queremos cambiarlle o nome, aparecer\u00e1 informaci\u00f3n sobre o mesmo:</p> <p></p> </li> <li> <p>Prememos no bot\u00f3n \"Editar volumen\" e mudamos o nome ao que queiramos, seguidamente confirmamos os cambios no bot\u00f3n azul.</p> <p></p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-asociar-un-volume-a-unha-instancia-en-execucion","title":"Como asociar un volume a unha instancia en execuci\u00f3n.","text":"<ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos na frecha de \"Crear instancia\" da instancia correspondente para que nos apareza o men\u00fa:</p> <p></p> </li> <li> <p>Seleccionamos a opci\u00f3n \"Asociar Volume\", seleccionamos o volume que queremos asociar e prememos no bot\u00f3n azul para confirmar.</p> <p></p> </li> <li> <p>Debemos montar o volume no sistema operativo. Primeiro entramos na instancia (seleccionamos o nome no listado de instancias) e vemos ao final a qu\u00e9 dipositivo virtual se asociou o novo volume, neste caso a <code>/dev/vdb</code></p> <p></p> </li> <li> <p>Mont\u00e1molo co comando mount (ou de ser preciso formateamos). Podemos asegurarnos que exista correctamente dentro da m\u00e1quina o interfaz virtual que vimos previamente no interfaz web co comando <code>lsblk</code> dende unha consola SSH.</p> <p>5.1 Opci\u00f3n 1: Para montar un volume:</p> <pre><code>lsblk\nsudo mkdir /mnt/vdb\nsudo mount /dev/vdb /mnt/vdb\n</code></pre> <p>5.2 Opci\u00f3n 2: Para formatear (borra os datos) dun volume:</p> <pre><code>lsblk\nsudo mkdir /mnt/vdb\nsudo mkfs.ext3 /dev/vdb\nsudo mount /dev/vdb /mnt/vdb\n</code></pre> </li> <li> <p>Asegur\u00e1monos que estea correctamente montado executando o comando <code>mount</code> e vendo que aparece na listaxe.</p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-desasociar-un-volume","title":"Como desasociar un volume","text":"<p>Importante: Se non queres perder datos, lembra apagar a instancia se lle vas a desasociar un volume. A outra opci\u00f3n \u00e9 desmontar previamente o dispositivo.</p> <p>Nota: Non se pode desasociar o volume ra\u00edz (o que cont\u00e9n o sistema operativo) dunha instancia en execuci\u00f3n, para eso deber\u00e1s apagala ou borrala. Se non tes marcada a opci\u00f3n de borrar o volume cando se borre a instancia, o volume non deber\u00eda borrarse polo feito de eliminar a instancia.</p> <p>Imos desasociar un volume adicional.</p> <ol> <li> <p>Buscamos o volume con calquera dos comandos:</p> <ul> <li><code>mount</code></li> <li><code>lsblk</code></li> <li><code>df -h</code></li> </ul> </li> <li> <p>Desmontamos o volume:</p> <pre><code>umount /mnt/vdb\n</code></pre> </li> <li> <p>Imos \u00e1 interfaz web \u21d2 Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos na frecha de \"Crear instancia\" da instancia correspondente para que nos apareza o men\u00fa:</p> <p></p> </li> <li> <p>Seleccionamos a opci\u00f3n \"Desasociar Volume\", seleccionamos o volume que queremos desasociar e prememos no bot\u00f3n azul para confirmar.</p> <p></p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-extender-un-volume","title":"Como extender un volume.","text":"<p>Se o volume \u00e9 de sistema, debemos apagar a m\u00e1quina (realmente p\u00f3dese facer coa instancia encendida e logo reiniciar pero NON \u00e9 recomendable).</p> <ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos no nome da instancia e nos sair\u00e1 informaci\u00f3n sobre a mesma, imos ao final da p\u00e1xina e veremos os volumes asociados:</p> <p></p> </li> <li> <p>Tras premer no volume que queremos extender, aparecer\u00e1 informaci\u00f3n sobre o mesmo:</p> <p></p> </li> <li> <p>Prememos na frecha \u00e1 dereita do bot\u00f3n \"Editar volumen \u2193\" e seleccionamos \"Extender Volumen\".</p> <p></p> </li> <li> <p>Po\u00f1emos o novo tama\u00f1o e confirmamos co bot\u00f3n azul. Finalmente volvemos encender a instancia ou ven a reiniciamos de estar encendida.</p> </li> </ol> <p>Opci\u00f3n: Se non \u00e9 un volume de sistema, debemos desmontalo, cambiar o tama\u00f1o da partici\u00f3n e volvelo montar. Exemplo:</p> <pre><code>lsblk\ndf -h\nsudo umount /mnt/vdb\nsudo e2fsck -f /dev/vdb\nsudo resize2fs /dev/vdb\nsudo mount /dev/vdb /mnt/vdb\nlsblk\ndf -h\n</code></pre>"},{"location":"nube-2-openstack-volumes/#como-clonar-un-volume","title":"Como clonar un volume.","text":"<p>Debe estar o volume desasociado para que non dea problemas e para que nos deixe seleccionalo.</p> <ol> <li> <p>Imos a \"Vol\u00famenes \u21d2 Vol\u00famenes\" e prememos no bot\u00f3n \"Crear\"     </p> </li> <li> <p>No cadro damos un nome ao novo volume, en \"Origen del volumen\" seleccionamos \"Volumen\" e en \"Usar un volumen como origen\" seleccionamos a volume que queremos clonar. Confirmamos premendo no bot\u00f3n azul.</p> <p></p> </li> <li> <p>Tras uns intres xa estar\u00e1 listo o novo volume para asociar a unha instancia ou para crear unha nova instancia baseada nel.</p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-borrar-unha-instancia-sen-borrar-o-volume","title":"Como borrar unha instancia sen borrar o volume.","text":"<ul> <li> <p>Opci\u00f3n 1: Est\u00e1 marcado borrar volume: Desasociamos antes o volume e despois borramos a instancia.</p> </li> <li> <p>Opci\u00f3n 2: Non est\u00e1 marcado borrar volume ao borrar a instancia. Simplemente borramos a instancia.</p> </li> </ul>"},{"location":"nube-2-openstack-volumes/#como-lanzar-unha-instancia-a-partir-dun-volume","title":"Como lanzar unha instancia a partir dun volume.","text":"<p>Se destrues unha instancia, por defecto non se destr\u00fae o volume (salvo que as\u00ed o te\u00f1as marcado). Se non vas a empregar a instancia ata a seguinte clase, \u00e9 unha boa pr\u00e1ctica borrala e volvela crear baseada no volume de datos que ti\u00f1a orixinalmente, as\u00ed como moito cambiar\u00e1 a IP. Este m\u00e9todo tam\u00e9n \u00e9 \u00fatil se queremos cambiar o sabor da instancia (CPU/RAM).</p> <ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos no bot\u00f3n \"Lanzar instancia\".</p> </li> <li> <p>Damos un nome \u00e1 nova instancia e decidimos cantas queremos lanzar (por defecto 1):</p> <p></p> </li> <li> <p>En \"Origen\" debemos marcar en \"Seleccionar Origen de arranque\" a opci\u00f3n \"Volumen\". Logo, abaixo en dispo\u00f1ible podemos buscar o volume que nos interese (que non estea xa asociado a outra m\u00e1quina) e premer no bot\u00f3n co frecha arriba \u2191 para seleccionalo.</p> <p></p> </li> <li> <p>Escollemos un sabor (procesador/RAM) como escoller\u00edamos nunha creaci\u00f3n normal dunha instancia:</p> <p></p> </li> <li> <p>Seleccionamos a rede na que queremos que estea:     </p> </li> <li> <p>Seleccionamos en caso necesario a configuraci\u00f3n en \"Puertos de Red\".     </p> </li> <li> <p>Marcamos o grupo de seguridade que lle queiramos aplicar:     </p> </li> <li> <p>\u00c9 importante seleccionar tam\u00e9n o par de chaves que queiramos meter a maiores dos que xa te\u00f1a. Presta atenci\u00f3n a esta parte, se \u00e9 unha imaxe doutra persoa incluir\u00e1 as chaves p\u00fablicas e privadas e meter\u00e1 as que ti lle indiques a maiores.</p> <p></p> </li> <li> <p>Finalmente prememos en \"Lanzar instancia\" e tras uns intres xa a teremos lanzada co volume seleccionado.</p> </li> </ol>"},{"location":"nube-3-openstack-grupos-seguridade/","title":"\u2601\ufe0f OpenStack \u2014 \ud83d\udee1\ufe0f Grupos de seguridade","text":"<p>O firewall na nube. Cada grupo de seguridade cont\u00e9n regras.</p> <p>Cada regra pode ser:</p> <ul> <li>Entrante, sa\u00ednte</li> <li>TCP/UDP</li> <li>Un porto ou un rango de portos</li> </ul> <p>En OpenStack acc\u00e9dese a trav\u00e9s do men\u00fa: \"Red\" \u21d2 \"Grupo de Seguridad\".</p> <p>Ollo, nalg\u00fans contornos alg\u00fans portos poden estar pechados debido a outras regras. Por exemplo: Pechar por seguridade os portos RDP ou o 3306 de MySQL e que non se poidan abrir a\u00ednda que se meta expl\u00edcitamente unha regra.</p>"},{"location":"nube-4-openstack-recovey/","title":"\u2601\ufe0f OpenStack \u2014 \u26c8\ufe0f Recuperaci\u00f3n","text":""},{"location":"nube-4-openstack-recovey/#recuperando-instancias-do-openstack-a-traves-dos-volumes","title":"Recuperando instancias do OpenStack a trav\u00e9s dos volumes","text":"<p>Se te tes quedado fora dunha instancia, sempre podes borrala (sen borrar o volume de datos asociado) e meter ese volume noutra instancia (nova ou existente). Desde esa m\u00e1quina a que tes acceso podes facer os cambios necesarios no volume, por exemplo copiar unha chave SSH ou po\u00f1erlle contrasinal ao usuario co que conectas (esto \u00faltimo \u00e9 inseguro).</p> <p>Un volume non debe estar asociado a outra instancia para poder asocialo (attach). Unha vez est\u00e1 libre, p\u00f3dese asociar a unha instancia en execuci\u00f3n.</p> <pre><code>sudo su\nlsblk # (1)!\nmkdir /mnt/volume-a-recuperar\nmount /dev/DISPOSITIVO /mnt/volume-a-recuperar\n</code></pre> <ol> <li>Este comando serve para averiguar o nome e n\u00famero do dispositivo (o \u00faltimo).</li> </ol>"},{"location":"nube-4-openstack-recovey/#opcion-1-mudando-o-contrasinal-de-usuario","title":"Opci\u00f3n 1: Mudando o contrasinal de usuario","text":"<pre><code>chroot /mnt/volume-a-recuperar /bin/bash\npasswd USUARIO # (1)!\n</code></pre> <ol> <li>En usuario debes po\u00f1er o usuario que empregas para conectar (mudar\u00e1s a clave del).</li> </ol>"},{"location":"nube-4-openstack-recovey/#opcion-2-copiando-a-chave-ssh-ao-authorized_keys","title":"Opci\u00f3n 2: Copiando a chave SSH ao authorized_keys","text":"<pre><code>mkdir /mnt/volume-a-recuperar/home/USUARIO/.ssh/\ncp $HOME/.ssh/id_rsa.pub /mnt/volume-a-recuperar/home/USUARIO/.ssh/\n</code></pre> <p>Emprega os comandos con sentido. Debes adaptalos ao teu caso.</p> <p>Esta t\u00e9cnica p\u00f3dese empregar tam\u00e9n nos servicios de computaci\u00f3n na nube como: Amazon AWS, Google Cloud Services, Microsoft Azure e outros.</p>"},{"location":"nube-5-openstack-crear-swap/","title":"\ud83d\udc22 SWAP en GNU/Linux","text":"<p>A SWAP \u00e9 a memoria virtual en GNU/Linux. Cando se acaba a memoria f\u00edsica, baixanse algunhas p\u00e1xinas de memoria ao almacenamento secundario adicado especialmente a isto.</p> <p>Algunhas veces pode que non chegue esta memoria virtual (ou que non fose configurada). Esto pod\u00e9molo ver co comando:</p> <pre><code>free -m\n</code></pre> <p>Se non vemos swap ou creemos que \u00e9 insuficiente, podemos engadir un arquivo para reservar parte do noso disco a esta memoria secundaria.</p>"},{"location":"nube-5-openstack-crear-swap/#pasos-para-engadir-un-arquivo-swap","title":"Pasos para engadir un arquivo SWAP","text":"<ol> <li>Creamos un arquivo para swap e o formateamos:</li> </ol> <pre><code>dd if=/dev/zero of=/arquivoswap bs=1024K count=4096\nmkswap /arquivoswap\n</code></pre> <ol> <li>Editamos como root o \u00b4/etc/fstab\u00b4. Este ficheiro de configuraci\u00f3n ind\u00edcanos que sistemas de arquivos se usan e se montan no sistema, tanto para o arranque, como para dar permisos de montaxe a usuarios.</li> </ol> <pre><code>sudo nano /etc/fstab\n</code></pre> <ol> <li>Nese arquivo metemos que o arquivo de swap se monte ao arranque:</li> </ol> <pre><code>/arquivoswap none swap sw 0 0\n</code></pre> <p>Curiosidade: Podes saber cando espacio ocupa un arquivo ou directorio co comando: <code>du -hs /directorio/</code></p> <ol> <li>Pon de m\u00e1scara de permisos 0600 ao arquivo /arquivoswap. Emprega o comando chmod. Estes permisos son bastante restrictivos, non queremos que calquer usuario poida acceder a este arquivo:</li> </ol> <pre><code>chmod 0600 /ficherito\n</code></pre> <ol> <li>Gardamos o arquivo e logo montamos t\u00f3dolos arquivos de swap (para non ter que reiniciar a m\u00e1quina):</li> </ol> <pre><code>swapon -a\n</code></pre> <ol> <li>Podemos ver que este espacio de swap foi engadido empregando de novo:</li> </ol> <pre><code>free -m\n</code></pre>"},{"location":"nube-6-comandos/","title":"\u2601\ufe0f OpenStack \u2014 \u2699\ufe0f Crear instancias autom\u00e1ticamente","text":"<p>Esta receita est\u00e1 creada para o contorno do CESGA, sen embargo, pode adaptarse de xeito sinxelo a calquer outro contorno con OpenStack.</p> <ol> <li> <p>Conectar \u00e1 VPN.</p> </li> <li> <p>Conectar por SSH.</p> <pre><code>ssh USUARIO@hadoop.cesga.es\n</code></pre> </li> <li> <p>Imos a: https://cloud.srv.cesga.es \u2192 Acceso a API \u2192 Descargar fichero RC de OpenStack \u2192 Fichero Openstack RC.</p> <pre><code>nano openstack.sh\n</code></pre> </li> <li> <p>Pegamos o contenido de OpenStack que temos baixado e gardamos (Ctrl+o, Enter) e sa\u00edmos (Ctrl+x).</p> </li> <li> <p>Cargar o contorno de openstack, PATH e autocompletado, as\u00ed como as variables de contorno.</p> <pre><code>module load openstack\nsource /opt/cesga/openstack/osc.bash_completion\nsource ./openstack.sh\n</code></pre> </li> <li> <p>Pediranos o contrasinal do noso usuario, introduc\u00edmolo. Tam\u00e9n aproveitamos para configurar un par de variables de contorno.</p> <pre><code>USUARIO=${OS_USERNAME}\nCENTRO='aqui-o-teu-centro'\n</code></pre> </li> <li> <p>Probamos se todo funciona.</p> <pre><code>openstack server list\n</code></pre> </li> <li> <p>Crear un par de claves no servidor e subir a chave p\u00fablica ao OpenStack.</p> <pre><code>ssh-keygen\nopenstack keypair create --public-key ~/.ssh/id_rsa.pub key-${USUARIO}-${CENTRO}-srvhadoop\n</code></pre> </li> <li> <p>Creamos o noso grupo de seguridade chamado segrup-USUARIO e que permita acceder a todo o mundo por SSH (normalmente abrir\u00edamolo s\u00f3 ao noso enderezo IP).</p> <pre><code>openstack security group create sg-centro-${USUARIO}\nopenstack security group rule list sg-centro-${USUARIO}\nopenstack security group rule create --proto tcp --dst-port 22 --ingress --remote-ip 0.0.0.0/0 sg-centro-${USUARIO}\n</code></pre> </li> <li> <p>Creamos catro instancias.</p> <pre><code>for numero in {1..4..1}; do \\\n  openstack server create --boot-from-volume 80 --image baseos-Rocky-8.7-v4 --flavor a1.4c8m --key-name key-${USUARIO}-${CENTRO}-srvhadoop --network provnet-formacion-vlan-133 --security-group segrup-${USUARIO} ${USUARIO}-${CENTRO}-srv${numero}; done\n</code></pre> </li> <li> <p>Se quix\u00e9ramos borrar as instancias</p> <pre><code>for numero in {1..4..1}; do \\\n   openstack server delete ${USUARIO}-${CENTRO}-srv${numero}; done\n</code></pre> </li> </ol> <p>Se queremos executar comandos en varias instancias \u00e1 vez debemos empregar clustershell (clush) qu est\u00e1 instalado no servidor FT3.</p> <p>Para evitar que nos pregunte se confiamos na clave dunha instancia a primeira vez que conecte, podemos empregar:</p> <pre><code>ssh-keyscan -H IP_OU_DNS_DO_SERVIDOR &gt;&gt; $HOME/.ssh/known_hosts\n</code></pre>"},{"location":"powerbi-0-python/","title":"\ud83d\udcf6 PowerBi e Python","text":""},{"location":"powerbi-0-python/#crear-un-novo-contorno-de-conda-para-microsoft-powerbi","title":"Crear un novo contorno de conda para Microsoft PowerBi","text":"<pre><code>conda create -n powerbi python=3.11\nconda activate powerbi\nconda install -c conda-forge matplotlib pandas mkl-service\n</code></pre>"},{"location":"powerbi-0-python/#configurar-un-contorno-conda-en-microsoft-powerbi","title":"Configurar un contorno conda en Microsoft PowerBI","text":"<ul> <li>Averiguar cal \u00e9 o directorio do contorno \"powerbi\", por exemplo con comando:</li> </ul> <pre><code>conda env list\n</code></pre> <ul> <li>Ir a: \"Archivo -&gt; Opciones y configuraci\u00f3n -&gt; Opciones\".</li> <li>Imos na parte esquerda, en: \"Creaci\u00f3n de scripts de Python\"</li> <li>En \"Directorios ra\u00edz de Python detectados:\" seleccionamos \"Otros\" e nos aparecer\u00e1 unha caixa para seleccionar un directorio cunha instalaci\u00f3n de Python.</li> <li>En \"Establezca un directorio ra\u00edz para Python\" preme en \"Examinar\" e selecciona o cartafol do contorno de conda que temos averiguado anteriormente.</li> </ul>"},{"location":"powerbi-0-python/#empregar-codigo-en-python-como-orixe-de-datos","title":"Empregar c\u00f3digo en Python como orixe de datos","text":"<ul> <li>Facer click en \"Inicio -&gt; Obtener datos -&gt; M\u00e1s...\"</li> <li>Buscar: \"Script de Python\".</li> <li>Podes empregar este c\u00f3digo como exemplo:</li> </ul> <pre><code>import pandas as pd\ndatos_estudantes = ({\n    'Nomes':[\"Fulano\", \"Mengana\", \"Zutano\", \"Perengana\"],\n    'Pesos' :[83, 56, 90, 60],\n    'Notas':[9, 8, 7, 6]\n        })\ndf = pd.DataFrame(datos_estudantes)\n</code></pre>"},{"location":"powerbi-0-python/#acceso-dende-powerbi-a-hadoop","title":"Acceso dende PowerBi a Hadoop","text":"<p>Podes acceder aos arquivos que estean no HDFS dende PowerBI </p> <p>Ver t\u00f3dolos arquivos:</p> <p>http://X.Y.Z.T:9870/webhdfs/v1/user?op=LISTSTATUS</p> <p>Descargar un arquivo concreto:</p> <p>http://hadoop1:9864/webhdfs/v1/user/oteusuario/arquivo.extension?op=OPEN&amp;namenoderpcaddress=hadoop1:9000&amp;offset=0</p> <p>Cambiar C:\\Windows\\system32\\drivers\\etc\\hosts e meter a IP do master co nome:</p> C:\\Windows\\system32\\drivers\\etc\\hosts<pre><code>10.133.28.88 hadoop1\n</code></pre> <p>Isto \u00e9 necesario porque internamente, cando baixamos un arquivo, por defecto temos configurado que vaia ao nome.</p> <p>Tam\u00e9n pode resultarche interesante:</p> <ul> <li>Expresi\u00f3ns DAX: https://learn.microsoft.com/es-es/dax/</li> <li>WebHDFS: https://hadoop.apache.org/docs/r1.0.4/webhdfs.html</li> </ul>"},{"location":"python-0-conceptos-previos/","title":"\ud83d\uddc2\ufe0f Arquivos en Python","text":""},{"location":"python-0-conceptos-previos/#rutas-absolutas-e-relativas-en-microsoft-windows-e-gnulinux","title":"Rutas absolutas e relativas en Microsoft Windows e GNU/Linux","text":"<p>As\u00ed de xeito r\u00e1pido poder\u00edamos definir:</p> <ul> <li>Ruta absoluta: Ruta completa, todas as indicaci\u00f3ns dende cero para chegar \u00e1 ruta.</li> <li>Ruta relativa: Partindo do directorio actual, as indicaci\u00f3ns para chegar \u00e1 ruta.</li> </ul>"},{"location":"python-0-conceptos-previos/#son-cuestions-de-formato-de-texto","title":"Son cuesti\u00f3ns de formato (de texto)...","text":"<p>Hai diferentes maneiras de po\u00f1er unha ruta (absoluta ou relativa) e que a mesma sexa compatible con Microsoft Windows e GNU/Linux.</p> <p>A m\u00e1is simple \u00e9 po\u00f1endo barras inclinadas / en lugar das invertidas \\</p> <p>No caso de querer empregar barras invertidas, debemos empregar dobre barra invertida para escapar o car\u00e1cter de escape por defecto, que \u00e9 a mesma barra invertida.</p> <p>Exemplo: <code>'C:\\\\Users\\\\USUARIO\\\\Downloads\\\\datasets\\\\proba.csv'</code></p> <p>Adem\u00e1is debemos detectar o sistema se pretendemos que o noso programa funcione en ambos e pretendemos empregar rutas escritas \"a man\".</p> <p>\ud83d\uddd2\ufe0f Nota: En Microsoft Windows poder\u00edamos omitir a letra da unidade nas rutas \u00ababsolutas\u00bb e coller\u00eda por defecto a letra da unidade onde se est\u00e1 a executar o script.</p> <p>\u26a0\ufe0f AVISO: Neste exemplo empregaremos rutas absolutas.</p> <pre><code>import platform\nsistema = platform.system()\n\nif sistema.casefold() == 'Windows'.casefold():\n    path_base='C:/Users/USUARIO/Downloads/datasets/'\nelse:\n    path_base='/home/usuario/Downloads/datasets/'\n</code></pre>"},{"location":"python-0-conceptos-previos/#comparacion-de-cadeas-de-texto","title":"Comparaci\u00f3n de cadeas de texto","text":"<p>\ud83d\udca1 Curiosidade polo m\u00e9todo casefold() empregado no c\u00f3digo de enriba? \u00c9 unha boa pr\u00e1ctica para comparar determinadas cadeas de texto, podes mirar a documentaci\u00f3n en: https://docs.python.org/3/library/stdtypes.html#str.casefold. B\u00e1sicamente ignora as mai\u00fasculas e min\u00fasculas e ten en conta cousas como que a dobre ss no alem\u00e1n pode equivaler \u00e1: \u00df. O algoritmo de casefold est\u00e1 descrito aqu\u00ed: https://www.unicode.org/versions/Unicode15.0.0/ch03.pdf. Se simplemente queres ignorar mai\u00fasculas, podes aplicar un lower() a ambas cadeas.</p> <p>Para engadir subdirectorios \u00e1 ruta, temos varias opci\u00f3ns:</p>"},{"location":"python-0-conceptos-previos/#suma-de-cadeas-de-texto","title":"Suma de cadeas de texto","text":"<pre><code>with open(path_base+'a-coruna.csv') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre> <p>\ud83d\udca1 Curiosidade do que fai o m\u00e9todo rstrip()? B\u00e1sicamente borra os caracteres da cola que lle indiquemos. Se non indicamos ning\u00fan, ent\u00f3n borrar\u00e1 os caracteres que sexan de tipo espacio en branco: espacios ' ', tabuladores '\\t' e novas li\u00f1as '\\n'. https://www.w3schools.com/python/ref_string_rstrip.asp e https://docs.python.org/3/library/stdtypes.html.</p>"},{"location":"python-0-conceptos-previos/#con-ospathjoin","title":"Con os.path.join","text":"<pre><code>import os\n\nwith open(os.path.join(path_base, 'lugo.csv')) as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre> <p>Tam\u00e9n existe a librar\u00eda pathlib: https://docs.python.org/3/library/pathlib.html.</p>"},{"location":"python-0-conceptos-previos/#con-f-string-format-string","title":"Con f-string (format string)","text":"<p>Po\u00f1eremos unha f antes das comillas e logo as variables entre chaves {}:</p> <pre><code>with open(f'{path_base}pontevedra.csv') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#con-r-string-raw-string","title":"Con r-string (raw string)","text":"<p>E se nos po\u00f1emos burros, con r-string tam\u00e9n podemos empregas as barras invertidas sen necesidade de escapalas. O texto non se interpreta, \u00e9 tal cual.</p> <pre><code>with open(r'C:\\Users\\USUARIO\\Downloads\\datasets\\ourense.csv') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#con-fr-string-format-e-raw","title":"Con fr-string (format e raw)","text":"<p>Tam\u00e9n podemos mezclar ambas combinaci\u00f3ns para obter o mellor de ambos mundos.</p> <pre><code>arquivo='ourense.csv'\nwith open(fr'C:\\Users\\USUARIO\\Downloads\\datasets\\{arquivo}') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#como-crear-un-arquivo-temporal","title":"C\u00f3mo crear un arquivo temporal","text":"<pre><code>import os\nimport tempfile\n\narquivo_temporal = os.path.join(tempfile.mktemp())\nprint(arquivo_temporal)\n</code></pre> <p>Esto daranos unha ruta a un novo arquivo que non existe cun nome que empezar\u00e1 por <code>tmp</code> e logo ter\u00e1 varios caracteres aleatorios. Exemplos: <code>tmp3yas5ei1</code>, <code>tmpvtwvejgk</code>.</p> <p>Dependendo do sistema, crear\u00e1 o arquivo en distintas ubicaci\u00f3ns:</p> <ul> <li>En Microsoft Windows no cartafol: <code>C:\\Users\\USUARIO\\AppData\\Local\\Temp\\</code></li> <li>En GNU/Linux no directorio temporal: <code>/tmp/</code></li> </ul>"},{"location":"python-0-conceptos-previos/#ler-arquivos-modo-simple","title":"Ler arquivos (modo simple)","text":"<pre><code>f = open(\"tmp.txt\", \"r\")\nprint(f.read())\n</code></pre>"},{"location":"python-0-conceptos-previos/#ler-arquivos-por-linas","title":"Ler arquivos por li\u00f1as","text":"<pre><code>ficheiro = open('/tmp/tmp.tmp', 'r')\n\nwhile li\u00f1a := ficheiro.readline():\n    print(li\u00f1a.rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#escribir-e-sobreescribir-nun-arquivo","title":"Escribir (e sobreescribir) nun arquivo","text":"<pre><code>ficheiro = open(\"tmp.txt\", \"w\")\nficheiro.write(\"Hola mundo!\")\nficheiro.close()\n</code></pre>"},{"location":"python-0-conceptos-previos/#como-engadir-contido-ao-final-dun-arquivo","title":"C\u00f3mo engadir contido ao final dun arquivo","text":"<pre><code>## Ler arquivos (modo simple)\nficheiro = open(\"tmp.txt\", \"a\")\nficheiro.write(\"Outra li\u00f1a!\")\nficheiro.close()\n</code></pre>"},{"location":"python-0-conceptos-previos/#manexo-de-erros","title":"\u2757 Manexo de erros","text":"<pre><code>import sys\n\nruta_arquivo=\"/tmp/tmp.tmp\"\n\ntry:\n  ficheiro = open(ruta_arquivo) #Se engado: 'rb' podo abrir o arquivo en binario\nexcept FileNotFoundError:\n    print(f\"Non se pode atopar o arquivo: {ruta_arquivo}.\")\n    sys.exit(1)\nexcept OSError:\n    print(f\"Erro de sistema abrindo o arquivo: {ruta_arquivo}\")\n    sys.exit(1)\nexcept Exception as err:\n    print(f\"Ocorreu un erro desco\u00f1ecido abrindo o arquivo: {ruta_arquivo} Erro: \",repr(err))\n    sys.exit(1)\nelse:\n  while li\u00f1a := ficheiro.readline():\n    print(li\u00f1a.rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#manexo-de-erros-con-with","title":"Manexo de erros con with","text":"<pre><code>ruta_arquivo=\"/tmp/tmp.tmp\"\n\nwith open(ruta_arquivo) as ficheiro:\n    while li\u00f1a := ficheiro.readline():\n        print(li\u00f1a.rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#tipos-de-apertura","title":"Tipos de apertura","text":"<p>No open() podemos especificar principalmente: r (lectura, por defecto), w (escritura), a (append ou engadir ao final) entre outras.</p> <p>Tam\u00e9n podemos abrir o arquivo no modo por defecto que \u00e9 modo texto (t) ou en binario (b)</p> <p>M\u00e1is informaci\u00f3n:</p> <ul> <li>https://www.w3schools.com/python/python_file_write.asp</li> </ul>"},{"location":"python-1-maxias/","title":"\ud83e\ude84 Ipython: Maxias pit\u00f3nicas","text":""},{"location":"python-1-maxias/#e-outras-herbas","title":"E outras herbas","text":"<p>Ipython engade algo de funcionalidade na consola: autocopletado, maxias, etc. \u00c9 un python interactivo. O jupyterlab precisa de ipython e ipykernel para funcionar correctamente.</p> <p>Podemos lanzar unha consola interactiva de iPython con ese mesmo comando:</p> <pre><code>(bigdata) PS C:\\&gt; ipython\nPython 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]\nType 'copyright', 'credits' or 'license' for more information\nIPython 8.12.0 -- An enhanced Interactive Python. Type '?' for help.\n</code></pre> <p>Podemos completar ou autocompletar e obter axuda con: TAB, Ctrl+TAB, Ctrl+Espacio...</p> <p>Tam\u00e9n temos dispo\u00f1ibles unha serie de funci\u00f3ns listas para empregar nos notebooks que poden ser moi \u00fatiles: https://ipython.readthedocs.io/en/stable/interactive/magics.html</p> <p>A continuaci\u00f3n veremos algunhas.</p>"},{"location":"python-1-maxias/#time","title":"%time","text":"<p>Perm\u00edtenos medir canto tempo leva unha execuci\u00f3n determinada.</p> <p>Exemplo:</p> <pre><code>import time\nfrom random import randint\n\ndef tarefa_pit\u00f3nica():\n    tempo=randint(1, 10)\n    print(f'Vaime levar: {tempo}')\n    time.sleep(tempo)\n\n%time tarefa_pit\u00f3nica()\n</code></pre>"},{"location":"python-1-maxias/#run","title":"%run","text":"<p>Executa scripts externos. Pode ser moi \u00fatil para preparar unha contorna cos datos, etc.</p> <pre><code>%run holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#load","title":"%load","text":"<p>Amosa o c\u00f3digo e despois o executa</p> <pre><code>%load holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#edit","title":"%edit","text":"<p>Abre o c\u00f3digo para edici\u00f3n e logo permite executalo</p> <pre><code>%edit holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#amosar-axuda-dunha-maxia","title":"Amosar axuda dunha maxia:","text":"<pre><code>%MAXIA??\n</code></pre> <pre><code>%edit??\n</code></pre>"},{"location":"python-1-maxias/#pycat","title":"%pycat","text":"<p>Amosa o c\u00f3digo</p> <pre><code>%pycat holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#who","title":"%who","text":"<p>Amosa as variables en memoria</p> <pre><code>%who\n</code></pre>"},{"location":"python-1-maxias/#reset","title":"%reset","text":"<p>Borra o estado da memoria</p> <pre><code>%reset\n</code></pre>"},{"location":"python-1-maxias/#save","title":"%save","text":"<p>Salva o estado da sesi\u00f3n, \u00e9 dicir, as li\u00f1as que foron executadas.</p> <pre><code>%save C:\\\\Users\\\\USUARIO\\\\sesion.py\n</code></pre>"},{"location":"python-1-maxias/#lsmagic","title":"%lsmagic","text":"<p>Lista as diferentes maxias</p> <pre><code>%lsmagic\n</code></pre>"},{"location":"python-1-maxias/#env","title":"%env","text":"<p>Amosa as variables do sistema</p> <pre><code>%env\n</code></pre>"},{"location":"ssh-0-chaves-tuneles/","title":"\ud83d\udd11 SSH e t\u00faneles","text":"<p>E todo sen cavar nin picar pedra. Con pouco esforzo comprender\u00e1s dunha vez como funciona SSH, os erros m\u00e1is habituais e como facer un t\u00fanel e os tipos que hai. Comprender\u00e1s a potencia que esconden e aprender\u00e1s a explotala.</p>"},{"location":"ssh-0-chaves-tuneles/#que-e-ssh","title":"\u25fc\ufe0f Qu\u00e9 \u00e9 SSH","text":"<p>Un protocolo cifrado (Secure SHell) para conectar cun servidor e poder enviarlle comandos en modo texto. Permite moitas m\u00e1is opci\u00f3ns, como por exemplo, redirixir portos.</p>"},{"location":"ssh-0-chaves-tuneles/#xerar-chave-ssh","title":"\ud83d\udddd\ufe0f Xerar chave SSH","text":"<p>Hoxe en d\u00eda deber\u00edamos abandonar a autenticaci\u00f3n por usuario e clave en prol dun m\u00e9todo m\u00e1is seguro, o cifrado asim\u00e9trico que emprega chave p\u00fablica e privada.</p> <p>Dentro do noso HOME (cartafol de usuario). Habitualmente en GNU/Linux: <code>/home/USUARIO</code> e en Microsoft Windows: <code>C:\\Users\\USUARIO</code>, debe existir un directorio/cartafol <code>.ssh</code> que pode conter o seguinte:</p> <ul> <li>\ud83d\udcc1 .ssh<ul> <li>\ud83d\udcc4 known_hosts: Fingerprints dos servidores aos que nos temos conectado. A primeira vez que conectamos cun servidor, av\u00edsanos e nos amosa o fingerprint. Te\u00f3ricamente deber\u00edamos asegurarnos que \u00e9 correcto para evitar ataques tipo MITM.</li> <li>\ud83d\udcc4 authorized_keys: Fingerprints das chaves p\u00fablicas autorizadas a entrar no servidor.</li> <li>\ud83d\udcc4 config: Para non ter que empregar opci\u00f3ns ao conectar. P\u00f3dese empregar unha chave, usuario e redirecci\u00f3n de portos diferente por cada host.</li> <li>\ud83d\udd11 id_rsa: Chave privada (non publicar e protexer por frase de paso) permite descifrar/asinar o que se cifrou coa chave p\u00fablica.</li> <li>\ud83d\udd10 id_rsa.pub: Chave p\u00fablica, p\u00f3dese publicar e subir aos servidores. D\u00e9bese engadir ao final do arquivo known_hosts para autorizar a nosa chave.</li> </ul> </li> </ul> <p>Se non existe, podemos facer unha das seguintes cousas para crealo:</p> <ul> <li>Tentar conectar con calquer servidor por SSH. Exemplo: <code>ssh localhost</code>.</li> <li>Xerar unha chave SSH: <code>ssh-keygen</code>.</li> </ul>"},{"location":"ssh-0-chaves-tuneles/#microsoft-windows","title":"\ud83e\ude9f Microsoft Windows","text":"<p>Abrimos PowerShell e executamos:</p> <pre><code>ssh-keygen\n</code></pre> <p>V\u00eddeo de Youtube</p> <p></p>"},{"location":"ssh-0-chaves-tuneles/#gnulinux","title":"\ud83d\udc27 GNU/Linux","text":"<p>Abrimos unha consola xterm ou similar e executamos:</p> <pre><code>ssh-keygen\n</code></pre> <p>V\u00eddeo en ASCIINEMA</p> <p></p>"},{"location":"ssh-0-chaves-tuneles/#tunelizacion-ssh-empregando-ssh-para-redireccionar-portos-ssh-port-forwarding","title":"\ud83d\ude87 Tunelizaci\u00f3n SSH: Empregando SSH para redireccionar portos (SSH Port Forwarding)","text":"<p>Se precisamos acceder a un recurso que est\u00e1 detr\u00e1s dun firewall ou ben non \u00e9 accesible directamente pero ao que pode acceder un equipo que ten o servizo de SSH aberto e ao que nos podemos conectar, podemos crear un tunel SSH.</p> <p></p>"},{"location":"ssh-0-chaves-tuneles/#tipos-de-tuneles","title":"\u2675 Tipos de t\u00faneles","text":"<ul> <li>Locales: Abren no noso equipo (no que executamos o comando SSH) un porto. O destino pode ser o mesmo host ssh (localhost) ou outro destino ao que ese servidor te\u00f1a acceso.</li> <li>Remotos: Abren no porto do host SSH ao que nos conectamos. Podemos exportar un servizo local.</li> <li>Din\u00e1micos: Creamos un proxy socks que pode ser empregado por moitas aplicaci\u00f3ns (por exemplo, un navegador).</li> </ul>"},{"location":"ssh-0-chaves-tuneles/#comandos","title":"\ud83d\udd32 Comandos","text":"<p>Nunha consola, chamando SSH directamente podemos facer:</p> <pre><code>ssh teuser@10.133.X.X -L 1337:172.17.X.X:3306\n</code></pre> <p>Sintaxe: -L: Indica local. O n\u00famero: 1337 representa o porto local que se abrir\u00e1 no noso equipo. De conectamos a \u00e9l, levaranos \u00e1 IP: 172.17.X.X e porto 3306 a trav\u00e9s do servidor ao que nos estamos a conectar.</p>"},{"location":"ssh-0-chaves-tuneles/#quitarmudar-o-contrasinal-ou-frase-a-unha-chave","title":"Quitar/Mudar o contrasinal ou frase a unha chave","text":"<pre><code>ssh-keygen -p -f .ssh/id_rsa\n</code></pre>"},{"location":"ssh-0-chaves-tuneles/#xerar-a-chave-publica-a-partires-dunha-privada","title":"Xerar a chave p\u00fablica a partires dunha privada","text":"<pre><code>ssh-keygen -y -f .ssh/id_rsa &gt; .ssh/id_rsa.pub\n</code></pre>"},{"location":"windows-wsl/","title":"\ud83d\udc27 WSL","text":"<p>Windows Subsystem for Linux (WSL)</p>"},{"location":"windows-wsl/#requisitos-previos","title":"Requisitos previos","text":"<p>Consid\u00e9rase unha m\u00e1quina con Microsoft Windows 10/11.</p>"},{"location":"windows-wsl/#instalacion","title":"Instalaci\u00f3n","text":"<p>Require permisos de administrador ou root para instalar por primeira vez o compo\u00f1ente no sistema.</p> <p>Abrimos unha consola de PowerShell e escribimos o comando:</p> <pre><code>wsl --install\n</code></pre> <p>Por defecto instalaranos unha m\u00e1quina de Ubuntu.</p> <p>Tras a instalaci\u00f3n \u00e9 preciso reiniciar, av\u00edsanos coa mensaxe: La operaci\u00f3n solicitada se realiz\u00f3 correctamente. Los cambios se aplicar\u00e1n una vez que se reinicie el sistema..</p> <p>Tras reiniciar, se non nos entra cun simple comando wsl, volvemos a unha consola de PowerShell como usuarios e volvemos escribir:</p> <pre><code>wsl --install\n</code></pre> <p>Se queremos outro sabor de GNU/Linux podemos executar:</p> <pre><code>wsl --list --online\n</code></pre> <p></p> <p>E instalar a versi\u00f3n desexada, por exemplo:</p> <pre><code>wsl --install -d Debian\n</code></pre> <p>Recomendaci\u00f3n 1: Empregar systemd no inicio (para que inicie os demos/servizos):</p> <pre><code>echo -e \"[boot]\\nsystemd=true\"| sudo tee /etc/wsl.conf\n</code></pre> <p>Recomendaci\u00f3n 2: Permitir o uso de m\u00e1is memoria RAM Podes crear no teu cartafol de usuario un arquivo .wslconfig que se aplicar\u00eda en global a t\u00f3dalas m\u00e1quinas ou ben po\u00f1er o seguinte contido no arquivo /etc/wsl.conf dentro de cada m\u00e1quina.</p> <p><pre><code>[wsl]\nmemory=12G\n</code></pre> Podes atopar m\u00e1is informaci\u00f3n e opci\u00f3ns de configuraci\u00f3n do wsl en: https://learn.microsoft.com/en-us/windows/wsl/wsl-config</p>"},{"location":"windows-wsl/#entrar-no-sistema","title":"Entrar no sistema","text":"<p>Abrimos unha consola de PowerShell e executamos:</p> <pre><code>wsl\n</code></pre> <p>Para ver as distribuci\u00f3ns instaladas:</p> <pre><code>wsl -l\n</code></pre> <p>Se temos m\u00e1is dunha distribuci\u00f3n, debemos seleccionar cal queremos executar (ou executar\u00e1 a por defecto). Por exemplo:</p> <pre><code>wsl -d Debian\n</code></pre> <p>Dentro da m\u00e1quina entrar\u00e1 por defecto co usuario creado, con ese usuario pod\u00e9monos facer root con comando sudo: <code>sudo su</code>. Pedirache o contrasinal que elixiches ao crear a m\u00e1quina, non o contrasinal da conta de Microsoft Windows.</p>"},{"location":"windows-wsl/#apagar-un-wsl","title":"Apagar un WSL","text":"<pre><code>wsl --shutdown -d DISTRO\n</code></pre>"},{"location":"windows-wsl/#acceso-aos-arquivos","title":"Acceso aos arquivos","text":"<p>Abrir un explorador de arquivos e no enderezo, introduce: \\wsl$\\DISITRIBUCI\u00d3N. Exemplo con Ubuntu:</p> <pre><code>\\\\wsl$\\Ubuntu\n</code></pre> <p>Os arquivos g\u00e1rdanse nun ficheiro .vhdx dentro do cartafol: %LOCALAPPDATA%\\Packages\\ nese cartafol localizamos a nosa distribuci\u00f3n: TheDebian... ou CanonicalGroupLimited.Ubuntu... e dentro do cartafol da distro en: LocalState.</p>"},{"location":"windows-wsl/#actualizacion-de-wsl","title":"Actualizaci\u00f3n de WSL","text":"<p>Abrimos unha consola de PowerShell e escribimos o comando:</p> <pre><code>wsl --update\n</code></pre>"},{"location":"windows-wsl/#borrar-unha-distribucion-de-wsl","title":"Borrar unha distribuci\u00f3n de WSL","text":"<p>Imaxinemos que queremos borrar a distribuci\u00f3n Ubuntu:</p> <pre><code>wsl --unregister Ubuntu\n</code></pre>"},{"location":"windows-wsl/#exportar-e-importar-unha-distribucion","title":"Exportar e importar unha distribuci\u00f3n","text":"<p>Pode ser \u00fatil gardar unha copia de seguridade dunha distribuci\u00f3n e restaurala.</p> <pre><code>wsl --export Debian debian.tar\n</code></pre> <p>Podemos borrar a distribuci\u00f3n con: <code>wsl --unregister Debian</code></p> <pre><code>wsl --import Debian C:\\Users\\jose\\distros\\Debian C:\\Users\\jose\\debian.tar \n</code></pre> <p>Normalmente a ruta de instalaci\u00f3n por defecto adoita estar baixo: <code>C:\\Users\\**USUARIO**\\AppData\\Local\\Packages\\TheDebian...</code>. Neste exemplo creamos dentro do cartafol de usuario outro chamado \"distros\" para localizar o arquivo de disco virtual ext4.vhdx m\u00e1is f\u00e1cilmente.</p> <p>Ollo, se WSL non detecta o usuario tras unha importaci\u00f3n do sistema, devolveranos unha consola de root.</p>"},{"location":"windows-wsl/#erros-comuns","title":"Erros com\u00fans","text":""},{"location":"windows-wsl/#erro-createprocessparsecommon","title":"Erro CreateProcessParseCommon","text":"<pre><code>&lt;3&gt;WSL (10) ERROR: CreateProcessParseCommon:711: Failed to translate X:\\\n</code></pre> <p>Trata de executar os comandos de WSL na unidade por defecto onde est\u00e1 instalado o sistema operativo (habitualmente C:).</p>"},{"location":"windows-wsl/#erros-0x80370102-ou-0x8007019e-wslregisterdistribution","title":"Erros: 0x80370102 ou 0x8007019e (WslRegisterDistribution)","text":"<pre><code>WslRegisterDistribution failed with error: 0x80370102\nPlease enable the Virtual Machine Platform Windows feature and ensure virtualization is enabled in the BIOS.\nFor information please visit: https://aka.ms/enablevirtualization\nPress any key to continue...\n</code></pre> <p>Teremos que asegurarnos que:</p> <ol> <li>Virtualizaci\u00f3n activada na BIOS.</li> <li>Dependendo do SO:<ol> <li>Para Microsoft Windows 10: En \"Inicio\" -&gt; \"Aplicaciones y caracter\u00edsticas\" -&gt; \"Programas y caracter\u00edsticas\" -&gt; \"Activar o desactivar las funciones de Windows\" -&gt; En \"caracter\u00edsticas\".</li> <li>Para Microsoft Windows 11: \"Inicio\" -&gt; \"Activar o desactivar las caracter\u00edsticas de Windows\".</li> </ol> </li> <li>Busca a \"Plataforma de m\u00e1quina virtual\" e mira que estea seleccionada.</li> <li>Busca o \"Subsistema de Windows para Linux\" e mira que estea seleccionado.</li> <li>Preme en aceptar e reinicia o equipo.</li> </ol>"},{"location":"windows-wsl/#erro-non-inicia-os-demosservizos","title":"Erro: Non inicia os demos/servizos","text":"<p>Hai que indicarlle que empregue systemd: </p> <pre><code>echo -e \"[boot]\\nsystemd=true\"| sudo tee /etc/wsl.conf\n</code></pre> <p>Se segue sen funcionar, compre actualizar wsl:</p> <pre><code>wsl --update\n</code></pre>"}]}