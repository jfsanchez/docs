# 游 Apache Spark - Instalaci칩n

Faremos unha instalaci칩n de Apache Spark en 4 m치quinas con **ClusterShell**, un programa que permite enviar 치 vez comandos a varias m치quinas.

A presente instalaci칩n contempla 1 master e 3 nodos (ou 4 nodos de actuar o m치ster tam칠n como worker). Se tes un n칰mero diferente de m치quinas, deber치s mudar nos comandos a parte do **[1-4]** ou **[2-4]** adapt치ndoo 치s t칰as necesidades.

Consideraremos os seguintes nomes de m치quinas:

``` title="/etc/hosts"
10.X.Y.101 hadoop1 hadoop1.local master1.local
10.X.Y.102 hadoop2 hadoop2.local
10.X.Y.103 hadoop3 hadoop3.local
10.X.Y.104 hadoop4 hadoop4.local
```

Imos empregar **Rocky 8.5 v2**, sen embargo, en caso de empregar Debian, podemos empregar `apt` en lugar de `dnf`. Consideramos tam칠n o contorno do cesga con usuario por defecto: `cesgaxuser` e `$HOME` en `/home/cesgaxuser/`.

Se est치s nun contorno Cloud no que debes destruir as instancias por tema de custes e p칩dense asignar distintos enderezos IP, lembra sempre facer:

1. Borrar o known_hosts:
    ``` bash
    rm ~/.ssh/known_hosts
    ```

2. Editar o arquivo `/etc/hosts` cos nomes que correspondan 치s novas IP.


## Instalaci칩n de Clustershell

1. Activar repo:

    ``` bash
    sudo yum --enablerepo=extras install epel-release
    ```

2. Instalaci칩n de paquete:

    ``` bash
    sudo yum install clustershell
    ```

## Descargar a m치quina de Java (Amazon Corretto)

Configuramos o repo de Amazon Corretto e instalamos o paquete de Java en t칩dolos nodos:

1. Importamos a chave do repositorio:

    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] \
      sudo rpm --import https://yum.corretto.aws/corretto.key
    ```

2. Baixamos o repositorio e o configuramos nos nodos:

    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] \
      sudo curl -L -o /etc/yum.repos.d/corretto.repo \
      https://yum.corretto.aws/corretto.repo
    ```

3. Instalamos o paquete de Java deste novo repostorio:
   
    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] \
      sudo dnf install -y java-11-amazon-corretto-devel
    ```

4. Configuramos as variables do contorno: `nano .bashrc` as li침as:

    ``` bash title=".bashrc"
    export JAVA_HOME='/usr/lib/jvm/java-11-amazon-corretto/'
    export EDITOR=nano
    export PATH=$PATH:$JAVA_HOME/bin
    ```

    - Se non temos o editor nano, podemos empregar vi. Lembra para gardar e sair en **nano**: Ctrl+O [ENTER], Ctrl + X. En **vi**: [ESC] :wq! [ENTER]

    - Logo de gardar, lembra recargar as variables de contorno!

    ``` bash
    source ~/.bashrc
    ```

5. Copia ao resto de nodos esta configuraci칩n:
    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] --copy $HOME/.bashrc \
      --dest $HOME/.bashrc
    ```

## Descarga de Apache Spark

Se non che funciona a descarga, pode ser que te침as que averiguar a nova ruta por existir unha nova versi칩n. Podes ir ao nivel superior da p치xina e buscar a nova versi칩n: <https://dlcdn.apache.org/spark/>.

Segundo as t칰as necesidades podes ter que escoller entre a versi칩n con ou sen Apache Hadoop.

Outra opci칩n se contas con pouco ancho de banda 칠 baixar unha vez o arquivo dende o master e facer un --copy  a --dest con Clustershell.

1. Baixamos Apache Spark (actualizado a 20 de abril de 2024):

    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] \
      sudo curl -L -O https://dlcdn.apache.org/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz \
      -o /home/cesgaxuser/spark-bin-hadoop3.tar.gz
    ```

    - G치rdase no arquivo `spark-bin-hadoop3.tar.gz` para que futuras versi칩ns destes apuntes non te침an que ser mudados t칩dolos comandos por mor da versi칩n.

2. Descomprimimos simult치neamente en t칩dolos nodos:

    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] \
      sudo tar xzvf spark-bin-hadoop3.tgz
    ```

3. Configuramos as variables de contorno por comodidade `nano .bashrc`:

    ``` bash title=".bashrc"
    export SPARK_HOME=$HOME/spark-bin-hadoop3
    export PATH=$PATH:$SPARK_HOME/sbin/:$SPARK_HOME/bin/
    ```

    - Logo de gardar, lembra recargar as variables do contorno!

    ``` bash
    source ~/.bashrc
    ```

4. Copia ao resto de nodos esta configuraci칩n:

    ``` bash
    clush -l cesgaxuser -bw hadoop[2-4] --copy $HOME/.bashrc \
      --dest $HOME/.bashrc
    ```

5. Copiamos o template de configuraci칩n:

    ``` bash
    sudo cp $SPARK_HOME/conf/spark-defaults.conf.template \
      $SPARK_HOME/conf/spark-defaults.conf
    ```

6. Editamos o novo arquivo de configuraci칩n:

    ``` bash
    sudo nano $SPARK_HOME/conf/spark-defaults.conf
    ```

    - Dentro do arquivo, mudamos a configuraci칩n de Apache Spark para que empregue YARN (Yet Another Resource Negociator):

    ``` bash title="$SPARK_HOME/conf/spark-defaults.conf"
    spark.master yarn
    ```

7. No nodo **master** executamos o script `start-master.sh` (estamos a executar todo como root):

    ``` bash
    sudo start-master.sh
    ```

8. Nos nodos **slaves** executamos o `start-worker.sh`:

    ``` bash
    clush -l cesgaxuser -bw hadoop[2-4] \
      sudo $SPARK_HOME/sbin/start-worker.sh spark://hadoop1:7077
    ```

## Instalaci칩n de PySpark

1. Instalamos Python 3.9:

    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] \
      sudo dnf install -y python39
    ```
    - Lembra que a nivel sistema podes seleccionar o python por defecto que queres cos comandos:

    ``` bash
    sudo /usr/sbin/alternatives --config python
    sudo /usr/sbin/alternatives --config python3
    ```

    - 丘멆잺 Considera que quiz치s a mellor opci칩n sexa instalar miniconda e dende ah칤 ter un contorno estable que poidas importar a t칩dolos nodos cunha versi칩n concreta de funcional de: Python, ipython, pyspark, jupyterlab, ipykernel, nbclassic, nbconvert, py4j, pandas, numpy, pyarrow, fastparquet... 

2. Lanzar pyspark

    ``` bash
    pyspark --master spark://hadoop1:7077
    ```

3. Configurar para que o worker arranque no inicio do servidor:

    ``` bash
    sudo crontab -e
    ```

    - De iniciarseche **vi**, preme a tecla INS para habilitar inserci칩n de texto neste editor. Lembra que para gardar debes premer a tecla ESC e despois `:wq!` e logo premer ENTER.

    ``` bash
    @reboot /home/cesgaxuser/spark-bin-hadoop3/sbin/start-worker.sh spark://hadoop1:7077
    ```

4. E no master o mesmo, pero con comando master:

    ``` bash
    sudo crontab -e
    ```

    - E meter no arquivo:

    ```
    @reboot /home/cesgaxuser/spark-bin-hadoop3/sbin/start-master.sh
    @reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-yarn.sh
    ```

5. Lembra darlle un reboot a t칩dalas m치quinas para ver que todo se est치 a executar ben ao inicio:

    ``` bash
    clush -l cesgaxuser -bw hadoop[1-4] reboot
    ```

![PySpark](images/spark/pyspark.png "PySpark")

## Configurando Spark para que funcione con Hadoop:

O arquivo `.bashrc` tam칠n debe ter a config de Apache Hadoop do exercicio anterior:
En `.bashrc` aseg칰rate que tes:

``` bash title=".bashrc"
export HADOOP_HOME='/home/cesgaxuser/hadoop-3.2.4'
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin
export LD_LIBRARY_PATH=${HADOOP_HOME}/lib/native:$LD_LIBRARY_PATH
```

E lembra ter todas as variables definidas nos arquivos **-env.sh** correspondentes.

## Lanzando traballos con spark-submit

Executamos dende o master con spark-submit un traballo, que deber칤a enviarse ao hadoop.

``` bash
spark-submit --deploy-mode client --class org.apache.spark.examples.SparkPi $SPARK_HOME/examples/jars/spark-examples_2.12-3.3.2.jar 2
```

Miramos nos logs de hadoop que se executara.

## Lendo arquivos do HDFS dende jupyterlab

Para ler arquivos do HDFS dende yarn / jupyterlab / pyspark hai que:

1. Crear o directorio de usuario no HDFS:

    ``` bash
    hdfs dfs -mkdir /user/
    hdfs dfs -mkdir /user/cesgaxuser
    ```

2. Po침er a ruta completa no c칩digo:

    ``` py title="ler_csv_dende_spark.py"
    df = spark.read.csv("hdfs://hadoop1:9000/user/cesgaxuser/arquivo.csv")
    ```

    - Ollo! se probas dende pyspark, mira que acceda ao cluster e non cree unha instancia nova propia.

## Lanzando exemplos

Se tes Apache Hadoop instalado do paso anterior, lembra que tam칠n podes probar os exemplos con:

``` bash
yarn jar hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar wordcount "books/*" output
```

## Comandos e outros

Haber치 que documentar:

- hdfs dfs -put ARQUIVO

- hdfs dfs -ls

- yarn top

- yarn node -list

- yarn application (-list/-kill)

- jps -> De java (non Spark ou Hadoop)

