# üêò Apache Hadoop &mdash; üî≤ Comandos

![Logo Apache Hadoop](images/hadoop/Hadoop_logo_new.svg#derecha "Logo Apache Hadoop")

[Apache Hadoop](https://hadoop.apache.org), √© un [framework](https://es.wikipedia.org/wiki/Framework) que permite o procesamento distribuido de grande volume de datos sobre [cl√∫steres de computadoras](https://es.wikipedia.org/wiki/Cl%C3%BAster_de_computadoras) empregando modelos sinxelos de programaci√≥n.

O **HDFS** ou **H**adoop **D**istributed **F**ile **S**ystem √© un sistema de arquivos distribu√≠do empregado por Apache Hadoop que espalla os datos polos distintos discos dos servidores que forman o cl√∫ster de Hadoop.

- Os arquivos grandes div√≠dense en bloques (**blocks**) por defecto de 128 MiB.

- De cada bloque hai varias copias, o n√∫mero exacto establ√©ceo o factor de replicaci√≥n (**replication factor**) por defecto 3.

## Onde est√°n os meus datos?

A primeira pregunta que debemos facernos √©: Onde est√°n os meus datos?

- No **$HOME** do teu usuario -> */home/subdirs-opcionais/usuario*.
- No **HOME** do servidor de HADOOP -> */user/usuario*.

A variable $HOME normalmente fai referencia ao teu cartafol persoal. Este adoita estar en **/home/usuario** ou en **/home/algo/mais/usuario**. Estes son os arquivos aos que accedes normalmente.

O HOME de Hadoop normalmente estar√° en: **/user/usuario** e para acceder a √©l debes empregar o comando hdfs ou ben API ou programas que se relacionen con Hadoop. A URL de acceso ao arquivo ten o formato: *hdfs://nameservice1/user/usuario/arquivo*.

## Interactuando co sistema de arquivos

O programa **hdfs** danos unha interfaz e operaci√≥ns √∫tiles para acceder ao HDFS de Hadoop. Os comandos seguen unha sintaxe de tipo:

``` bash
hdfs dfs -COMANDO # (1)!
```

1.  dfs: Indica que a operaci√≥n √© de arquivos sobre o sistema de arquivos.

Os comandos habituais son:

### Ver arquivos e directorios

Ver arquivos no noso HOME de HDFS. Imos ver adem√°is as distintas rutas: relativas, absolutas e completas.

``` bash
hdfs dfs -ls
```

Ver arquivos que hai en "directorio" que √© un directorio que est√° no noso HOME de HDFS:

``` bash
hdfs dfs -ls directorio
```

O mesmo que o anterior pero empregando unha ruta absoluta:

``` bash
hdfs dfs -ls /user/usuario/directorio
```

O mesmo que o anterior pero empregando a ruta absoluta e completa do HDFS:

``` bash
hdfs dfs -ls hdfs://nameservice1/user/usuario/directorio
```

### Transferindo datos entre o HDFS e o almacenamento local

üîº **Subir**/Enviar o ARQUIVO_LOCAL que est√° no noso $HOME ("o noso disco duro") a un directorio de HDFS chamado "DIRECTORIO_HDFS":

``` bash
hdfs dfs -put ARQUIVO_LOCAL DIRECTORIO_HDFS
```

üîΩ **Baixar**/Descargar/Recibir do HDFS ("cl√∫ster de Hadoop") o arquivo ao noso almacenamento local ("disco duro"):

``` bash
hdfs dfs -get arquivo-do-hdfs.txt
```

**Amosar** un **arquivo** do HDFS por consola **en modo texto**. Adem√°is admite o formato **ZIP** e **TextRecordInputStream**:

``` bash
hdfs dfs -text arquivo.zip
hdfs dfs -text arquivo.txt
```

**Amosar un arquivo do HDFS** por consola, danos igual o formato no que estea:

``` bash
hdfs dfs -cat arquivo-calquera.xyz
```

**Ver o inicio do arquivo** (cabeceira) empregando pipes:

``` bash
hdfs dfs -cat arquivo-moi-grande.csv|head
```

Amosar a cola (o final) do arquivo. √ötil para comprobar se est√° ben recibido e o formato.

``` bash
hdfs dfs -tail arquivo-longo.csv
```

**Copiar** un arquivo dentro do HDFS (de HDFS a HDFS)

``` bash
hdfs dfs -cp ARQUIVO_ORIXE ARQUIVO_DESTINO
```

**Mover** un arquivo dentro do HDFS (de HDFS a HDFS)

``` bash
hdfs dfs -mv ARQUIVO_ORIXE ARQUIVO_DESTINO
```
**Borrar** un arquivo do HDFS

``` bash
hdfs dfs -rm arquivo.txt
```

Resultado:

```
25/02/08 16:39:19 INFO fs.TrashPolicyDefault: Moved: 'hdfs://nameservice1/user/usuario/arquivo.txt' to trash at: hdfs://nameservice1/user/usuario/.Trash/Current/user/usuario/arquivo.txt
```

**Borrar** un arquivo do HDFS **evitando a papeleira** (skipTrash):

``` bash
hdfs dfs -rm -skipTrash arquivo.txt
```

Resultado:
```
Deleted arquivo.txt
```

### Mudando de usuario, grupo e permisos

Seguindo a [m√°scara de permisos UGO](https://es.wikipedia.org/wiki/Umask) podemos mudar os permisos dun arquivo ou dun directorio de forma recursiva (-R):

``` bash
hdfs dfs -chmod 765 ficheiro
```

``` bash
hdfs dfs -chmod -R 755 meudir
```

Tam√©n podemos mudar o propietario e o grupo do ficheiro (tam√©n admite -R para directorios):

``` bash
hdfs dfs -chown hadoop:hadoop ficheiro123.txt
```

Ou mudar solo o grupo:

``` bash
hdfs dfs -chgrp hadoop ficheiro321.txt
```

### √â cuesti√≥n de espazo

Medir o espazo consumido non sempre √© directo. Se preguntamos canto oucpa un arquivo:

``` bash
dfs dfs -du -h -s 100MB.zip
```

Veremos dous tama√±os: Tama√±o do arquivo e o espazo en disco consumido.

```
100 M  300 M  100MB.zip
```

O tama√±o en disco consumido p√≥dese calcular como o resultado de multiplicar o tama√±o do arquivo polo factor de replicaci√≥n. Pode haber diferencias debidas ao tama√±o de bloque, sobre todo con tama√±os de bloque grandes.

Consultar o espazo libre dispo√±ible:

``` bash
hdfs dfs -df -h
```


### Outros comandos √∫tiles (probar):

Engadir (concatenar) o contido de `ventas-diarias-hoxe-LOCAL.txt` que est√° no **almacenamento local** (disco duro local ou $HOME) ao arquivo do **HDFS** `ventas-HDFS.txt`

``` bash
hdfs dfs -appendToFile ventas-diarias-hoxe-LOCAL.txt ventas-HDFS.txt
```

Descargar a local ao arquivo `ventas-local.txt` o resultado da concatenaci√≥n dos arquivos do HDFS: `ventas-HDFS-part1.txt` e `ventas-HDFS-part2.txt`.

``` bash
hdfs dfs -getmerge -nl ventas-HDFS-part1.txt ventas-HDFS-part2.txt ventas-local.txt
```

Xerar un checksum dos datos para comprobar se est√°n ben (empr√©gase MD5, non est√° pensado para modificaci√≥ns maliciosas dos datos, sen√≥n para cambios accidentais)

``` bash
hdfs dfs -checksum ventas-HDFS.txt
```

Mudar o factor de replicaci√≥n dun arquivo ou dun directorio:

``` bash
hadoop fs -setrep -w 3 100MB.zip
hadoop fs -setrep -w 3 -R /user/usuario/directorio
```

C√≥mo se comproba que mudou. D√∫as maneiras:

Con ls, o n√∫mero antes de **usuario** √© o factor de replicaci√≥n:

```
-rw-r--r--   **4** usuario grupo  104857600 2025-01-29 22:00 100MB.zip
```

Con du mirando que sube o espacio ocupado en disco:

``` bash
hdfs dfs -du -h -s 100MB.zip
```

Vemos que:

```
100 M  400 M  100MB.zip
```

## Arquivos de configuraci√≥n

### hdfs-site.xml. Tama√±o de bloque

Cada arquivo div√≠dese en bloques (m√≠nimo 1 bloque por arquivo) de por defecto 128 MiB.

``` xml
<property>
<name>dfs.block.size</name>
<value>134217728</value>
<property>
```


### hdfs-site.xml. Factor de replicaci√≥n

O n√∫mero de copias de cada bloque, por defecto 3.

``` xml
<property>
<name>dfs.replication</name>
<value>3</value>
</property>
```


## M√°is informaci√≥n

- <https://bigdata.cesga.es/tutorials/hdfs.html>

Se empregas os recursos do [CESGA](https://www.cesga.es/), lembra que dende a casa debes conectarte √° VPN antes de conectarte por SSH ao servidor hadoop.cesga.es.