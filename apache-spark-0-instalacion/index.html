
<!doctype html>
<html lang="gl" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Jose Sánchez">
      
      
        <link rel="canonical" href="https://jfsanchez.es/apache-spark-0-instalacion/">
      
      
        <link rel="prev" href="../apache-hadoop-2-cuentapalabras/">
      
      
        <link rel="next" href="../apache-spark-1-comandos/">
      
      
      <link rel="icon" href="../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>🧾 Instalación - JFSanchez</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../_res/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#apache-spark-instalacion" class="md-skip">
          Ir ao contido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabeceira">
    <a href=".." title="JFSanchez" class="md-header__button md-logo" aria-label="JFSanchez" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            JFSanchez
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              🧾 Instalación
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Modo oscuro (da calambre)"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Modo oscuro (da calambre)" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Modo normal"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Modo normal" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Procura" placeholder="Procura" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Procurar">
        
        <button type="reset" class="md-search__icon md-icon" title="Limpar" aria-label="Limpar" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando procura
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/jfsanchez/" title="Ir ao repositorio" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="JFSanchez" class="md-nav__button md-logo" aria-label="JFSanchez" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    JFSanchez
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/jfsanchez/" title="Ir ao repositorio" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    📚 Inicio — Presentacións
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../conda-0-config-basica/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    👷 Contorno/Configuracións
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../apache-hadoop-0-instalacion/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    🐘 Apache Hadoop
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    ⚝ Apache Spark
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            ⚝ Apache Spark
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    🧾 Instalación
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    🧾 Instalación
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Táboa de contidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Táboa de contidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#instalacion-de-clustershell" class="md-nav__link">
    <span class="md-ellipsis">
      Instalación de Clustershell
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#descargar-a-maquina-de-java-amazon-corretto" class="md-nav__link">
    <span class="md-ellipsis">
      Descargar a máquina de Java (Amazon Corretto)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#descarga-de-apache-spark" class="md-nav__link">
    <span class="md-ellipsis">
      Descarga de Apache Spark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instalacion-de-pyspark" class="md-nav__link">
    <span class="md-ellipsis">
      Instalación de PySpark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configurando-spark-para-que-funcione-con-hadoop" class="md-nav__link">
    <span class="md-ellipsis">
      Configurando Spark para que funcione con Hadoop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lanzando-traballos-con-spark-submit" class="md-nav__link">
    <span class="md-ellipsis">
      Lanzando traballos con spark-submit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lendo-arquivos-do-hdfs-dende-jupyterlab" class="md-nav__link">
    <span class="md-ellipsis">
      Lendo arquivos do HDFS dende jupyterlab
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lanzando-exemplos" class="md-nav__link">
    <span class="md-ellipsis">
      Lanzando exemplos
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comandos-e-outros" class="md-nav__link">
    <span class="md-ellipsis">
      Comandos e outros
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apache-spark-1-comandos/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔲 Comandos
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../apache-kafka-0-instalacion-docker/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    ➿ Apache Kafka
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../apache-nifi-0-instalacion/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    💧 Apache NIFI
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../apache-sqoop-0-resumo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🇸 Apache Sqoop
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../apache-airflow-0-instalacion/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🍀 Apache Airflow
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../apache-superset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ♾️ Apache Superset
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../nube-0-intro/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    ☁️ Nube/Cloud/Openstack
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../powerbi-0-python/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    📶 Microsoft PowerBi
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/jfsanchez/docencia/tree/main/libreta" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🗒️ Plantillas docencia
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Táboa de contidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Táboa de contidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#instalacion-de-clustershell" class="md-nav__link">
    <span class="md-ellipsis">
      Instalación de Clustershell
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#descargar-a-maquina-de-java-amazon-corretto" class="md-nav__link">
    <span class="md-ellipsis">
      Descargar a máquina de Java (Amazon Corretto)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#descarga-de-apache-spark" class="md-nav__link">
    <span class="md-ellipsis">
      Descarga de Apache Spark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instalacion-de-pyspark" class="md-nav__link">
    <span class="md-ellipsis">
      Instalación de PySpark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configurando-spark-para-que-funcione-con-hadoop" class="md-nav__link">
    <span class="md-ellipsis">
      Configurando Spark para que funcione con Hadoop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lanzando-traballos-con-spark-submit" class="md-nav__link">
    <span class="md-ellipsis">
      Lanzando traballos con spark-submit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lendo-arquivos-do-hdfs-dende-jupyterlab" class="md-nav__link">
    <span class="md-ellipsis">
      Lendo arquivos do HDFS dende jupyterlab
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lanzando-exemplos" class="md-nav__link">
    <span class="md-ellipsis">
      Lanzando exemplos
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comandos-e-outros" class="md-nav__link">
    <span class="md-ellipsis">
      Comandos e outros
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="apache-spark-instalacion">⚝ Apache Spark &mdash; 🧾 Instalación</h1>
<p><img alt="Logo Apache Spark" src="../images/spark/Apache_Spark_logo.svg#derecha" title="Logo Apache Spark" /></p>
<p>Faremos unha instalación de Apache Spark en 4 máquinas con <strong>ClusterShell</strong>, un programa que permite enviar á vez comandos a varias máquinas.</p>
<p>A presente instalación contempla 1 master e 3 nodos (ou 4 nodos de actuar o máster tamén como worker). Se tes un número diferente de máquinas, deberás mudar nos comandos a parte do <strong>[1-4]</strong> ou <strong>[2-4]</strong> adaptándoo ás túas necesidades.</p>
<p>Consideraremos os seguintes nomes de máquinas:</p>
<div class="language-text highlight"><span class="filename">/etc/hosts</span><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>10.X.Y.101 hadoop1 hadoop1.local master1.local
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>10.X.Y.102 hadoop2 hadoop2.local
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>10.X.Y.103 hadoop3 hadoop3.local
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>10.X.Y.104 hadoop4 hadoop4.local
</span></code></pre></div>
<p>Imos empregar <strong>Rocky 8.5 v2</strong>, sen embargo, en caso de empregar Debian, podemos empregar <code>apt</code> en lugar de <code>dnf</code>. Consideramos tamén o contorno do cesga con usuario por defecto: <code>cesgaxuser</code> e <code>$HOME</code> en <code>/home/cesgaxuser/</code>.</p>
<p>Se estás nun contorno Cloud no que debes destruir as instancias por tema de custes e pódense asignar distintos enderezos IP, lembra sempre facer:</p>
<ol>
<li>
<p>Editar o arquivo <code>/etc/hosts</code> cos nomes que correspondan ás novas IP.</p>
</li>
<li>
<p>Borrar o known_hosts:
    <div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>rm<span class="w"> </span>~/.ssh/known_hosts
</span></code></pre></div></p>
</li>
<li>
<p>Rexenerar o <code>/etc/hosts</code>:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="k">for</span><span class="w"> </span>servidor<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span>cat<span class="w"> </span>/etc/hosts<span class="p">|</span>grep<span class="w"> </span>hadoop<span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">  </span>ssh-keyscan<span class="w"> </span>-H<span class="w"> </span><span class="nv">$servidor</span><span class="p">;</span><span class="w"> </span><span class="k">done</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>/home/cesgaxuser/.ssh/known_hosts
</span></code></pre></div>
</li>
<li>
<p>Copialo ao resto de nodos:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="w">  </span>--copy<span class="w"> </span><span class="nv">$HOME</span>/.ssh/known_hosts<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="w">  </span>--dest<span class="w"> </span><span class="nv">$HOME</span>/.ssh/known_hosts
</span></code></pre></div>
</li>
<li>
<p>Copia o <code>/etc/hosts</code> ao resto de nodos:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">2</span>-4<span class="o">]</span><span class="w"> </span>--copy<span class="w"> </span>/etc/hosts<span class="w"> </span>--dest<span class="w"> </span>/tmp
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">2</span>-4<span class="o">]</span><span class="w"> </span>sudo<span class="w"> </span>cp<span class="w"> </span>/tmp/hosts<span class="w"> </span>/etc/hosts
</span></code></pre></div>
</li>
</ol>
<h2 id="instalacion-de-clustershell">Instalación de Clustershell</h2>
<ol>
<li>
<p>Activar repo:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>sudo<span class="w"> </span>yum<span class="w"> </span>--enablerepo<span class="o">=</span>extras<span class="w"> </span>install<span class="w"> </span>epel-release
</span></code></pre></div>
</li>
<li>
<p>Instalación de paquete:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>sudo<span class="w"> </span>yum<span class="w"> </span>install<span class="w"> </span>clustershell
</span></code></pre></div>
</li>
</ol>
<h2 id="descargar-a-maquina-de-java-amazon-corretto">Descargar a máquina de Java (Amazon Corretto)</h2>
<p>Configuramos o repo de Amazon Corretto e instalamos o paquete de Java en tódolos nodos:</p>
<ol>
<li>
<p>Importamos a chave do repositorio:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="w">  </span>sudo<span class="w"> </span>rpm<span class="w"> </span>--import<span class="w"> </span>https://yum.corretto.aws/corretto.key
</span></code></pre></div>
</li>
<li>
<p>Baixamos o repositorio e o configuramos nos nodos:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="w">  </span>sudo<span class="w"> </span>curl<span class="w"> </span>-L<span class="w"> </span>-o<span class="w"> </span>/etc/yum.repos.d/corretto.repo<span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="w">  </span>https://yum.corretto.aws/corretto.repo
</span></code></pre></div>
</li>
<li>
<p>Instalamos o paquete de Java deste novo repostorio:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="w">  </span>sudo<span class="w"> </span>dnf<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>java-11-amazon-corretto-devel
</span></code></pre></div>
</li>
<li>
<p>Configuramos as variables do contorno: <code>nano .bashrc</code> as liñas:</p>
<div class="language-bash highlight"><span class="filename">.bashrc</span><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">JAVA_HOME</span><span class="o">=</span><span class="s1">&#39;/usr/lib/jvm/java-11-amazon-corretto/&#39;</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="nb">export</span><span class="w"> </span><span class="nv">EDITOR</span><span class="o">=</span>nano
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$JAVA_HOME</span>/bin
</span></code></pre></div>
<ul>
<li>
<p>Se non temos o editor nano, podemos empregar vi. Lembra para gardar e sair en <strong>nano</strong>: Ctrl+O [ENTER], Ctrl + X. En <strong>vi</strong>: [ESC] :wq! [ENTER]</p>
</li>
<li>
<p>Logo de gardar, lembra recargar as variables de contorno!</p>
</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="nb">source</span><span class="w"> </span>~/.bashrc
</span></code></pre></div>
</li>
<li>
<p>Copia ao resto de nodos esta configuración:
    <div class="language-bash highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span>--copy<span class="w"> </span><span class="nv">$HOME</span>/.bashrc<span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="w">  </span>--dest<span class="w"> </span><span class="nv">$HOME</span>/.bashrc
</span></code></pre></div></p>
</li>
</ol>
<h2 id="descarga-de-apache-spark">Descarga de Apache Spark</h2>
<p>Se non che funciona a descarga, pode ser que teñas que averiguar a nova ruta por existir unha nova versión. Podes ir ao nivel superior da páxina e buscar a nova versión: <a href="https://dlcdn.apache.org/spark/">https://dlcdn.apache.org/spark/</a>.</p>
<p>Segundo as túas necesidades podes ter que escoller entre a versión con ou sen Apache Hadoop.</p>
<p>Outra opción se contas con pouco ancho de banda é baixar unha vez o arquivo dende o master e facer un --copy  a --dest con Clustershell.</p>
<ol>
<li>
<p>Baixamos Apache Spark (actualizado a 20 de abril de 2024):</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="w">  </span>sudo<span class="w"> </span>curl<span class="w"> </span>-L<span class="w"> </span>-O<span class="w"> </span>https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz<span class="w"> </span><span class="se">\</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="w">  </span>-o<span class="w"> </span>/home/cesgaxuser/spark-bin-hadoop3.tgz
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="w">  </span>sudo<span class="w"> </span>mv<span class="w"> </span>spark-3.5.5-bin-hadoop3.tgz<span class="w"> </span>spark-bin-hadoop3.tgz
</span></code></pre></div>
<ul>
<li>Gárdase no arquivo <code>spark-bin-hadoop3.tar.gz</code> para que futuras versións destes apuntes non teñan que ser mudados tódolos comandos por mor da versión.</li>
</ul>
</li>
<li>
<p>Descomprimimos simultáneamente en tódolos nodos:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="w">  </span>sudo<span class="w"> </span>tar<span class="w"> </span>xzvf<span class="w"> </span>spark-bin-hadoop3.tgz
</span></code></pre></div>
</li>
<li>
<p>Configuramos as variables de contorno por comodidade <code>nano .bashrc</code>:</p>
<div class="language-bash highlight"><span class="filename">.bashrc</span><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">SPARK_HOME</span><span class="o">=</span><span class="nv">$HOME</span>/spark-bin-hadoop3
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$SPARK_HOME</span>/sbin/:<span class="nv">$SPARK_HOME</span>/bin/
</span></code></pre></div>
<ul>
<li>Logo de gardar, lembra recargar as variables do contorno!</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="nb">source</span><span class="w"> </span>~/.bashrc
</span></code></pre></div>
</li>
<li>
<p>Copia ao resto de nodos esta configuración:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">2</span>-4<span class="o">]</span><span class="w"> </span>--copy<span class="w"> </span><span class="nv">$HOME</span>/.bashrc<span class="w"> </span><span class="se">\</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="w">  </span>--dest<span class="w"> </span><span class="nv">$HOME</span>/.bashrc
</span></code></pre></div>
</li>
<li>
<p>Copiamos o template de configuración:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>sudo<span class="w"> </span>cp<span class="w"> </span><span class="nv">$SPARK_HOME</span>/conf/spark-defaults.conf.template<span class="w"> </span><span class="se">\</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="w">  </span><span class="nv">$SPARK_HOME</span>/conf/spark-defaults.conf
</span></code></pre></div>
</li>
<li>
<p>Editamos o novo arquivo de configuración:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>sudo<span class="w"> </span>nano<span class="w"> </span><span class="nv">$SPARK_HOME</span>/conf/spark-defaults.conf
</span></code></pre></div>
<ul>
<li>Dentro do arquivo, mudamos a configuración de Apache Spark para que empregue YARN (Yet Another Resource Negociator):</li>
</ul>
<div class="language-bash highlight"><span class="filename">$SPARK_HOME/conf/spark-defaults.conf</span><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>spark.master<span class="w"> </span>yarn
</span></code></pre></div>
</li>
<li>
<p>No nodo <strong>master</strong> executamos o script <code>start-master.sh</code> (estamos a executar todo como root):</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>sudo<span class="w"> </span>start-master.sh
</span></code></pre></div>
</li>
<li>
<p>Nos nodos <strong>slaves</strong> executamos o <code>start-worker.sh</code>:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">2</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="w">  </span>sudo<span class="w"> </span><span class="nv">$SPARK_HOME</span>/sbin/start-worker.sh<span class="w"> </span>spark://hadoop1:7077
</span></code></pre></div>
</li>
</ol>
<h2 id="instalacion-de-pyspark">Instalación de PySpark</h2>
<ol>
<li>
<p>Instalamos Python 3.9:</p>
<p><div class="language-bash highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="w">  </span>sudo<span class="w"> </span>dnf<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>python39
</span></code></pre></div>
- Lembra que a nivel sistema podes seleccionar o python por defecto que queres cos comandos:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>sudo<span class="w"> </span>/usr/sbin/alternatives<span class="w"> </span>--config<span class="w"> </span>python
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>sudo<span class="w"> </span>/usr/sbin/alternatives<span class="w"> </span>--config<span class="w"> </span>python3
</span></code></pre></div>
<ul>
<li>⚠️ Considera que quizás a mellor opción sexa instalar miniconda e dende ahí ter un contorno estable que poidas importar a tódolos nodos cunha versión concreta de funcional de: Python, ipython, pyspark, jupyterlab, ipykernel, nbclassic, nbconvert, py4j, pandas, numpy, pyarrow, fastparquet... </li>
</ul>
</li>
<li>
<p>Lanzar pyspark:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>pyspark<span class="w"> </span>--master<span class="w"> </span>spark://hadoop1:7077
</span></code></pre></div>
</li>
<li>
<p>Configurar para que o worker arranque no inicio do servidor:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>sudo<span class="w"> </span>crontab<span class="w"> </span>-e
</span></code></pre></div>
<ul>
<li>De iniciarseche <strong>vi</strong>, preme a tecla INS para habilitar inserción de texto neste editor. Lembra que para gardar debes premer a tecla ESC e despois <code>:wq!</code> e logo premer ENTER.</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>@reboot<span class="w"> </span>/home/cesgaxuser/spark-bin-hadoop3/sbin/start-worker.sh<span class="w"> </span>spark://hadoop1:7077
</span></code></pre></div>
</li>
<li>
<p>E no master o mesmo, pero con comando master:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>sudo<span class="w"> </span>crontab<span class="w"> </span>-e
</span></code></pre></div>
<ul>
<li>E meter no arquivo:</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>@reboot /home/cesgaxuser/spark-bin-hadoop3/sbin/start-master.sh
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>@reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-yarn.sh
</span></code></pre></div>
</li>
<li>
<p>Lembra darlle un reboot a tódalas máquinas para ver que todo se está a executar ben ao inicio:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>clush<span class="w"> </span>-l<span class="w"> </span>cesgaxuser<span class="w"> </span>-bw<span class="w"> </span>hadoop<span class="o">[</span><span class="m">1</span>-4<span class="o">]</span><span class="w"> </span>reboot
</span></code></pre></div>
</li>
</ol>
<p><img alt="PySpark" src="../images/spark/pyspark.png" title="PySpark" /></p>
<h2 id="configurando-spark-para-que-funcione-con-hadoop">Configurando Spark para que funcione con Hadoop</h2>
<p>O arquivo <code>.bashrc</code> tamén debe ter a config de Apache Hadoop do exercicio anterior:
En <code>.bashrc</code> asegúrate que tes:</p>
<div class="language-bash highlight"><span class="filename">.bashrc</span><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">HADOOP_HOME</span><span class="o">=</span><span class="s1">&#39;/home/cesgaxuser/hadoop-3.2.4&#39;</span>
</span><span id="__span-31-2"><a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a><span class="nb">export</span><span class="w"> </span><span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span><span class="si">${</span><span class="nv">HADOOP_HOME</span><span class="si">}</span>/etc/hadoop
</span><span id="__span-31-3"><a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">PATH</span><span class="si">}</span>:<span class="si">${</span><span class="nv">HADOOP_HOME</span><span class="si">}</span>/bin:<span class="si">${</span><span class="nv">HADOOP_HOME</span><span class="si">}</span>/sbin
</span><span id="__span-31-4"><a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">HADOOP_HOME</span><span class="si">}</span>/lib/native:<span class="nv">$LD_LIBRARY_PATH</span>
</span></code></pre></div>
<p>E lembra ter todas as variables definidas nos arquivos <strong>-env.sh</strong> correspondentes.</p>
<h2 id="lanzando-traballos-con-spark-submit">Lanzando traballos con spark-submit</h2>
<p>Executamos dende o master con spark-submit un traballo, que debería enviarse ao hadoop.</p>
<p><strong>Modo cluster seleccionando manualmente master de hadoop:</strong></p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>spark-submit<span class="w"> </span>--deploy-mode<span class="w"> </span>cluster<span class="w"> </span><span class="se">\</span>
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a><span class="w">  </span>--master<span class="w"> </span>spark://hadoop1:7077
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a><span class="w">  </span>--class<span class="w"> </span>org.apache.spark.examples.SparkPi<span class="w"> </span><span class="se">\</span>
</span><span id="__span-32-4"><a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a><span class="w">  </span><span class="nv">$SPARK_HOME</span>/examples/jars/spark-examples_2.14-3.4.2.jar<span class="w"> </span><span class="m">2</span>
</span></code></pre></div>
<p>Modo cliente:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>spark-submit<span class="w"> </span>--deploy-mode<span class="w"> </span>client<span class="w"> </span><span class="se">\</span>
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a><span class="w">  </span>--class<span class="w"> </span>org.apache.spark.examples.SparkPi<span class="w"> </span><span class="se">\</span>
</span><span id="__span-33-3"><a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a><span class="w">  </span><span class="nv">$SPARK_HOME</span>/examples/jars/spark-examples_2.14-3.4.2.jar<span class="w"> </span><span class="m">2</span>
</span></code></pre></div>
<p>Miramos nos logs de hadoop que se executara.</p>
<h2 id="lendo-arquivos-do-hdfs-dende-jupyterlab">Lendo arquivos do HDFS dende jupyterlab</h2>
<p>Para ler arquivos do HDFS dende yarn / jupyterlab / pyspark hai que:</p>
<ol>
<li>
<p>Crear o directorio de usuario no HDFS:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>hdfs<span class="w"> </span>dfs<span class="w"> </span>-mkdir<span class="w"> </span>/user/
</span><span id="__span-34-2"><a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a>hdfs<span class="w"> </span>dfs<span class="w"> </span>-mkdir<span class="w"> </span>/user/cesgaxuser
</span></code></pre></div>
</li>
<li>
<p>Poñer a ruta completa no código:</p>
<div class="language-py highlight"><span class="filename">ler_csv_dende_spark.py</span><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;hdfs://hadoop1:9000/user/cesgaxuser/arquivo.csv&quot;</span><span class="p">)</span>
</span></code></pre></div>
<ul>
<li>Ollo! se probas dende pyspark, mira que acceda ao cluster e non cree unha instancia nova propia.</li>
</ul>
</li>
</ol>
<h2 id="lanzando-exemplos">Lanzando exemplos</h2>
<p>Se tes Apache Hadoop instalado do paso anterior, lembra que tamén podes probar os exemplos con:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>yarn<span class="w"> </span>jar<span class="w"> </span>hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar<span class="w"> </span><span class="se">\</span>
</span><span id="__span-36-2"><a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a><span class="w">  </span>wordcount<span class="w"> </span><span class="s2">&quot;books/*&quot;</span><span class="w"> </span>output
</span></code></pre></div>
<h2 id="comandos-e-outros">Comandos e outros</h2>
<p>Haberá que documentar:</p>
<ul>
<li>
<p>hdfs dfs -put ARQUIVO</p>
</li>
<li>
<p>hdfs dfs -ls</p>
</li>
<li>
<p>yarn top</p>
</li>
<li>
<p>yarn node -list</p>
</li>
<li>
<p>yarn application (-list/-kill)</p>
</li>
<li>
<p>jps -&gt; De java (non Spark ou Hadoop)</p>
</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Volver ao principio
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      2025 - Jose Sánchez
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy", "content.code.annotate", "navigation.indexes", "toc.follow", "navigation.top", "navigation.path", "navigation.prune"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copiado no cortapapeis", "clipboard.copy": "Copiar no cortapapeis", "search.result.more.one": "1 m\u00e1is nesta p\u00e1xina", "search.result.more.other": "# m\u00e1is nesta p\u00e1xina", "search.result.none": "Sen resultados", "search.result.one": "1 resultado atopado", "search.result.other": "# resultados atopados", "search.result.placeholder": "Insira un termo", "search.result.term.missing": "Falta", "select.version": "Seleccionar version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>